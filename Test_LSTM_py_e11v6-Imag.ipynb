{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LSTM Series (working)\n",
    "\n",
    "** - Matlab initialization strategy **\n",
    "\n",
    "** - Train and Dev different loss functions **\n",
    "\n",
    "** - Adam Optimizer **\n",
    "_Imag only_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, TimeDistributed\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read parameters from .mat files\n",
    "save in Opt object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_Data_VERSION = \"_e10v5\"\n",
    "Code_VERSION = \"_e11v9-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DNN_DATA_FILE = \"./dnn_models/Test_datas\"+ Test_Data_VERSION+\".mat\"\n",
    "\n",
    "# MODEL_FILE = \"./dnn_models/py_model\"+ Code_VERSION+\".h5\"\n",
    "MODEL_FILE = \"./dnn_models/weights_15_e11v9-2.h5\"\n",
    "\n",
    "OUTPUT_FILE = \"./dnn_models/Real_Imag\"+ Code_VERSION+\".mat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files saved by Matlab reading class. Data, Parameters are read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Opts:\n",
    "    opts_dict = dict()\n",
    "\n",
    "    def __init__(self, FILE_DATA):\n",
    "\n",
    "        # Testing Data \n",
    "        with h5py.File(FILE_DATA, 'r') as f:\n",
    "            print('Opts h5py keys:', list(f.keys()))\n",
    "            for k, v in f.items():\n",
    "\n",
    "                if k == 'teData':\n",
    "                    print(\"teData.shape: \", v.shape)\n",
    "                    self.teData = np.transpose(np.array(v))\n",
    "                    print(\"teData-> mean:\", np.mean(self.teData), \", var:\", np.var(self.teData), \", std:\",\n",
    "                          np.std(self.teData), \", range:\", (np.amin(self.teData),np.amax(self.teData)))\n",
    "                    \n",
    "\n",
    "                elif k == 'teLabel_i':\n",
    "                    print(\"teLabel_i.shape: \", v.shape)\n",
    "                    self.teLabel_i = np.transpose(np.array(v))\n",
    "                    print(\"teLabel_i-> mean:\", np.mean(self.teLabel_i), \", var:\", np.var(self.teLabel_i), \", std:\",\n",
    "                          np.std(self.teLabel_i), \", range:\", (np.amin(self.teLabel_i),np.amax(self.teLabel_i)))\n",
    "                    \n",
    "                elif k == 'teLabel_r':\n",
    "                    print(\"teLabel_r.shape: \", v.shape)\n",
    "                    self.teLabel_r = np.transpose(np.array(v))\n",
    "                    print(\"teLabel_r-> mean:\", np.mean(self.teLabel_r), \", var:\", np.var(self.teLabel_r), \", std:\",\n",
    "                          np.std(self.teLabel_r), \", range:\", (np.amin(self.teLabel_r),np.amax(self.teLabel_r)))\n",
    "                \n",
    "                elif k == 'teNumframes':\n",
    "                    print(\"teNumframes.shape: \", v.shape)\n",
    "                    self.teNumframes = np.transpose(np.array(v))\n",
    "                    \n",
    "            self.teLabel = np.concatenate((self.teLabel_r, self.teLabel_i), axis=1)\n",
    "\n",
    "     \n",
    "    def prepare3D_list(self):\n",
    "        # TEST: total_num_samples = self.teData.shape[0] = 72440\n",
    "        \n",
    "        feat_vec_len = 1230\n",
    "        out_vec_len = 963\n",
    "        \n",
    "        data = self.teData\n",
    "        label_r = self.teLabel_r\n",
    "        label_i = self.teLabel_i\n",
    "        numframes = self.teNumframes\n",
    "\n",
    "        data3D, label3D_r, label3D_i = [], [], []\n",
    "        numframes = np.cumsum(numframes)\n",
    "        \n",
    "        for e, frames in enumerate(numframes):\n",
    "            frames= int(frames)\n",
    "            pre_frames= int(numframes[e-1])\n",
    "            \n",
    "            d = data[:frames] if len(data3D)==0 else data[pre_frames:frames]\n",
    "            r = label_r[:frames] if len(label3D_r)==0 else label_r[pre_frames:frames]\n",
    "            i = label_i[:frames] if len(label3D_i)==0 else label_i[pre_frames:frames]\n",
    "            \n",
    "            data3D.append( d )\n",
    "            label3D_r.append( r )\n",
    "            label3D_i.append( i )\n",
    "\n",
    "        return data3D, label3D_r, label3D_i\n",
    "\n",
    "\n",
    "    def ready_batchID(self, total_num_samples, batch_size):\n",
    "        # TRAIN: total_num_samples = self.trData.shape[0] = 195192\n",
    "        # DEV: total_num_samples = self.trData.shape[0] = 44961\n",
    "\n",
    "        batchID = []\n",
    "        num_batch = math.ceil(total_num_samples/batch_size)\n",
    "\n",
    "        for b in range( int(num_batch) ):\n",
    "            s = b*batch_size\n",
    "            e = (b+1)*batch_size -1\n",
    "\n",
    "            if e >= total_num_samples:\n",
    "                e = total_num_samples - 1\n",
    "\n",
    "            batchID.append((s,e))\n",
    "\n",
    "        return np.array(batchID,ndmin=2)\n",
    "\n",
    "\n",
    "    def suffle_data(self, total_num_samples):\n",
    "        # TRAIN: total_num_samples = self.trData.shape[0] = 195192\n",
    "        # DEV: total_num_samples = self.trData.shape[0] = 44961\n",
    "\n",
    "        return  np.random.permutation(total_num_samples)\n",
    "\n",
    "\n",
    "    def next_batch(self, total_num_samples, batch_size, isTrainCycle=True):\n",
    "        # TRAIN: total_num_samples = self.trData.shape[0] = 195192\n",
    "        # DEV: total_num_samples = self.trData.shape[0] = 44961\n",
    "\n",
    "        batchID = self.ready_batchID(total_num_samples, batch_size)\n",
    "        seq = self.suffle_data(total_num_samples)\n",
    "\n",
    "        for batch in range(batchID.shape[0]):\n",
    "            if isTrainCycle:\n",
    "                x = opts.trData[ seq[batchID[batch][0]:batchID[batch][1] ] ]\n",
    "                y = opts.trLabel[ seq[batchID[batch][0]:batchID[batch][1] ] ]\n",
    "\n",
    "            else:\n",
    "                x = opts.cvData[seq[batchID[batch][0]:batchID[batch][1]]]\n",
    "                y = opts.cvLabel[seq[batchID[batch][0]:batchID[batch][1]]]\n",
    "\n",
    "            # print('Next Batch', x.shape, y.shape)\n",
    "            yield [x, y]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opts h5py keys: ['#refs#', '#subsystem#', 'teData', 'teFilename_mix', 'teLabel_i', 'teLabel_r', 'teNumframes']\n",
      "teData.shape:  (1230, 72440)\n",
      "teData-> mean: -0.00110349 , var: 0.556445 , std: 0.745952 , range: (-4.8041673, 5.2418036)\n",
      "teLabel_i.shape:  (963, 72440)\n",
      "teLabel_i-> mean: -3.01466e-06 , var: 1.05955e-05 , std: 0.00325507 , range: (-0.03745788, 0.035189673)\n",
      "teLabel_r.shape:  (963, 72440)\n",
      "teLabel_r-> mean: 0.0328164 , var: 0.00246607 , std: 0.0496596 , range: (-0.15398552, 0.43288523)\n",
      "teNumframes.shape:  (1, 545)\n"
     ]
    }
   ],
   "source": [
    "opts = Opts(DNN_DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opts.teFilename_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch generator (now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_batch_rnn(opts, maxlen=185):\n",
    "    # TEST: total_num_samples = self.trData.shape[0] = 72440\n",
    "\n",
    "    feat_vec_len = 1230\n",
    "    out_vec_len = 963\n",
    "\n",
    "    selected_indics = np.arange(len(opts.teNumframes))\n",
    "    data3D, label3D_r, label3D_i = opts.prepare3D_list()\n",
    "\n",
    "    f = 0\n",
    "    x, y = None, None\n",
    "    \n",
    "    for indx in selected_indics:\n",
    "        d = data3D[indx]\n",
    "        d = np.concatenate( (d, np.zeros((maxlen-d.shape[0],feat_vec_len))),axis=0 )\n",
    "        d = np.expand_dims(d, axis=0)\n",
    "\n",
    "        l = label3D_r[indx] # here real only\n",
    "        l = np.concatenate( (l, np.zeros((maxlen-l.shape[0],out_vec_len))),axis=0 )\n",
    "        l = np.expand_dims(l, axis=0)\n",
    "\n",
    "        x = d if x is None else np.concatenate( (x,d),axis=0 )\n",
    "        y = l if y is None else np.concatenate( (y,l),axis=0 )\n",
    "\n",
    "    f += 1\n",
    "\n",
    "#                 if x.shape[0]<batch_size:\n",
    "#                     x = np.concatenate( (x, np.zeros((batch_size-x.shape[0],maxlen,feat_vec_len))), axis=0)\n",
    "#                     y = np.concatenate( (y, np.zeros((batch_size-y.shape[0],maxlen,out_vec_len*2))), axis=0)\n",
    "\n",
    "    print(\"x:\",x.shape, \", y:\", y.shape)\n",
    "    return x,y\n",
    "                        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for e,[x,y] in enumerate(next_batch_rnn(opts,128)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (545, 200, 1230) , y: (545, 200, 963)\n"
     ]
    }
   ],
   "source": [
    "x,y_r = test_batch_rnn(opts, maxlen=Max_RNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Testing\n",
    "single bidirectional GRU layer\n",
    "\n",
    "real+img (963+963)=1926-d output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Max_RNN = 200# 185\n",
    "\n",
    "feat_vec_len = 1230\n",
    "out_vec_len = 963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545/545 [==============================] - 2s\n",
      "(545, 185, 963)\n"
     ]
    }
   ],
   "source": [
    "model = load_model(MODEL_FILE)\n",
    "\n",
    "\n",
    "y_hat = model.predict(x, batch_size=x.shape[0], verbose=1)\n",
    "\n",
    "print(y_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 200, 1230) (576, 200, 963)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "if x.shape[0]%batch_size:\n",
    "    d = x.shape[0]//batch_size + 1\n",
    "    \n",
    "    x = np.concatenate((x, np.zeros((batch_size*d-x.shape[0],x.shape[1],x.shape[2]))), axis=0)\n",
    "    y_r = np.concatenate((y_r, np.zeros((batch_size*d-y_r.shape[0],y_r.shape[1],y_r.shape[2]))), axis=0)\n",
    "    \n",
    "print(x.shape, y_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "32/32 [==============================] - 0s\n",
      "(576, 200, 963)\n"
     ]
    }
   ],
   "source": [
    "model = load_model(MODEL_FILE)\n",
    "for b in range(d):\n",
    "    if b==0:\n",
    "        y_hat = model.predict(x[batch_size*b:batch_size*(b+1)], batch_size=batch_size, verbose=1)\n",
    "    elif b==d: \n",
    "        y_hat = np.concatenate( \\\n",
    "            (y_hat,model.predict(x[batch_size*b:], batch_size=batch_size, verbose=1))\\\n",
    "            ,axis=0)\n",
    "    else: \n",
    "        y_hat = np.concatenate( \\\n",
    "            (y_hat,model.predict(x[batch_size*b:batch_size*(b+1)], batch_size=batch_size, verbose=1))\\\n",
    "            ,axis=0)\n",
    "\n",
    "print(y_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 200, 1926)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((y_r, y_hat), axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat(OUTPUT_FILE, {'y_hat':np.concatenate((y_hat, y_r), axis=2)[:545]}) # originally 545 (not 576)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### For RNN style 3D batch generation (old)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def next_batch_rnn(opts, batch_size, maxlen=185):\n",
    "    # TEST: total_num_samples = self.trData.shape[0] = 72440\n",
    "\n",
    "    feat_vec_len = 1230\n",
    "    out_vec_len = 963\n",
    "\n",
    "    selected_indics = np.arange(len(opts.teNumframes))\n",
    "    data3D, label3D_r, label3D_i = opts.prepare3D_list()\n",
    "\n",
    "    np.random.shuffle(selected_indics)\n",
    "\n",
    "\n",
    "    f = 0\n",
    "    while (f*batch_size) < len(selected_indics):\n",
    "\n",
    "        if (f+1)*batch_size < len(selected_indics):\n",
    "            si = selected_indics[(f*batch_size):((f+1)*batch_size)]\n",
    "        else:\n",
    "            si = selected_indics[(f*batch_size):]\n",
    "\n",
    "        print(f, len(selected_indics), f*batch_size, f*batch_size+len(si))\n",
    "\n",
    "        x, y = None, None\n",
    "        for indx in si:\n",
    "            d = data3D[indx]\n",
    "            d = np.concatenate( (d, np.zeros((maxlen-d.shape[0],feat_vec_len))),axis=0 )\n",
    "            d = np.expand_dims(d, axis=0)\n",
    "\n",
    "            l = np.concatenate((label3D_r[indx], label3D_i[indx]), axis=1)\n",
    "            l = np.concatenate( (l, np.zeros((maxlen-l.shape[0],out_vec_len*2))),axis=0 )\n",
    "            l = np.expand_dims(l, axis=0)\n",
    "\n",
    "            x = d if x is None else np.concatenate( (x,d),axis=0 )\n",
    "            y = l if y is None else np.concatenate( (y,l),axis=0 )\n",
    "\n",
    "        f += 1\n",
    "\n",
    "#                 if x.shape[0]<batch_size:\n",
    "#                     x = np.concatenate( (x, np.zeros((batch_size-x.shape[0],maxlen,feat_vec_len))), axis=0)\n",
    "#                     y = np.concatenate( (y, np.zeros((batch_size-y.shape[0],maxlen,out_vec_len*2))), axis=0)\n",
    "\n",
    "        print(\"x:\",x.shape, \", y:\", y.shape)\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### unwrapAugmentedTF_wAvg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unwrapAugmentedTF_wAvg(impt_mag,num_per_side,unwrap_mag=None):\n",
    "    \n",
    "#     Description: Unwrap the augmented time-frequency (T-F) representation and compute the average.\n",
    "\n",
    "#     Input:\n",
    "#         impt_mag: wrapped T-F representation with dimensions (2*T+1)*d x m\n",
    "#         T: number of frames to left and right of each frame used to augmented T-F representation\n",
    "#     Output:\n",
    "#         unwrap_avgmag: unwrapped and averaged T-F representation with dimensions d x m\n",
    "#         unwrap_mag: unwrapped T-F representation with dimensions d x (2*T+1) x m\n",
    "#\n",
    "        \n",
    "        sliding_window_len       = 2*num_per_side + 1\n",
    "        (numWrapFreqs,numFrames) = impt_mag.shape\n",
    "        numFreqs                 = numWrapFreqs//sliding_window_len\n",
    "        unwrap_avgmag            = np.zeros((numFreqs,numFrames))\n",
    "        \n",
    "        if num_per_side > 0:\n",
    "            if unwrap_mag is None:\n",
    "            \n",
    "                unwrap_mag        = np.zeros((numFreqs,sliding_window_len+1,numFrames))\n",
    "                curr_ind_location = np.ones((numFrames,1),dtype=int)\n",
    "                \n",
    "\n",
    "                for frameNum in range(numFrames):\n",
    "                    \n",
    "                    # Get the indices for the frames used in this augmented matrix\n",
    "                    frame_inds=[]\n",
    "                    for inds in range(frameNum-num_per_side,frameNum+num_per_side+1):\n",
    "                        if inds<0:\n",
    "                            frame_inds.append(0)\n",
    "                        elif inds>=numFrames:\n",
    "                            frame_inds.append(numFrames-1)\n",
    "                        else:\n",
    "                            frame_inds.append(inds)\n",
    "                    \n",
    "                    # Unwrap the data for this frame\n",
    "                    slid_win_data = np.reshape( impt_mag[:,frameNum], (numFreqs,sliding_window_len)) #Size d x (2*T + 1)\n",
    "                    \n",
    "                    for ind_num in range(len(frame_inds)):\n",
    "\n",
    "                        slid = np.array(slid_win_data[:,ind_num], ndmin=2).T\n",
    "                        unwrap_mag[:,curr_ind_location[frame_inds[ind_num]], frame_inds[ind_num]] = slid \n",
    "                        \n",
    "                        # Update counters\n",
    "                        curr_ind_location[frame_inds[ind_num]] = curr_ind_location[frame_inds[ind_num]] + 1\n",
    "\n",
    "\n",
    "            temp = np.zeros((numFreqs,sliding_window_len+1))\n",
    "            \n",
    "            for frameNum in range(numFrames):\n",
    "#                 print(unwrap_mag.shape)\n",
    "                \n",
    "                unwrap_avgmag[:,frameNum] = np.mean(unwrap_mag[:,:,frameNum],axis=1)\n",
    "#                 print(unwrap_mag.shape)\n",
    "#                 return\n",
    "\n",
    "            \n",
    "        else:\n",
    "            unwrap_avgmag = impt_mag;\n",
    "            unwrap_mag = 0;\n",
    "            \n",
    "        return unwrap_avgmag,unwrap_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unwrap: (321, 127) , reals: 1\n",
      "unwrap: (321, 127) , reals: 2\n",
      "unwrap: (321, 127) , reals: 3\n",
      "unwrap: (321, 127) , reals: 4\n",
      "unwrap: (321, 127) , reals: 5\n",
      "unwrap: (321, 147) , reals: 6\n",
      "unwrap: (321, 147) , reals: 7\n",
      "unwrap: (321, 147) , reals: 8\n",
      "unwrap: (321, 147) , reals: 9\n",
      "unwrap: (321, 147) , reals: 10\n",
      "unwrap: (321, 131) , reals: 11\n",
      "unwrap: (321, 131) , reals: 12\n",
      "unwrap: (321, 131) , reals: 13\n",
      "unwrap: (321, 131) , reals: 14\n",
      "unwrap: (321, 131) , reals: 15\n",
      "unwrap: (321, 147) , reals: 16\n",
      "unwrap: (321, 147) , reals: 17\n",
      "unwrap: (321, 147) , reals: 18\n",
      "unwrap: (321, 147) , reals: 19\n",
      "unwrap: (321, 147) , reals: 20\n",
      "unwrap: (321, 145) , reals: 21\n",
      "unwrap: (321, 145) , reals: 22\n",
      "unwrap: (321, 145) , reals: 23\n",
      "unwrap: (321, 145) , reals: 24\n",
      "unwrap: (321, 145) , reals: 25\n",
      "unwrap: (321, 141) , reals: 26\n",
      "unwrap: (321, 141) , reals: 27\n",
      "unwrap: (321, 141) , reals: 28\n",
      "unwrap: (321, 141) , reals: 29\n",
      "unwrap: (321, 141) , reals: 30\n",
      "unwrap: (321, 155) , reals: 31\n",
      "unwrap: (321, 155) , reals: 32\n",
      "unwrap: (321, 155) , reals: 33\n",
      "unwrap: (321, 155) , reals: 34\n",
      "unwrap: (321, 155) , reals: 35\n",
      "unwrap: (321, 130) , reals: 36\n",
      "unwrap: (321, 130) , reals: 37\n",
      "unwrap: (321, 130) , reals: 38\n",
      "unwrap: (321, 130) , reals: 39\n",
      "unwrap: (321, 130) , reals: 40\n",
      "unwrap: (321, 130) , reals: 41\n",
      "unwrap: (321, 130) , reals: 42\n",
      "unwrap: (321, 130) , reals: 43\n",
      "unwrap: (321, 130) , reals: 44\n",
      "unwrap: (321, 130) , reals: 45\n",
      "unwrap: (321, 146) , reals: 46\n",
      "unwrap: (321, 146) , reals: 47\n",
      "unwrap: (321, 146) , reals: 48\n",
      "unwrap: (321, 146) , reals: 49\n",
      "unwrap: (321, 146) , reals: 50\n",
      "unwrap: (321, 142) , reals: 51\n",
      "unwrap: (321, 142) , reals: 52\n",
      "unwrap: (321, 142) , reals: 53\n",
      "unwrap: (321, 142) , reals: 54\n",
      "unwrap: (321, 142) , reals: 55\n",
      "unwrap: (321, 141) , reals: 56\n",
      "unwrap: (321, 141) , reals: 57\n",
      "unwrap: (321, 141) , reals: 58\n",
      "unwrap: (321, 141) , reals: 59\n",
      "unwrap: (321, 141) , reals: 60\n",
      "unwrap: (321, 118) , reals: 61\n",
      "unwrap: (321, 118) , reals: 62\n",
      "unwrap: (321, 118) , reals: 63\n",
      "unwrap: (321, 118) , reals: 64\n",
      "unwrap: (321, 118) , reals: 65\n",
      "unwrap: (321, 158) , reals: 66\n",
      "unwrap: (321, 158) , reals: 67\n",
      "unwrap: (321, 158) , reals: 68\n",
      "unwrap: (321, 158) , reals: 69\n",
      "unwrap: (321, 158) , reals: 70\n",
      "unwrap: (321, 129) , reals: 71\n",
      "unwrap: (321, 129) , reals: 72\n",
      "unwrap: (321, 129) , reals: 73\n",
      "unwrap: (321, 129) , reals: 74\n",
      "unwrap: (321, 129) , reals: 75\n",
      "unwrap: (321, 126) , reals: 76\n",
      "unwrap: (321, 126) , reals: 77\n",
      "unwrap: (321, 126) , reals: 78\n",
      "unwrap: (321, 126) , reals: 79\n",
      "unwrap: (321, 126) , reals: 80\n",
      "unwrap: (321, 143) , reals: 81\n",
      "unwrap: (321, 143) , reals: 82\n",
      "unwrap: (321, 143) , reals: 83\n",
      "unwrap: (321, 143) , reals: 84\n",
      "unwrap: (321, 143) , reals: 85\n",
      "unwrap: (321, 139) , reals: 86\n",
      "unwrap: (321, 139) , reals: 87\n",
      "unwrap: (321, 139) , reals: 88\n",
      "unwrap: (321, 139) , reals: 89\n",
      "unwrap: (321, 139) , reals: 90\n",
      "unwrap: (321, 128) , reals: 91\n",
      "unwrap: (321, 128) , reals: 92\n",
      "unwrap: (321, 128) , reals: 93\n",
      "unwrap: (321, 128) , reals: 94\n",
      "unwrap: (321, 128) , reals: 95\n",
      "unwrap: (321, 130) , reals: 96\n",
      "unwrap: (321, 130) , reals: 97\n",
      "unwrap: (321, 130) , reals: 98\n",
      "unwrap: (321, 130) , reals: 99\n",
      "unwrap: (321, 130) , reals: 100\n",
      "unwrap: (321, 172) , reals: 101\n",
      "unwrap: (321, 172) , reals: 102\n",
      "unwrap: (321, 172) , reals: 103\n",
      "unwrap: (321, 172) , reals: 104\n",
      "unwrap: (321, 172) , reals: 105\n",
      "unwrap: (321, 141) , reals: 106\n",
      "unwrap: (321, 141) , reals: 107\n",
      "unwrap: (321, 141) , reals: 108\n",
      "unwrap: (321, 141) , reals: 109\n",
      "unwrap: (321, 141) , reals: 110\n",
      "unwrap: (321, 117) , reals: 111\n",
      "unwrap: (321, 117) , reals: 112\n",
      "unwrap: (321, 117) , reals: 113\n",
      "unwrap: (321, 117) , reals: 114\n",
      "unwrap: (321, 117) , reals: 115\n",
      "unwrap: (321, 128) , reals: 116\n",
      "unwrap: (321, 128) , reals: 117\n",
      "unwrap: (321, 128) , reals: 118\n",
      "unwrap: (321, 128) , reals: 119\n",
      "unwrap: (321, 128) , reals: 120\n",
      "unwrap: (321, 125) , reals: 121\n",
      "unwrap: (321, 125) , reals: 122\n",
      "unwrap: (321, 125) , reals: 123\n",
      "unwrap: (321, 125) , reals: 124\n",
      "unwrap: (321, 125) , reals: 125\n",
      "unwrap: (321, 143) , reals: 126\n",
      "unwrap: (321, 143) , reals: 127\n",
      "unwrap: (321, 143) , reals: 128\n",
      "unwrap: (321, 143) , reals: 129\n",
      "unwrap: (321, 143) , reals: 130\n",
      "unwrap: (321, 119) , reals: 131\n",
      "unwrap: (321, 119) , reals: 132\n",
      "unwrap: (321, 119) , reals: 133\n",
      "unwrap: (321, 119) , reals: 134\n",
      "unwrap: (321, 119) , reals: 135\n",
      "unwrap: (321, 134) , reals: 136\n",
      "unwrap: (321, 134) , reals: 137\n",
      "unwrap: (321, 134) , reals: 138\n",
      "unwrap: (321, 134) , reals: 139\n",
      "unwrap: (321, 134) , reals: 140\n",
      "unwrap: (321, 143) , reals: 141\n",
      "unwrap: (321, 143) , reals: 142\n",
      "unwrap: (321, 143) , reals: 143\n",
      "unwrap: (321, 143) , reals: 144\n",
      "unwrap: (321, 143) , reals: 145\n",
      "unwrap: (321, 148) , reals: 146\n",
      "unwrap: (321, 148) , reals: 147\n",
      "unwrap: (321, 148) , reals: 148\n",
      "unwrap: (321, 148) , reals: 149\n",
      "unwrap: (321, 148) , reals: 150\n",
      "unwrap: (321, 128) , reals: 151\n",
      "unwrap: (321, 128) , reals: 152\n",
      "unwrap: (321, 128) , reals: 153\n",
      "unwrap: (321, 128) , reals: 154\n",
      "unwrap: (321, 128) , reals: 155\n",
      "unwrap: (321, 124) , reals: 156\n",
      "unwrap: (321, 124) , reals: 157\n",
      "unwrap: (321, 124) , reals: 158\n",
      "unwrap: (321, 124) , reals: 159\n",
      "unwrap: (321, 124) , reals: 160\n",
      "unwrap: (321, 145) , reals: 161\n",
      "unwrap: (321, 145) , reals: 162\n",
      "unwrap: (321, 145) , reals: 163\n",
      "unwrap: (321, 145) , reals: 164\n",
      "unwrap: (321, 145) , reals: 165\n",
      "unwrap: (321, 153) , reals: 166\n",
      "unwrap: (321, 153) , reals: 167\n",
      "unwrap: (321, 153) , reals: 168\n",
      "unwrap: (321, 153) , reals: 169\n",
      "unwrap: (321, 153) , reals: 170\n",
      "unwrap: (321, 124) , reals: 171\n",
      "unwrap: (321, 124) , reals: 172\n",
      "unwrap: (321, 124) , reals: 173\n",
      "unwrap: (321, 124) , reals: 174\n",
      "unwrap: (321, 124) , reals: 175\n",
      "unwrap: (321, 126) , reals: 176\n",
      "unwrap: (321, 126) , reals: 177\n",
      "unwrap: (321, 126) , reals: 178\n",
      "unwrap: (321, 126) , reals: 179\n",
      "unwrap: (321, 126) , reals: 180\n",
      "unwrap: (321, 126) , reals: 181\n",
      "unwrap: (321, 126) , reals: 182\n",
      "unwrap: (321, 126) , reals: 183\n",
      "unwrap: (321, 126) , reals: 184\n",
      "unwrap: (321, 126) , reals: 185\n",
      "unwrap: (321, 136) , reals: 186\n",
      "unwrap: (321, 136) , reals: 187\n",
      "unwrap: (321, 136) , reals: 188\n",
      "unwrap: (321, 136) , reals: 189\n",
      "unwrap: (321, 136) , reals: 190\n",
      "unwrap: (321, 129) , reals: 191\n",
      "unwrap: (321, 129) , reals: 192\n",
      "unwrap: (321, 129) , reals: 193\n",
      "unwrap: (321, 129) , reals: 194\n",
      "unwrap: (321, 129) , reals: 195\n",
      "unwrap: (321, 142) , reals: 196\n",
      "unwrap: (321, 142) , reals: 197\n",
      "unwrap: (321, 142) , reals: 198\n",
      "unwrap: (321, 142) , reals: 199\n",
      "unwrap: (321, 142) , reals: 200\n",
      "unwrap: (321, 134) , reals: 201\n",
      "unwrap: (321, 134) , reals: 202\n",
      "unwrap: (321, 134) , reals: 203\n",
      "unwrap: (321, 134) , reals: 204\n",
      "unwrap: (321, 134) , reals: 205\n",
      "unwrap: (321, 118) , reals: 206\n",
      "unwrap: (321, 118) , reals: 207\n",
      "unwrap: (321, 118) , reals: 208\n",
      "unwrap: (321, 118) , reals: 209\n",
      "unwrap: (321, 118) , reals: 210\n",
      "unwrap: (321, 146) , reals: 211\n",
      "unwrap: (321, 146) , reals: 212\n",
      "unwrap: (321, 146) , reals: 213\n",
      "unwrap: (321, 146) , reals: 214\n",
      "unwrap: (321, 146) , reals: 215\n",
      "unwrap: (321, 166) , reals: 216\n",
      "unwrap: (321, 166) , reals: 217\n",
      "unwrap: (321, 166) , reals: 218\n",
      "unwrap: (321, 166) , reals: 219\n",
      "unwrap: (321, 166) , reals: 220\n",
      "unwrap: (321, 129) , reals: 221\n",
      "unwrap: (321, 129) , reals: 222\n",
      "unwrap: (321, 129) , reals: 223\n",
      "unwrap: (321, 129) , reals: 224\n",
      "unwrap: (321, 129) , reals: 225\n",
      "unwrap: (321, 152) , reals: 226\n",
      "unwrap: (321, 152) , reals: 227\n",
      "unwrap: (321, 152) , reals: 228\n",
      "unwrap: (321, 152) , reals: 229\n",
      "unwrap: (321, 152) , reals: 230\n",
      "unwrap: (321, 132) , reals: 231\n",
      "unwrap: (321, 132) , reals: 232\n",
      "unwrap: (321, 132) , reals: 233\n",
      "unwrap: (321, 132) , reals: 234\n",
      "unwrap: (321, 132) , reals: 235\n",
      "unwrap: (321, 156) , reals: 236\n",
      "unwrap: (321, 156) , reals: 237\n",
      "unwrap: (321, 156) , reals: 238\n",
      "unwrap: (321, 156) , reals: 239\n",
      "unwrap: (321, 156) , reals: 240\n",
      "unwrap: (321, 142) , reals: 241\n",
      "unwrap: (321, 142) , reals: 242\n",
      "unwrap: (321, 142) , reals: 243\n",
      "unwrap: (321, 142) , reals: 244\n",
      "unwrap: (321, 142) , reals: 245\n",
      "unwrap: (321, 116) , reals: 246\n",
      "unwrap: (321, 116) , reals: 247\n",
      "unwrap: (321, 116) , reals: 248\n",
      "unwrap: (321, 116) , reals: 249\n",
      "unwrap: (321, 116) , reals: 250\n",
      "unwrap: (321, 130) , reals: 251\n",
      "unwrap: (321, 130) , reals: 252\n",
      "unwrap: (321, 130) , reals: 253\n",
      "unwrap: (321, 130) , reals: 254\n",
      "unwrap: (321, 130) , reals: 255\n",
      "unwrap: (321, 106) , reals: 256\n",
      "unwrap: (321, 106) , reals: 257\n",
      "unwrap: (321, 106) , reals: 258\n",
      "unwrap: (321, 106) , reals: 259\n",
      "unwrap: (321, 106) , reals: 260\n",
      "unwrap: (321, 132) , reals: 261\n",
      "unwrap: (321, 132) , reals: 262\n",
      "unwrap: (321, 132) , reals: 263\n",
      "unwrap: (321, 132) , reals: 264\n",
      "unwrap: (321, 132) , reals: 265\n",
      "unwrap: (321, 120) , reals: 266\n",
      "unwrap: (321, 120) , reals: 267\n",
      "unwrap: (321, 120) , reals: 268\n",
      "unwrap: (321, 120) , reals: 269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unwrap: (321, 120) , reals: 270\n",
      "unwrap: (321, 136) , reals: 271\n",
      "unwrap: (321, 136) , reals: 272\n",
      "unwrap: (321, 136) , reals: 273\n",
      "unwrap: (321, 136) , reals: 274\n",
      "unwrap: (321, 136) , reals: 275\n",
      "unwrap: (321, 123) , reals: 276\n",
      "unwrap: (321, 123) , reals: 277\n",
      "unwrap: (321, 123) , reals: 278\n",
      "unwrap: (321, 123) , reals: 279\n",
      "unwrap: (321, 123) , reals: 280\n",
      "unwrap: (321, 145) , reals: 281\n",
      "unwrap: (321, 145) , reals: 282\n",
      "unwrap: (321, 145) , reals: 283\n",
      "unwrap: (321, 145) , reals: 284\n",
      "unwrap: (321, 145) , reals: 285\n",
      "unwrap: (321, 123) , reals: 286\n",
      "unwrap: (321, 123) , reals: 287\n",
      "unwrap: (321, 123) , reals: 288\n",
      "unwrap: (321, 123) , reals: 289\n",
      "unwrap: (321, 123) , reals: 290\n",
      "unwrap: (321, 126) , reals: 291\n",
      "unwrap: (321, 126) , reals: 292\n",
      "unwrap: (321, 126) , reals: 293\n",
      "unwrap: (321, 126) , reals: 294\n",
      "unwrap: (321, 126) , reals: 295\n",
      "unwrap: (321, 117) , reals: 296\n",
      "unwrap: (321, 117) , reals: 297\n",
      "unwrap: (321, 117) , reals: 298\n",
      "unwrap: (321, 117) , reals: 299\n",
      "unwrap: (321, 117) , reals: 300\n",
      "unwrap: (321, 131) , reals: 301\n",
      "unwrap: (321, 131) , reals: 302\n",
      "unwrap: (321, 131) , reals: 303\n",
      "unwrap: (321, 131) , reals: 304\n",
      "unwrap: (321, 131) , reals: 305\n",
      "unwrap: (321, 128) , reals: 306\n",
      "unwrap: (321, 128) , reals: 307\n",
      "unwrap: (321, 128) , reals: 308\n",
      "unwrap: (321, 128) , reals: 309\n",
      "unwrap: (321, 128) , reals: 310\n",
      "unwrap: (321, 128) , reals: 311\n",
      "unwrap: (321, 128) , reals: 312\n",
      "unwrap: (321, 128) , reals: 313\n",
      "unwrap: (321, 128) , reals: 314\n",
      "unwrap: (321, 128) , reals: 315\n",
      "unwrap: (321, 119) , reals: 316\n",
      "unwrap: (321, 119) , reals: 317\n",
      "unwrap: (321, 119) , reals: 318\n",
      "unwrap: (321, 119) , reals: 319\n",
      "unwrap: (321, 119) , reals: 320\n",
      "unwrap: (321, 122) , reals: 321\n",
      "unwrap: (321, 122) , reals: 322\n",
      "unwrap: (321, 122) , reals: 323\n",
      "unwrap: (321, 122) , reals: 324\n",
      "unwrap: (321, 122) , reals: 325\n",
      "unwrap: (321, 110) , reals: 326\n",
      "unwrap: (321, 110) , reals: 327\n",
      "unwrap: (321, 110) , reals: 328\n",
      "unwrap: (321, 110) , reals: 329\n",
      "unwrap: (321, 110) , reals: 330\n",
      "unwrap: (321, 132) , reals: 331\n",
      "unwrap: (321, 132) , reals: 332\n",
      "unwrap: (321, 132) , reals: 333\n",
      "unwrap: (321, 132) , reals: 334\n",
      "unwrap: (321, 132) , reals: 335\n",
      "unwrap: (321, 118) , reals: 336\n",
      "unwrap: (321, 118) , reals: 337\n",
      "unwrap: (321, 118) , reals: 338\n",
      "unwrap: (321, 118) , reals: 339\n",
      "unwrap: (321, 118) , reals: 340\n",
      "unwrap: (321, 126) , reals: 341\n",
      "unwrap: (321, 126) , reals: 342\n",
      "unwrap: (321, 126) , reals: 343\n",
      "unwrap: (321, 126) , reals: 344\n",
      "unwrap: (321, 126) , reals: 345\n",
      "unwrap: (321, 158) , reals: 346\n",
      "unwrap: (321, 158) , reals: 347\n",
      "unwrap: (321, 158) , reals: 348\n",
      "unwrap: (321, 158) , reals: 349\n",
      "unwrap: (321, 158) , reals: 350\n",
      "unwrap: (321, 146) , reals: 351\n",
      "unwrap: (321, 146) , reals: 352\n",
      "unwrap: (321, 146) , reals: 353\n",
      "unwrap: (321, 146) , reals: 354\n",
      "unwrap: (321, 146) , reals: 355\n",
      "unwrap: (321, 125) , reals: 356\n",
      "unwrap: (321, 125) , reals: 357\n",
      "unwrap: (321, 125) , reals: 358\n",
      "unwrap: (321, 125) , reals: 359\n",
      "unwrap: (321, 125) , reals: 360\n",
      "unwrap: (321, 151) , reals: 361\n",
      "unwrap: (321, 151) , reals: 362\n",
      "unwrap: (321, 151) , reals: 363\n",
      "unwrap: (321, 151) , reals: 364\n",
      "unwrap: (321, 151) , reals: 365\n",
      "unwrap: (321, 144) , reals: 366\n",
      "unwrap: (321, 144) , reals: 367\n",
      "unwrap: (321, 144) , reals: 368\n",
      "unwrap: (321, 144) , reals: 369\n",
      "unwrap: (321, 144) , reals: 370\n",
      "unwrap: (321, 124) , reals: 371\n",
      "unwrap: (321, 124) , reals: 372\n",
      "unwrap: (321, 124) , reals: 373\n",
      "unwrap: (321, 124) , reals: 374\n",
      "unwrap: (321, 124) , reals: 375\n",
      "unwrap: (321, 149) , reals: 376\n",
      "unwrap: (321, 149) , reals: 377\n",
      "unwrap: (321, 149) , reals: 378\n",
      "unwrap: (321, 149) , reals: 379\n",
      "unwrap: (321, 149) , reals: 380\n",
      "unwrap: (321, 168) , reals: 381\n",
      "unwrap: (321, 168) , reals: 382\n",
      "unwrap: (321, 168) , reals: 383\n",
      "unwrap: (321, 168) , reals: 384\n",
      "unwrap: (321, 168) , reals: 385\n",
      "unwrap: (321, 181) , reals: 386\n",
      "unwrap: (321, 181) , reals: 387\n",
      "unwrap: (321, 181) , reals: 388\n",
      "unwrap: (321, 181) , reals: 389\n",
      "unwrap: (321, 181) , reals: 390\n",
      "unwrap: (321, 149) , reals: 391\n",
      "unwrap: (321, 149) , reals: 392\n",
      "unwrap: (321, 149) , reals: 393\n",
      "unwrap: (321, 149) , reals: 394\n",
      "unwrap: (321, 149) , reals: 395\n",
      "unwrap: (321, 139) , reals: 396\n",
      "unwrap: (321, 139) , reals: 397\n",
      "unwrap: (321, 139) , reals: 398\n",
      "unwrap: (321, 139) , reals: 399\n",
      "unwrap: (321, 139) , reals: 400\n",
      "unwrap: (321, 149) , reals: 401\n",
      "unwrap: (321, 149) , reals: 402\n",
      "unwrap: (321, 149) , reals: 403\n",
      "unwrap: (321, 149) , reals: 404\n",
      "unwrap: (321, 149) , reals: 405\n",
      "unwrap: (321, 130) , reals: 406\n",
      "unwrap: (321, 130) , reals: 407\n",
      "unwrap: (321, 130) , reals: 408\n",
      "unwrap: (321, 130) , reals: 409\n",
      "unwrap: (321, 130) , reals: 410\n",
      "unwrap: (321, 130) , reals: 411\n",
      "unwrap: (321, 130) , reals: 412\n",
      "unwrap: (321, 130) , reals: 413\n",
      "unwrap: (321, 130) , reals: 414\n",
      "unwrap: (321, 130) , reals: 415\n",
      "unwrap: (321, 153) , reals: 416\n",
      "unwrap: (321, 153) , reals: 417\n",
      "unwrap: (321, 153) , reals: 418\n",
      "unwrap: (321, 153) , reals: 419\n",
      "unwrap: (321, 153) , reals: 420\n",
      "unwrap: (321, 128) , reals: 421\n",
      "unwrap: (321, 128) , reals: 422\n",
      "unwrap: (321, 128) , reals: 423\n",
      "unwrap: (321, 128) , reals: 424\n",
      "unwrap: (321, 128) , reals: 425\n",
      "unwrap: (321, 141) , reals: 426\n",
      "unwrap: (321, 141) , reals: 427\n",
      "unwrap: (321, 141) , reals: 428\n",
      "unwrap: (321, 141) , reals: 429\n",
      "unwrap: (321, 141) , reals: 430\n",
      "unwrap: (321, 124) , reals: 431\n",
      "unwrap: (321, 124) , reals: 432\n",
      "unwrap: (321, 124) , reals: 433\n",
      "unwrap: (321, 124) , reals: 434\n",
      "unwrap: (321, 124) , reals: 435\n",
      "unwrap: (321, 142) , reals: 436\n",
      "unwrap: (321, 142) , reals: 437\n",
      "unwrap: (321, 142) , reals: 438\n",
      "unwrap: (321, 142) , reals: 439\n",
      "unwrap: (321, 142) , reals: 440\n",
      "unwrap: (321, 146) , reals: 441\n",
      "unwrap: (321, 146) , reals: 442\n",
      "unwrap: (321, 146) , reals: 443\n",
      "unwrap: (321, 146) , reals: 444\n",
      "unwrap: (321, 146) , reals: 445\n",
      "unwrap: (321, 107) , reals: 446\n",
      "unwrap: (321, 107) , reals: 447\n",
      "unwrap: (321, 107) , reals: 448\n",
      "unwrap: (321, 107) , reals: 449\n",
      "unwrap: (321, 107) , reals: 450\n",
      "unwrap: (321, 121) , reals: 451\n",
      "unwrap: (321, 121) , reals: 452\n",
      "unwrap: (321, 121) , reals: 453\n",
      "unwrap: (321, 121) , reals: 454\n",
      "unwrap: (321, 121) , reals: 455\n",
      "unwrap: (321, 121) , reals: 456\n",
      "unwrap: (321, 121) , reals: 457\n",
      "unwrap: (321, 121) , reals: 458\n",
      "unwrap: (321, 121) , reals: 459\n",
      "unwrap: (321, 121) , reals: 460\n",
      "unwrap: (321, 108) , reals: 461\n",
      "unwrap: (321, 108) , reals: 462\n",
      "unwrap: (321, 108) , reals: 463\n",
      "unwrap: (321, 108) , reals: 464\n",
      "unwrap: (321, 108) , reals: 465\n",
      "unwrap: (321, 112) , reals: 466\n",
      "unwrap: (321, 112) , reals: 467\n",
      "unwrap: (321, 112) , reals: 468\n",
      "unwrap: (321, 112) , reals: 469\n",
      "unwrap: (321, 112) , reals: 470\n",
      "unwrap: (321, 121) , reals: 471\n",
      "unwrap: (321, 121) , reals: 472\n",
      "unwrap: (321, 121) , reals: 473\n",
      "unwrap: (321, 121) , reals: 474\n",
      "unwrap: (321, 121) , reals: 475\n",
      "unwrap: (321, 132) , reals: 476\n",
      "unwrap: (321, 132) , reals: 477\n",
      "unwrap: (321, 132) , reals: 478\n",
      "unwrap: (321, 132) , reals: 479\n",
      "unwrap: (321, 132) , reals: 480\n",
      "unwrap: (321, 110) , reals: 481\n",
      "unwrap: (321, 110) , reals: 482\n",
      "unwrap: (321, 110) , reals: 483\n",
      "unwrap: (321, 110) , reals: 484\n",
      "unwrap: (321, 110) , reals: 485\n",
      "unwrap: (321, 137) , reals: 486\n",
      "unwrap: (321, 137) , reals: 487\n",
      "unwrap: (321, 137) , reals: 488\n",
      "unwrap: (321, 137) , reals: 489\n",
      "unwrap: (321, 137) , reals: 490\n",
      "unwrap: (321, 116) , reals: 491\n",
      "unwrap: (321, 116) , reals: 492\n",
      "unwrap: (321, 116) , reals: 493\n",
      "unwrap: (321, 116) , reals: 494\n",
      "unwrap: (321, 116) , reals: 495\n",
      "unwrap: (321, 124) , reals: 496\n",
      "unwrap: (321, 124) , reals: 497\n",
      "unwrap: (321, 124) , reals: 498\n",
      "unwrap: (321, 124) , reals: 499\n",
      "unwrap: (321, 124) , reals: 500\n",
      "unwrap: (321, 109) , reals: 501\n",
      "unwrap: (321, 109) , reals: 502\n",
      "unwrap: (321, 109) , reals: 503\n",
      "unwrap: (321, 109) , reals: 504\n",
      "unwrap: (321, 109) , reals: 505\n",
      "unwrap: (321, 114) , reals: 506\n",
      "unwrap: (321, 114) , reals: 507\n",
      "unwrap: (321, 114) , reals: 508\n",
      "unwrap: (321, 114) , reals: 509\n",
      "unwrap: (321, 114) , reals: 510\n",
      "unwrap: (321, 138) , reals: 511\n",
      "unwrap: (321, 138) , reals: 512\n",
      "unwrap: (321, 138) , reals: 513\n",
      "unwrap: (321, 138) , reals: 514\n",
      "unwrap: (321, 138) , reals: 515\n",
      "unwrap: (321, 107) , reals: 516\n",
      "unwrap: (321, 107) , reals: 517\n",
      "unwrap: (321, 107) , reals: 518\n",
      "unwrap: (321, 107) , reals: 519\n",
      "unwrap: (321, 107) , reals: 520\n",
      "unwrap: (321, 127) , reals: 521\n",
      "unwrap: (321, 127) , reals: 522\n",
      "unwrap: (321, 127) , reals: 523\n",
      "unwrap: (321, 127) , reals: 524\n",
      "unwrap: (321, 127) , reals: 525\n",
      "unwrap: (321, 141) , reals: 526\n",
      "unwrap: (321, 141) , reals: 527\n",
      "unwrap: (321, 141) , reals: 528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unwrap: (321, 141) , reals: 529\n",
      "unwrap: (321, 141) , reals: 530\n",
      "unwrap: (321, 130) , reals: 531\n",
      "unwrap: (321, 130) , reals: 532\n",
      "unwrap: (321, 130) , reals: 533\n",
      "unwrap: (321, 130) , reals: 534\n",
      "unwrap: (321, 130) , reals: 535\n",
      "unwrap: (321, 112) , reals: 536\n",
      "unwrap: (321, 112) , reals: 537\n",
      "unwrap: (321, 112) , reals: 538\n",
      "unwrap: (321, 112) , reals: 539\n",
      "unwrap: (321, 112) , reals: 540\n",
      "unwrap: (321, 105) , reals: 541\n",
      "unwrap: (321, 105) , reals: 542\n",
      "unwrap: (321, 105) , reals: 543\n",
      "unwrap: (321, 105) , reals: 544\n",
      "unwrap: (321, 105) , reals: 545\n"
     ]
    }
   ],
   "source": [
    "reals=[]\n",
    "imags=None\n",
    "\n",
    "labwin = 1\n",
    "for e, y_ in enumerate(y_hat):\n",
    "    \n",
    "    numFrames = int(opts.teNumframes[e])\n",
    "    \n",
    "    real_output = y_[:numFrames,:out_vec_len]\n",
    "    imag_output = y_[:numFrames,out_vec_len:]\n",
    "#     print(e, numFrames, real_output.shape, imag_output.shape)\n",
    "    \n",
    "    real_output_unwrap, _ = unwrapAugmentedTF_wAvg(real_output.T,labwin)\n",
    "    imag_output_unwrap, _ = unwrapAugmentedTF_wAvg(imag_output.T,labwin)\n",
    "    \n",
    "    print('unwrap:',real_output_unwrap.shape, end=' , ')\n",
    "    \n",
    "#     reals= np.array([list(real_output_unwrap)], dtype=object) if reals is None else np.append(reals,[list(real_output_unwrap)], axis=0)\n",
    "    reals.append(real_output_unwrap)\n",
    "    print('reals:',len(reals))\n",
    "#     imags.append(imag_output_unwrap)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('./dnn_models/test.out', reals[0], delimiter=',')   # X is an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_file(FILE_Name, *argv):\n",
    "    \n",
    "    saved_list=[]\n",
    "    name_list=[]\n",
    "    dic = dict()\n",
    "    \n",
    "    for arg in argv:\n",
    "        if isinstance(arg, str):\n",
    "            name_list.append(arg)\n",
    "        else:\n",
    "            saved_list.append(arg)\n",
    "        \n",
    "    for n in name_list:\n",
    "        print(type(n), type(saved_list.pop(0)))\n",
    "#         dic[n]=np.array(saved_list.pop(0),  dtype=np.object)\n",
    "        \n",
    "#     Param_Dict = np.core.records.fromarrays( saved_list, names=\",\".join(name_list))\n",
    "#     sio.savemat(FILE_Name, Param_Dict, format='5', long_field_names=True)\n",
    "#     sio.savemat(FILE_Name, dic)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "write_file(OUTPUT_FILE,'real_output_unwrap',reals,'imag_output_unwrap', imags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## HAVE to use OPS PARAMS ***********\n",
    "learning_rate = 0.001\n",
    "# training_epochs = 80\n",
    "# batch_size = 256\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## HAVE to use NET_STRUCTURE ***********\n",
    "n_input_dim = 195192.0\n",
    "n_input = 1230  # data input\n",
    "n_hidden_1 = 1024  # 1st layer number of neurons\n",
    "n_hidden_2 = 1024  # 2nd layer number of neurons\n",
    "n_hidden_3 = 1024  # 3rd layer number of neurons\n",
    "n_classes = (963 + 963)  # total classes (real+imaginary)\n",
    "\n",
    "# For checking\n",
    "# train_time = np.zeros(training_epochs)\n",
    "\n",
    "# validation_error = np.full((1), np.inf)\n",
    "# min_validation_error = np.full((1), np.inf)\n",
    "\n",
    "Best_Cost = - np.inf\n",
    "Best_Weight, Best_Bias = None, None\n",
    "Best_epoch = -1\n",
    "\n",
    "# For displaying\n",
    "PREVIOUS_10 = 10\n",
    "DIFF_THRESHOLD = 0.000001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected 3 layer Feed Forward Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, n_input])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, n_classes])\n",
    "\n",
    "\n",
    "# Xavier Initialization\n",
    "def weight_variable(shape, stddev=None, stddev_2=None):\n",
    "    if stddev is None:\n",
    "        initial = tf.truncated_normal(shape, stddev=np.sqrt(2.0 / sum(shape)))\n",
    "    elif stddev > 0.0:\n",
    "        if stddev_2 is not None:\n",
    "            r, c = shape\n",
    "            initial1 = tf.truncated_normal([r, c//2], stddev=stddev)\n",
    "            initial2 = tf.truncated_normal([r, c//2], stddev=stddev_2)\n",
    "            initial = tf.concat([initial1,initial2], axis=1)\n",
    "        else:\n",
    "            initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "\n",
    "    else:\n",
    "        initial = tf.constant(0.0, shape=shape)\n",
    "\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape, stddev=None, stddev_2=None):\n",
    "    # initial = tf.constant(0.1, shape=shape)\n",
    "    if stddev is None:\n",
    "        initial = tf.truncated_normal(shape, stddev=np.sqrt(1.0 / sum(shape)))\n",
    "    elif stddev > 0.0:\n",
    "        if stddev_2 is not None:\n",
    "            r, c = shape\n",
    "            initial1 = tf.truncated_normal([r, c//2], stddev=stddev)\n",
    "            initial2 = tf.truncated_normal([r, c//2], stddev=stddev_2)\n",
    "            initial = tf.concat([initial1,initial2], axis=1)\n",
    "        else:\n",
    "            initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "\n",
    "    else:\n",
    "        initial = tf.constant(0.0, shape=shape)\n",
    "\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# old way\n",
    "weights = {\n",
    "    'h1': weight_variable([n_input, n_hidden_1],0.001),\n",
    "    'h2': weight_variable([n_hidden_1, n_hidden_2],0.001),\n",
    "    'h3': weight_variable([n_hidden_2, n_hidden_3],0.001),\n",
    "    'out': weight_variable([n_hidden_3, n_classes],0.001,0.0)\n",
    "}\n",
    "biases = {\n",
    "    'b1': bias_variable([1, n_hidden_1],0.0),\n",
    "    'b2': bias_variable([1, n_hidden_2],0.0),\n",
    "    'b3': bias_variable([1, n_hidden_3],0.0),\n",
    "    'out': bias_variable([1, n_classes],0.001,0.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_NN(x):\n",
    "    layer_1 = tf.nn.relu(tf.matmul(x, weights['h1']) + biases['b1'])\n",
    "    layer_2 = tf.nn.relu(tf.matmul(layer_1, weights['h2']) + biases['b2'])\n",
    "    layer_3 = tf.nn.relu(tf.matmul(layer_2, weights['h3']) + biases['b3'])\n",
    "    out_layer = tf.matmul(layer_3, weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "def calc(x, y):\n",
    "    # Returns predictions and error\n",
    "    predictions = multilayer_NN(x)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    r, c = y.get_shape().as_list()\n",
    "    r = opts.sgd_batch_size\n",
    "    print('r:', type(r), r, ',c:', type(c), c)\n",
    "\n",
    "    # TRAIN: matlab\n",
    "    # cost1 = 0.5 * sum(sum((pred_real - label_real). ^ 2)) / num_sample;\n",
    "    # cost2 = 0.5 * sum(sum((pred_imag - label_imag). ^ 2)) / num_sample;\n",
    "    # cost = cost1 + cost2;\n",
    "    cost1 = tf.reduce_sum(tf.squared_difference(y[:, :c//2], predictions[:, :c//2]))\n",
    "    cost2 = tf.reduce_sum(tf.squared_difference(y[:, c//2:], predictions[:, c//2:]))\n",
    "    loss_t = 0.5*(cost1+cost2)/r\n",
    "    # mse = tf.losses.mean_squared_error(labels=y, predictions=predictions,weights=0.5)\n",
    "    # loss_t = tf.divide(tf.reduce_sum(mse), r)\n",
    "\n",
    "\n",
    "    # DEV: matlab\n",
    "    # dev_perfs = -mean(sum((dev_label_real - dev_netout1). ^ 2)) - mean(sum((dev_label_imag - dev_netout2). ^ 2));\n",
    "    mse_r = tf.reduce_sum(tf.squared_difference(y[:, :c // 2], predictions[:, :c // 2]), axis=0)\n",
    "    mse_i = tf.reduce_sum(tf.squared_difference(y[:, c // 2:], predictions[:, c // 2:]), axis=0)\n",
    "\n",
    "    loss_d = -tf.reduce_mean(mse_r)-tf.reduce_mean(mse_i)\n",
    "\n",
    "\n",
    "    return [predictions, loss_t, mse_r, mse_i, loss_d ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_file(best_weights, best_biases, DNN_NET_FILE):\n",
    "    W_1, W_2, W_3, W_4 = [np.array(best_weights['h1'], ndmin=2), np.array(best_weights['h2'], ndmin=2),\n",
    "                          np.array(best_weights['h3'], ndmin=2), np.array([], ndmin=2)]\n",
    "    W_1, W_2, W_3, W_4 = W_1.T, W_2.T, W_3.T, W_4\n",
    "\n",
    "    print('W_1: ', W_1.shape, 'W_2: ', W_2.shape, 'W_3: ', W_3.shape, 'W_4: ', W_4.shape)\n",
    "\n",
    "    b_1, b_2, b_3, b_4 = [np.array(best_biases['b1'], ndmin=2), np.array(best_biases['b2'], ndmin=2),\n",
    "                          np.array(best_biases['b3'], ndmin=2), np.array([], ndmin=2)]\n",
    "    b_1, b_2, b_3, b_4 = b_1.T, b_2.T, b_3.T, b_4\n",
    "\n",
    "    print('b_1: ', b_1.shape, 'b_2: ', b_2.shape, 'b_3: ', b_3.shape, 'b_4: ', b_4.shape)\n",
    "\n",
    "    Wo, bo = np.array(best_weights['out'], ndmin=2), np.array(best_biases['out'], ndmin=2)\n",
    "\n",
    "    Wo1_1, Wo1_2, Wo1_3, Wo1_4 = [np.array([], ndmin=2), np.array([], ndmin=2), np.array([], ndmin=2), Wo[:, :963].T]\n",
    "    bo1_1, bo1_2, bo1_3, bo1_4 = [np.array([], ndmin=2), np.array([], ndmin=2), np.array([], ndmin=2),\n",
    "                                  bo[:, :963].T]\n",
    "    # Wo1_1, Wo1_2, Wo1_3, Wo1_4 = [np.array([], ndmin=2), np.array([], ndmin=2), np.array([], ndmin=2), Wo[:963]]\n",
    "    # bo1_1, bo1_2, bo1_3, bo1_4 = [np.array([],ndmin=2), np.array([],ndmin=2), np.array([],ndmin=2),\n",
    "    #                               np.reshape(np.transpose(bo[:963]), (963, 1))]\n",
    "\n",
    "\n",
    "    Wo2_1, Wo2_2, Wo2_3, Wo2_4 = [np.array([], ndmin=2), np.array([], ndmin=2), np.array([], ndmin=2), Wo[:, 963:].T]\n",
    "    bo2_1, bo2_2, bo2_3, bo2_4 = [np.array([], ndmin=2), np.array([], ndmin=2), np.array([], ndmin=2),\n",
    "                                  bo[:, 963:].T]\n",
    "    # Wo2_1, Wo2_2, Wo2_3, Wo2_4 = [np.array([],ndmin=2), np.array([],ndmin=2), np.array([],ndmin=2), Wo[963:]]\n",
    "    # bo2_1, bo2_2, bo2_3, bo2_4 = [np.array([],ndmin=2), np.array([],ndmin=2), np.array([],ndmin=2),\n",
    "    #                               np.reshape(np.transpose(bo[963:]), (963, 1))]\n",
    "\n",
    "    print('Wo1_1: ', Wo1_1.shape, 'Wo1_2: ', Wo1_2.shape, 'Wo1_3: ', Wo1_3.shape, 'Wo1_4: ', Wo1_4.shape)\n",
    "    print('bo1_1: ', bo1_1.shape, 'bo1_2: ', bo1_2.shape, 'bo1_3: ', bo1_3.shape, 'bo1_4: ', bo1_4.shape)\n",
    "\n",
    "    print('Wo2_1: ', Wo2_1.shape, 'Wo2_2: ', Wo2_2.shape, 'Wo2_3: ', Wo2_3.shape, 'Wo2_4: ', Wo2_4.shape)\n",
    "    print('bo2_1: ', bo2_1.shape, 'bo2_2: ', bo2_2.shape, 'bo2_3: ', bo2_3.shape, 'bo2_4: ', bo2_4.shape)\n",
    "\n",
    "    # Param_Dict = {'W': np.transpose([W_1,W_2, W_3]), 'b':np.transpose([b_1,b_2, b_3]) }\n",
    "    # Param_Dict = {'W': { (W_1, W_2, (W_3)}, 'b': {(b_1), (b_2), (b_3)}}\n",
    "    Param_Dict = np.core.records.fromarrays(\n",
    "        [[W_1, W_2, W_3, W_4], [b_1, b_2, b_3, b_4], [Wo1_1, Wo1_2, Wo1_3, Wo1_4], [bo1_1, bo1_2, bo1_3, bo1_4],\n",
    "         [Wo2_1, Wo2_2, Wo2_3, Wo2_4], [bo2_1, bo2_2, bo2_3, bo2_4]], names='W,b,Wo1,bo1,Wo2,bo2')\n",
    "\n",
    "    # print(Param_Dict.shape, Param_Dict)\n",
    "    master_dict = {'struct_net': [Param_Dict]}\n",
    "\n",
    "    sio.savemat(DNN_NET_FILE, master_dict, format='5', long_field_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAIN ops\n",
    "y_p, loss_op, m_r, m_i, _ = calc(X, Y)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss=loss_op)\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Training cycle\n",
    "\n",
    "for epoch in range(opts.sgd_max_epoch):\n",
    "\n",
    "    s = time.time()\n",
    "    cost_sum = 0.0\n",
    "\n",
    "    ##### Create Train Batch, evaluate COST, Weight, Bias #####\n",
    "    ###########################################################\n",
    "    for batch_num, (batch_x, batch_y) in enumerate(opts.next_batch(opts.trData.shape[0], opts.sgd_batch_size)):\n",
    "\n",
    "        _, c, epoch_w, epoch_b  = sess.run([train_op, loss_op, weights, biases ],\n",
    "                                          feed_dict={X: batch_x, Y: batch_y})\n",
    "        cost_sum += c\n",
    "\n",
    "        if batch_num % 1000 == 0:\n",
    "            print('[T] - Epoch:', epoch, ', batch_num:', batch_num, \", Cost:\", c, \"Cost Sum:\", cost_sum)\n",
    "\n",
    "    print('[T] - Epoch:', epoch, \",Sum:\", cost_sum)\n",
    "\n",
    "\n",
    "    ################ Validation in whole batch ################\n",
    "    ###########################################################\n",
    "\n",
    "    avg_cost, sum_mse_r, sum_mse_i = 0.0, np.zeros(n_classes//2), np.zeros(n_classes//2)\n",
    "    ##### Create DEV Batch, evaluate COST, Weight, Bias #####\n",
    "    ###########################################################\n",
    "    for batch_num, (batch_x, batch_y) in enumerate(opts.next_batch(opts.cvData.shape[0], opts.sgd_batch_size, isTrainCycle=False)):\n",
    "\n",
    "        mse_r, mse_i = sess.run([m_r, m_i], feed_dict={X: batch_x, Y: batch_y})\n",
    "        # print(sum_mse_r.shape, mse_r.shape, mse_i.shape)\n",
    "        sum_mse_r += (mse_r)\n",
    "        sum_mse_i += (mse_i)\n",
    "\n",
    "    avg_cost = - np.mean(sum_mse_r) - np.mean(sum_mse_i)\n",
    "    # print('[D] - Epoch:', epoch, \", Mean Real:\", - np.mean(sum_mse_r), \", Mean Img:\" , - np.mean(sum_mse_i), \", Avg Cost:\", avg_cost)\n",
    "\n",
    "    print(\"[D] - Epoch:{0}, Avg Cost:{1:.5f}, Real(mean,var):({2:.5f},{3:.5f}), Img(mean,var):({4:.5f},{5:.5f})\".format( epoch,avg_cost, -np.mean(sum_mse_r),-np.var(sum_mse_r), -np.mean(sum_mse_i),\n",
    "          -np.var(sum_mse_i)) )\n",
    "\n",
    "    ####### Min validation error, update weights, bias #########\n",
    "    ############################################################\n",
    "\n",
    "\n",
    "    if avg_cost > Best_Cost:\n",
    "        Best_Cost = avg_cost\n",
    "        Best_Weight = epoch_w\n",
    "        Best_Bias = epoch_b\n",
    "        Best_epoch = epoch\n",
    "\n",
    "        print('***** [D] - Best Model at Epoch:', epoch, \", Avg Cost:\", avg_cost, '*****')\n",
    "\n",
    "\n",
    "    ######################  Write Model File ###################\n",
    "    ############################################################\n",
    "\n",
    "    print('[] - Elapsed Time: {0:.2f}(s), {1:.2f}(min)'.format( time.time()-s, (time.time()-s)/60 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training DONE !!!\n",
    "print(\"Optimization Finished!\")\n",
    "print('***** [-] - Best Model at Epoch:', Best_epoch, \", Best Val Cost:\", Best_Cost, '*****')\n",
    "write_file(Best_Weight, Best_Bias, DNN_NET_FILE)\n",
    "print(\" File Write complete\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
