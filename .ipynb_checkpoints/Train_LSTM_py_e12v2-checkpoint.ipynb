{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LSTM Series (working)\n",
    "\n",
    "** - Simple LSTM  **\n",
    "\n",
    "** - Train and Dev different loss functions **\n",
    "\n",
    "** - Adam Optimizer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, TimeDistributed\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,Callback\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configuration to control GPU use\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.33\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read parameters from .mat files\n",
    "save in Opt object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_VERSION = \"_e10v5\"\n",
    "Test_Data_VERSION = '_e04v2_nf'\n",
    "\n",
    "Code_VERSION = \"_e12v2\"\n",
    "\n",
    "Param_VERSION = '_e12v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DNN_DATA_FILE = \"./dnn_models/DNN_datas\"+ Data_VERSION+\".mat\"\n",
    "DNN_TEST_FILE = \"./dnn_models/Test_datas\"+Test_Data_VERSION+\".mat\"\n",
    "\n",
    "PARAM_FILE = \"./dnn_models/DNN_params\"+Param_VERSION+\".mat\"\n",
    "# PARAM_FILE = \"./dnn_models/DNN_params\"+Data_VERSION+\".mat\"\n",
    "\n",
    "TrainData_FILE = \"./dnn_models/Train_datas.mat\"\n",
    "DevData_FILE = \"./dnn_models/CrossValidation_datas.mat\"\n",
    "TestData_FILE = \"./dnn_models/Test_datas.mat\"\n",
    "\n",
    "\n",
    "# Best model, after adding 1st dense layer\n",
    "MODEL_FILE = \"./dnn_models/lstm_weights\"+ Code_VERSION+\"_{epoch:02d}.h5\"\n",
    "\n",
    "#dummy save file\n",
    "SAVE_MODEL_FILE = \"./dnn_models/lstm_py_model\"+ Code_VERSION+\".h5\"\n",
    "\n",
    "# estimated real+imag for test dataset\n",
    "OUTPUT_FILE = \"./dnn_models/Real_Imag\"+Code_VERSION+\".mat\"\n",
    "\n",
    "LOG_FILE = \"./dnn_models/Log\"+Code_VERSION+\".txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files saved by Matlab reading class. Data, Parameters are read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Opts:\n",
    "#     opts_dict = dict()\n",
    "\n",
    "    def __init__(self, FILE_PARA, FILE_DATA=\"\", FILE_TEST=\"\"):\n",
    "        \n",
    "        # Basic parameters\n",
    "        with h5py.File(FILE_PARA, 'r') as f:\n",
    "            key_list = list(f.keys())\n",
    "            print('Opt keys:')\n",
    "\n",
    "            for e,(k, v) in enumerate(f['opts'].items()):\n",
    "\n",
    "                print(\"{0}->{1},\".format(e,k), end=\"\")\n",
    "\n",
    "                if k == 'ARMA_order':\n",
    "                    self.ARMA_order = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.ARMA_order\n",
    "                elif k == 'ada_grad_eps':\n",
    "                    self.ada_grad_eps = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.ada_grad_eps\n",
    "                elif k == 'ada_sgd_scale':\n",
    "                    self.ada_sgd_scale = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.ada_sgd_scale\n",
    "                elif k == 'change_momentum_point':\n",
    "                    self.change_momentum_point = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.change_momentum_point\n",
    "                elif k == 'cost_function':\n",
    "                    self.cost_function = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.cost_function += chr(c[0])\n",
    "\n",
    "#                     self.opts_dict[k] = self.cost_function\n",
    "\n",
    "                elif k == 'cv_interval':\n",
    "                    self.cv_interval = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.cv_interval\n",
    "                elif k == 'dim_input':\n",
    "                    self.dim_input = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.dim_input\n",
    "                    print(\"(\",k,\"=\",self.dim_input,\")\",end=\" \")\n",
    "                elif k == 'dim_output':\n",
    "                    self.dim_output = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.dim_output\n",
    "                    print(\"(\",k,\"=\",self.dim_output,\")\",end=\" \")\n",
    "                elif k == 'drop_ratio':\n",
    "                    self.drop_ratio = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.drop_ratio\n",
    "                elif k == 'eval_on_gpu':\n",
    "                    self.eval_on_gpu = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.eval_on_gpu\n",
    "                elif k == 'final_momentum':\n",
    "                    self.final_momentum = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.final_momentum\n",
    "                elif k == 'hid_struct':\n",
    "                    self.hid_struct = np.array(v)\n",
    "#                     self.opts_dict[k] = self.hid_struct\n",
    "                elif k == 'initial_momentum':\n",
    "                    self.initial_momentum = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.initial_momentum\n",
    "                elif k == 'isDropout':\n",
    "                    self.isDropout = 0\n",
    "#                     self.opts_dict[k] = self.isDropout\n",
    "                elif k == 'isDropoutInput':\n",
    "                    self.isDropoutInput = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isDropoutInput\n",
    "                elif k == 'isGPU':\n",
    "                    self.isGPU = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isGPU\n",
    "                elif k == 'isNormalize':\n",
    "                    self.isNormalize = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isNormalize\n",
    "                elif k == 'isPretrain':\n",
    "                    self.isPretrain = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isPretrain\n",
    "                elif k == 'learner':\n",
    "                    self.learner = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.learner += chr(c[0])\n",
    "#                     self.opts_dict[k] = self.learner\n",
    "\n",
    "                elif k == 'net_struct':\n",
    "                    self.net_struct = np.array(v)\n",
    "#                     for n_s in np.array(v):\n",
    "#                         print('Opts Net Stuct:',n_s[0])\n",
    "#                     self.opts_dict[k] = self.net_struct\n",
    "                elif k == 'rbm_batch_size':\n",
    "                    self.rbm_batch_size = int(np.array(v)[0][0])\n",
    "                    print(\"(self.rbm_batch_size=\",self.rbm_batch_size,\")\",end=\" \")\n",
    "#                     self.opts_dict[k] = self.rbm_batch_size\n",
    "                elif k == 'rbm_learn_rate_binary':\n",
    "                    self.rbm_learn_rate_binary = np.array(v)\n",
    "#                     self.opts_dict[k] = self.rbm_learn_rate_binary\n",
    "                elif k == 'rbm_learn_rate_real':\n",
    "                    self.rbm_learn_rate_real = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.rbm_learn_rate_real\n",
    "                elif k == 'rbm_max_epoch':\n",
    "                    self.rbm_max_epoch = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.rbm_max_epoch\n",
    "                elif k == 'save_on_fly':\n",
    "                    self.save_on_fly = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.save_on_fly\n",
    "                elif k == 'sgd_batch_size':\n",
    "                    self.sgd_batch_size = int(np.array(v)[0][0]) # BATCH_SIZE for training net\n",
    "                    print(\"(self.sgd_batch_size:\",self.sgd_batch_size,\")\",end=\" \")\n",
    "#                     self.opts_dict[k] = self.sgd_batch_size\n",
    "                elif k == 'sgd_learn_rate':\n",
    "                    self.sgd_learn_rate = np.array(v)\n",
    "#                     self.opts_dict[k] = self.sgd_learn_rate\n",
    "                elif k == 'sgd_max_epoch':\n",
    "                    self.sgd_max_epoch = int(np.array(v)[0][0])\n",
    "                    # self.opts_dict[k] = self.sgd_max_epoch\n",
    "                elif k == 'split_tanh1_c1':\n",
    "                    self.split_tanh1_c1 = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.split_tanh1_c1\n",
    "                elif k == 'split_tanh1_c2':\n",
    "                    self.split_tanh1_c2 = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.split_tanh1_c2\n",
    "                elif k == 'unit_type_hidden':\n",
    "                    self.unit_type_hidden = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.unit_type_hidden += chr(c[0])\n",
    "\n",
    "                elif k == 'unit_type_output':\n",
    "                    self.unit_type_output = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.unit_type_output += chr(c[0])\n",
    "\n",
    "                        \n",
    "\n",
    "    # Read different data files (Train, Dev, Test)\n",
    "    def read_data(self, FILE_NAME, DATA_TYPE):\n",
    "        print(FILE_NAME, os.path.isfile(FILE_NAME))\n",
    "\n",
    "        with h5py.File(FILE_NAME, 'r') as f:\n",
    "            # print('\\n\\nFile name <{0}>\\nOpt h5py keys (Total {1}):'.format(FILE_TEST,len(f.keys())) )\n",
    "\n",
    "            for k, v in f.items():\n",
    "                if DATA_TYPE.lower() == 'train':\n",
    "                    # Features (input)\n",
    "                    if k == 'trData':\n",
    "                        self.trData = np.transpose(np.array(v))\n",
    "                    elif k == 'trLabel_r':\n",
    "                        self.trLabel_r = np.transpose(np.array(v))\n",
    "                    elif k == 'trLabel_i':\n",
    "                        self.trLabel_i = np.transpose(np.array(v))\n",
    "                    elif k == 'numframes':\n",
    "                        self.trNumframes = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_r':\n",
    "                        self.trCleanSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_i':\n",
    "                        self.trCleanSpec_i = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_r':\n",
    "                        self.trMixtureSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_i':\n",
    "                        self.trMixtureSpec_i = np.transpose(np.array(v))\n",
    "                \n",
    "                elif DATA_TYPE.lower() == 'dev':\n",
    "                    # Features (input)\n",
    "                    if k == 'cvData':\n",
    "                        self.cvData = np.transpose(np.array(v))\n",
    "                    elif k == 'cvLabel_r':\n",
    "                        self.cvLabel_r = np.transpose(np.array(v))\n",
    "                    elif k == 'cvLabel_i':\n",
    "                        self.cvLabel_i = np.transpose(np.array(v))\n",
    "                    elif k == 'numframes':\n",
    "                        self.cvNumframes = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_r':\n",
    "                        self.cvCleanSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_i':\n",
    "                        self.cvCleanSpec_i = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_r':\n",
    "                        self.cvMixtureSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_i':\n",
    "                        self.cvMixtureSpec_i = np.transpose(np.array(v))\n",
    "            \n",
    "                elif DATA_TYPE.lower() == 'test':\n",
    "                    # Features (input)\n",
    "                    if k == 'teData':\n",
    "                        self.teData = np.transpose(np.array(v))\n",
    "                    elif k == 'teLabel_r':\n",
    "                        self.teLabel_r = np.transpose(np.array(v))\n",
    "                    elif k == 'teLabel_i':\n",
    "                        self.teLabel_i = np.transpose(np.array(v))\n",
    "                    elif k == 'numframes':\n",
    "                        self.teNumframes = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_r':\n",
    "                        self.teCleanSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_i':\n",
    "                        self.teCleanSpec_i = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_r':\n",
    "                        self.teMixtureSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_i':\n",
    "                        self.teMixtureSpec_i = np.transpose(np.array(v))\n",
    "            \n",
    "            # Display statistics\n",
    "            if DATA_TYPE.lower() == 'train':\n",
    "                self.trLabel = np.concatenate((self.trLabel_r, self.trLabel_i), axis=1)\n",
    "#                 self.display_stat(DATA_TYPE=\"train\")\n",
    "                \n",
    "            elif DATA_TYPE.lower() == 'dev':\n",
    "                self.cvLabel = np.concatenate((self.cvLabel_r, self.cvLabel_i), axis=1)\n",
    "#                 self.display_stat(DATA_TYPE=\"dev\")\n",
    "                \n",
    "            elif DATA_TYPE.lower() == 'test':\n",
    "                self.teLabel = np.concatenate((self.teLabel_r, self.teLabel_i), axis=1)\n",
    "#                 self.display_stat(DATA_TYPE=\"test\")\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Display the simple statistics of Data (train, dev, test)\n",
    "    def display_stat(self, DATA_TYPE):\n",
    "        if DATA_TYPE.lower() == 'train':\n",
    "            print(\"\\nSummary->[TRAIN DATA]\")\n",
    "            print(\"trNumframes.shape=\", self.trNumframes.shape)\n",
    "            \n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trData)\n",
    "            print(\"trData.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trLabel_r)\n",
    "            print(\"trLabel_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trLabel_i)\n",
    "            print(\"trLabel_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trLabel)\n",
    "            print(\"trLabel.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "#             shp, m, v, s, mn, mx = self.data_stat(self.trCleanSpec_r)\n",
    "#             print(\"trCleanSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "#                               format(shp, m, v, s, mn, mx) )\n",
    "#             shp, m, v, s, mn, mx = self.data_stat(self.trCleanSpec_i)\n",
    "#             print(\"trCleanSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "#                               format(shp, m, v, s, mn, mx) )\n",
    "#             shp, m, v, s, mn, mx = self.data_stat(self.trMixtureSpec_r)\n",
    "#             print(\"trMixtureSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "#                               format(shp, m, v, s, mn, mx) )\n",
    "#             shp, m, v, s, mn, mx = self.data_stat(self.trMixtureSpec_i)\n",
    "#             print(\"trMixtureSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "#                               format(shp, m, v, s, mn, mx) )\n",
    "            \n",
    "        elif DATA_TYPE.lower() == 'dev':\n",
    "            print(\"\\nSummary->[DEV DATA]\")\n",
    "            print(\"cvNumframes.shape=\", self.cvNumframes.shape)\n",
    "            \n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvData)\n",
    "            print(\"cvData.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f}-{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvLabel_r)\n",
    "            print(\"cvLabel_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvLabel_i)\n",
    "            print(\"cvLabel_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvLabel)\n",
    "            print(\"cvLabel.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvCleanSpec_r)\n",
    "            print(\"cvCleanSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvCleanSpec_i)\n",
    "            print(\"cvCleanSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvMixtureSpec_r)\n",
    "            print(\"cvMixtureSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvMixtureSpec_i)\n",
    "            print(\"cvMixtureSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "\n",
    "            \n",
    "        elif DATA_TYPE.lower() == 'test':\n",
    "            print(\"\\nSummary->[TEST DATA]\")\n",
    "            print(\"teNumframes.shape=\", self.teNumframes.shape)\n",
    "            \n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teData)\n",
    "            print(\"teData.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teLabel_r)\n",
    "            print(\"teLabel_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teLabel_i)\n",
    "            print(\"teLabel_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teLabel)\n",
    "            print(\"teLabel.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teCleanSpec_r)\n",
    "            print(\"teCleanSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teCleanSpec_i)\n",
    "            print(\"teCleanSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teMixtureSpec_r)\n",
    "            print(\"teMixtureSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teMixtureSpec_i)\n",
    "            print(\"teMixtureSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "                        \n",
    "    # Helper function for display, returns actual values\n",
    "    def data_stat(self, data):\n",
    "        return data.shape,np.mean(data),np.var(data),np.std(data),np.amin(data),np.amax(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt keys:\n",
      "0->ARMA_order,1->ada_grad_eps,2->ada_sgd_scale,3->change_momentum_point,4->cost_function,5->cv_interval,6->dim_input,( dim_input = 1230 ) 7->dim_output,( dim_output = 963 ) 8->drop_ratio,9->eval_on_gpu,10->final_momentum,11->hid_struct,12->initial_momentum,13->isDropout,14->isDropoutInput,15->isGPU,16->isNormalize,17->isPretrain,18->learner,19->net_struct,20->rbm_batch_size,(self.rbm_batch_size= 1024 ) 21->rbm_learn_rate_binary,22->rbm_learn_rate_real,23->rbm_max_epoch,24->save_on_fly,25->sgd_batch_size,(self.sgd_batch_size: 1024 ) 26->sgd_learn_rate,27->sgd_max_epoch,28->split_tanh1_c1,29->split_tanh1_c2,30->tr_mu,31->tr_std,32->unit_type_hidden,33->unit_type_output,"
     ]
    }
   ],
   "source": [
    "opts = Opts(PARAM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dnn_models/Train_datas.mat True\n"
     ]
    }
   ],
   "source": [
    "opts.read_data(TrainData_FILE, DATA_TYPE=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dnn_models/CrossValidation_datas.mat True\n"
     ]
    }
   ],
   "source": [
    "opts.read_data(DevData_FILE, DATA_TYPE=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dnn_models/Test_datas.mat True\n"
     ]
    }
   ],
   "source": [
    "opts.read_data(TestData_FILE, DATA_TYPE=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0134557 , -0.00549853, -0.00025761, -0.0040397 ,  0.00147402],\n",
       "       [-0.04657207,  0.03029321,  0.00073667, -0.02018796,  0.02272554],\n",
       "       [ 0.0426428 , -0.03104717,  0.01431777, -0.0314163 ,  0.06807565],\n",
       "       [-0.09032005,  0.02352479,  0.00491432,  0.04725359, -0.07824395],\n",
       "       [ 0.03109347,  0.00310555, -0.03451523,  0.0277781 , -0.00758577]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts.teCleanSpec_i[789:794, 89:94]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For RNN style 3D batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare3D_list(opts, CYCLE):\n",
    "        # TRAIN: total_num_samples = self.trData.shape[0] = 195192\n",
    "        # DEV: total_num_samples = self.trData.shape[0] = 44961\n",
    "\n",
    "        feat_vec_len = opts.dim_input # 1230\n",
    "        out_vec_len = opts.dim_output #963\n",
    "        \n",
    "        if CYCLE.lower()=='train':\n",
    "            data = opts.trData\n",
    "            label_r = opts.trLabel_r\n",
    "            label_i = opts.trLabel_i\n",
    "            numframes = opts.trNumframes\n",
    "#             mix_spec_r = opts.trMixtureSpec_r\n",
    "#             mix_spec_i = opts.trMixtureSpec_i\n",
    "            \n",
    "        elif CYCLE.lower()=='dev':\n",
    "            data = opts.cvData\n",
    "            label_r = opts.cvLabel_r\n",
    "            label_i = opts.cvLabel_i\n",
    "            numframes = opts.cvNumframes\n",
    "#             mix_spec_r = opts.cvMixtureSpec_r\n",
    "#             mix_spec_i = opts.cvMixtureSpec_i\n",
    "            \n",
    "        elif CYCLE.lower()=='test':\n",
    "            data = opts.teData\n",
    "            label_r = opts.teLabel_r\n",
    "            label_i = opts.teLabel_i\n",
    "            numframes = opts.teNumframes\n",
    "#             mix_spec_r = opts.teMixtureSpec_r\n",
    "#             mix_spec_i = opts.teMixtureSpec_i\n",
    "            \n",
    "\n",
    "        data3D, label3D_r, label3D_i = [], [], []\n",
    "        numframes = np.cumsum(numframes)\n",
    "        \n",
    "        for e, frames in enumerate(numframes):\n",
    "            frames= int(frames)\n",
    "            pre_frames= int(numframes[e-1])\n",
    "            \n",
    "            d = data[:frames] if len(data3D)==0 else data[pre_frames:frames]\n",
    "            r = label_r[:frames] if len(label3D_r)==0 else label_r[pre_frames:frames]\n",
    "            i = label_i[:frames] if len(label3D_i)==0 else label_i[pre_frames:frames]\n",
    "            \n",
    "            data3D.append( d )\n",
    "            label3D_r.append( r )\n",
    "            label3D_i.append( i )\n",
    "            \n",
    "#             print('d.shape=',d.shape, ', r.shape=',r.shape, ', i.shape=',i.shape)\n",
    "        \n",
    "        return data3D, label3D_r, label3D_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch_rnn(opts, batch_size, CYCLE, maxlen=185):\n",
    "    # TRAIN: total_num_samples = self.trData.shape[0] = 1951920\n",
    "    # DEV: total_num_samples = self.trData.shape[0] = 449610\n",
    "\n",
    "    feat_vec_len = opts.dim_input #1230\n",
    "    out_vec_len = opts.dim_output #963\n",
    "\n",
    "\n",
    "    if CYCLE.lower()=='train':\n",
    "        selected_indics = np.arange(len(opts.trNumframes))\n",
    "        data3D, label3D_r, label3D_i = prepare3D_list(opts,CYCLE)\n",
    "        np.random.shuffle(selected_indics)\n",
    "\n",
    "    elif CYCLE.lower()=='dev':\n",
    "        selected_indics = np.arange(len(opts.cvNumframes))\n",
    "        data3D, label3D_r, label3D_i = prepare3D_list(opts,CYCLE)\n",
    "        np.random.shuffle(selected_indics)\n",
    "\n",
    "    elif CYCLE.lower()=='test':\n",
    "        selected_indics = np.arange(len(opts.teNumframes))\n",
    "        data3D, label3D_r, label3D_i = prepare3D_list(opts, CYCLE)\n",
    "        si = selected_indics\n",
    "\n",
    "\n",
    "    f = 0\n",
    "    while (f*batch_size) < len(selected_indics):\n",
    "\n",
    "        if CYCLE.lower()=='train'or CYCLE.lower()=='dev':\n",
    "            if (f+1)*batch_size < len(selected_indics):\n",
    "                si = selected_indics[(f*batch_size):((f+1)*batch_size)]\n",
    "            else:\n",
    "                si = selected_indics[(f*batch_size):]\n",
    "                \n",
    "        opts.batch_ids = si;\n",
    "            \n",
    "        x, y = None, None\n",
    "        for indx in si[:len(si)//10]:\n",
    "            d = data3D[indx]\n",
    "            d = np.concatenate( (d, np.zeros((maxlen-d.shape[0],feat_vec_len))),axis=0 )\n",
    "            d = np.expand_dims(d, axis=0)\n",
    "\n",
    "            l = np.concatenate((label3D_r[indx], label3D_i[indx]), axis=1)\n",
    "            l = np.concatenate( (l, np.zeros((maxlen-l.shape[0],out_vec_len*2))),axis=0 )\n",
    "            l = np.expand_dims(l, axis=0)\n",
    "\n",
    "            x = d if x is None else np.concatenate( (x,d),axis=0 )\n",
    "            y = l if y is None else np.concatenate( (y,l),axis=0 )\n",
    "            \n",
    "            \n",
    "        f += 1\n",
    "\n",
    "        if CYCLE.lower()=='test':\n",
    "            with open(LOG_FILE,'a+') as log:\n",
    "                log.write('{5} {0}-CYCLE, batch_id:{1}, #{2}samples, x.shape:{3}, y.shape:{4}\\n'.\n",
    "                    format(CYCLE, f, len(si), x.shape, y.shape, strftime(\"%Y-%m-%d %H:%M:%S\",gmtime())))\n",
    "                \n",
    "            print(x.shape, y.shape)\n",
    "            yield x, y\n",
    "            \n",
    "            break\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if x.shape[0]<batch_size:\n",
    "                x = np.concatenate( (x, np.zeros((batch_size-x.shape[0],maxlen,feat_vec_len))), axis=0)\n",
    "                y = np.concatenate( (y, np.zeros((batch_size-y.shape[0],maxlen,out_vec_len*2))), axis=0)\n",
    "\n",
    "            with open(LOG_FILE,'a+') as log:\n",
    "                log.write('{5} {0}-CYCLE, batch_id:{1:0002}, #{2}samples, x.shape:{3}, y.shape:{4}\\n'.\n",
    "                        format(CYCLE, f, len(si), x.shape, y.shape, strftime(\"%Y-%m-%d %H:%M:%S\",gmtime())))\n",
    "            yield x,y\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for e,[x,y] in enumerate(next_batch_rnn(opts,50,CYCLE='train')):\n",
    "    print(e,end=\" \")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for e,[x,y] in enumerate(next_batch_rnn(opts,batch_size = 5,CYCLE='dev')):\n",
    "    print('batch id', e, opts.batch_ids, opts.cvNumframes[opts.batch_ids])\n",
    "    if e == 10:\n",
    "        break\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(opts.trNumframes)//256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opts.si.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unwrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unwrapAugmentedTF_wAvg(impt_mag,num_per_side,unwrap_mag=None):\n",
    "    \n",
    "#     Description: Unwrap the augmented time-frequency (T-F) representation and compute the average.\n",
    "\n",
    "#     Input:\n",
    "#         impt_mag: wrapped T-F representation with dimensions (2*T+1)*d x m\n",
    "#         T: number of frames to left and right of each frame used to augmented T-F representation\n",
    "#     Output:\n",
    "#         unwrap_avgmag: unwrapped and averaged T-F representation with dimensions d x m\n",
    "#         unwrap_mag: unwrapped T-F representation with dimensions d x (2*T+1) x m\n",
    "#\n",
    "        \n",
    "        sliding_window_len       = 2*num_per_side + 1\n",
    "        (numWrapFreqs,numFrames) = impt_mag.shape\n",
    "        numFreqs                 = numWrapFreqs//sliding_window_len\n",
    "        unwrap_avgmag            = np.zeros((numFreqs,numFrames))\n",
    "        \n",
    "        if num_per_side > 0:\n",
    "            if unwrap_mag is None:\n",
    "            \n",
    "                unwrap_mag        = np.zeros((numFreqs,sliding_window_len+1,numFrames))\n",
    "                curr_ind_location = np.ones((numFrames,1),dtype=int)\n",
    "                \n",
    "\n",
    "                for frameNum in range(numFrames):\n",
    "                    \n",
    "                    # Get the indices for the frames used in this augmented matrix\n",
    "                    frame_inds=[]\n",
    "                    for inds in range(frameNum-num_per_side,frameNum+num_per_side+1):\n",
    "                        if inds<0:\n",
    "                            frame_inds.append(0)\n",
    "                        elif inds>=numFrames:\n",
    "                            frame_inds.append(numFrames-1)\n",
    "                        else:\n",
    "                            frame_inds.append(inds)\n",
    "                    \n",
    "                    # Unwrap the data for this frame\n",
    "                    slid_win_data = np.reshape( impt_mag[:,frameNum], (numFreqs,sliding_window_len)) #Size d x (2*T + 1)\n",
    "                    \n",
    "                    for ind_num in range(len(frame_inds)):\n",
    "\n",
    "                        slid = np.array(slid_win_data[:,ind_num], ndmin=2).T\n",
    "                        unwrap_mag[:,curr_ind_location[frame_inds[ind_num]], frame_inds[ind_num]] = slid \n",
    "                        \n",
    "                        # Update counters\n",
    "                        curr_ind_location[frame_inds[ind_num]] = curr_ind_location[frame_inds[ind_num]] + 1\n",
    "\n",
    "\n",
    "            temp = np.zeros((numFreqs,sliding_window_len+1))\n",
    "            \n",
    "            for frameNum in range(numFrames):\n",
    "#                 print(unwrap_mag.shape)\n",
    "                \n",
    "                unwrap_avgmag[:,frameNum] = np.mean(unwrap_mag[:,:,frameNum],axis=1)\n",
    "#                 print(unwrap_mag.shape)\n",
    "#                 return\n",
    "\n",
    "            \n",
    "        else:\n",
    "            unwrap_avgmag = impt_mag;\n",
    "            unwrap_mag = 0;\n",
    "            \n",
    "        return unwrap_avgmag,unwrap_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Opts' object has no attribute 'si'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0cfafb0fc30e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Opts' object has no attribute 'si'"
     ]
    }
   ],
   "source": [
    "def estimate(opts, real_output, imag_output, spec_r, spec_i):\n",
    "    \n",
    "    mix_stft = spec_r + 1j*spec_i\n",
    "    complex_irmmask_mat = real_output + 1j*imag_output\n",
    "\n",
    "    if not opts.labwin:\n",
    "        estimate_mat = np.multiply(complex_irmmask_mat,mix_stft);\n",
    "    else\n",
    "        real_output_unwrap = unwrapAugmentedTF_wAvg(np.transpose(real_output), opts.labwin)\n",
    "        imag_output_unwrap = unwrapAugmentedTF_wAvg(np.transpose(imag_output), opts.labwin)\n",
    "        \n",
    "        complex_irmmask_mat    = real_output_unwrap + 1j*imag_output_unwrap\n",
    "        estimate_mat = np.multiply(complex_irmmask_mat,mix_stft)\n",
    "        \n",
    "    return estimate_mat\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss_train(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    numframes = opts.trNumframes[opts.batch_ids]\n",
    "    numframes = [int(f[0]) for f in numframes]\n",
    "    \n",
    "    cost_r = K.variable(value=0)\n",
    "    cost_i = K.variable(value=0)\n",
    "    for n in numframes:\n",
    "        cost_r += K.sum(K.square(yTrue[:n, :(c//2)]- yPred[:n, :(c//2)]))\n",
    "        cost_i += K.sum(K.square(yTrue[:n, (c//2):]- yPred[:n, (c//2):]))\n",
    "\n",
    "#     cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "#     cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss_val(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    numframes = opts.cvNumframes[opts.batch_ids]\n",
    "    numframes = [int(f[0]) for f in numframes]\n",
    "    \n",
    "    cost_r = K.variable(value=0)\n",
    "    cost_i = K.variable(value=0)\n",
    "    for n in numframes:\n",
    "        \n",
    "        \n",
    "        \n",
    "        cost_r += K.sum(K.square(yTrue[:n, :(c//2)]- yPred[:n, :(c//2)]))\n",
    "        cost_i += K.sum(K.square(yTrue[:n, (c//2):]- yPred[:n, (c//2):]))\n",
    "\n",
    "#     cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "#     cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss_test(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    numframes = opts.teNumframes[opts.batch_ids]\n",
    "    numframes = [int(f[0]) for f in numframes]\n",
    "    \n",
    "    cost_r = K.variable(value=0)\n",
    "    cost_i = K.variable(value=0)\n",
    "    for n in numframes:\n",
    "        cost_r += K.sum(K.square(yTrue[:n, :(c//2)]- yPred[:n, :(c//2)]))\n",
    "        cost_i += K.sum(K.square(yTrue[:n, (c//2):]- yPred[:n, (c//2):]))\n",
    "\n",
    "#     cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "#     cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossFunctionCallback(Callback):\n",
    "    def __init__(self, model, opts):\n",
    "        self.model = model\n",
    "        self.opts = opts\n",
    "        pass\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        self.model.loss = customLoss_train\n",
    "        pass\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.model.loss = customLoss_val\n",
    "        pass\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        # print('-> on_train_end=',self.params)\n",
    "        self.model.loss = customLoss_test\n",
    "        pass\n",
    "        \n",
    " \n",
    "    def on_train_begin(self, logs={}):\n",
    "        pass\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        pass\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### RNN variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Max_RNN = 256\n",
    "\n",
    "# feat_vec_len = 1230\n",
    "# out_vec_len = 963\n",
    "\n",
    "# epochs = 50\n",
    "# train_size = 15000\n",
    "# dev_size = 3300\n",
    "# batch_size = 256\n",
    "\n",
    "\n",
    "batch_size = 25 #opts.sgd_batch_size\n",
    "epochs = 50\n",
    "\n",
    "Max_RNN = 256\n",
    "\n",
    "'''\n",
    "n_train, n_train_dim = <number of samples for training, input dimentions>, final will be (1951920, 1230)\n",
    "n_dev, n_dev_dim = <number of samples for development, input dimentions>, final will be (449610, 1230)\n",
    "n_test, n_test_dim =<number of samples for testing, input dimentions>, final will be (72440, 1230)\n",
    "\n",
    "'''\n",
    "n_train, n_train_dim = (195192, 1230) # opts.trData.shape = (1951920, 1230)\n",
    "n_dev, n_dev_dim = (44961, 1230) # opts.cvData.shape =(449610, 1230)\n",
    "n_test, n_test_dim = (72440, 1230) # opts.teData.shape =(72440, 1230)\n",
    "\n",
    "n_train_files = 1500 #15000\n",
    "n_dev_files = 330 # 3300\n",
    "n_test_files = 545\n",
    "\n",
    "n_classes = (963 + 963)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 1\n",
    "single bidirectional GRU layer\n",
    "\n",
    "real+img (963+963)=1926-d output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 256, 256)          1522688   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256, 1926)         494982    \n",
      "=================================================================\n",
      "Total params: 2,017,670\n",
      "Trainable params: 2,017,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 141s - loss: 11027.8529 - acc: 0.0460 - mean_squared_error: 0.0089 - mean_absolute_error: 0.0275 - mean_absolute_percentage_error: 1107418.3633 - cosine_proximity: -4.9032e-05 - val_loss: 11444.4234 - val_acc: 0.0087 - val_mean_squared_error: 0.0093 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 630035.2405 - val_cosine_proximity: -5.8133e-05\n",
      "Epoch 2/5\n",
      "123/300 [===========>..................] - ETA: 76s - loss: 10507.1139 - acc: 0.0370 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0235 - mean_absolute_percentage_error: 555171.7589 - cosine_proximity: -6.0186e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-831bca04fd4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train_files\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_dev_files\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     verbose=1, callbacks=callbacks)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_MODEL_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1108\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1889\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(Max_RNN, return_sequences=True, input_shape=(Max_RNN,opts.dim_input)))\n",
    "# model.add(Bidirectional(LSTM(Max_RNN, return_sequences=True), input_shape=(Max_RNN,feat_vec_len)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Bidirectional(GRU(Max_RNN, return_sequences=True, stateful=True)))\n",
    "model.add(Dense(n_classes, activation='linear'))\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_acc', patience=2, min_delta=1e-6, verbose=1, mode='auto'), \n",
    "             ModelCheckpoint(filepath= MODEL_FILE, monitor='val_acc', save_best_only=True),\n",
    "            LossFunctionCallback(model,opts)]\n",
    "\n",
    "\n",
    "model.compile(loss = customLoss_train, optimizer = 'adam', metrics = ['accuracy','mse', 'mae', 'mape', 'cosine'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit_generator(next_batch_rnn(opts,batch_size,maxlen=Max_RNN,CYCLE='train'), \n",
    "                    validation_data=next_batch_rnn(opts,batch_size,maxlen=Max_RNN,CYCLE='dev'),\n",
    "                    epochs=epochs, steps_per_epoch=n_train_files//batch_size, \n",
    "                    validation_steps=n_dev_files//batch_size, \n",
    "                    verbose=1, callbacks=callbacks)\n",
    "\n",
    "model.save(SAVE_MODEL_FILE)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-674b27952856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot metrics                                                       \n",
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.suptitle(\"Train result\")\n",
    "\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "# plt.plot(history.history['val_mean_absolute_percentage_error'])\n",
    "# plt.plot(history.history['val_cosine_proximity'])\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['acc'])\n",
    "\n",
    "# plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    "# plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "# plt.plot(history.history['cosine_proximity'])\n",
    "                                                           \n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"numbers\")\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 256, 1230) (54, 256, 1926)\n",
      "(54, 256, 1230) (54, 256, 1926)\n"
     ]
    }
   ],
   "source": [
    "for x,y in next_batch_rnn(opts, batch_size, CYCLE='test', maxlen=Max_RNN):\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -9.77755785e-02,  -2.13767529e-01,  -3.35417807e-01, ...,\n",
       "           5.77727318e-01,   6.15890980e-01,   1.03157616e+00],\n",
       "        [ -9.77755785e-02,  -2.13767529e-01,  -3.35417807e-01, ...,\n",
       "           4.53526169e-01,   4.97604191e-01,   7.06406236e-01],\n",
       "        [ -9.77755785e-02,  -2.13767529e-01,  -3.35417807e-01, ...,\n",
       "           3.25931698e-01,   3.84144664e-01,   3.86540592e-01],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       [[  2.30982825e-01,   5.36823869e-01,   1.07098162e+00, ...,\n",
       "           4.86497968e-01,   4.71507549e-01,   4.23954964e-01],\n",
       "        [  2.61801183e-01,   4.00247484e-01,   7.09207714e-01, ...,\n",
       "           2.96573579e-01,   2.61470795e-01,   2.64180124e-01],\n",
       "        [  4.28339481e-01,   6.48911476e-01,   9.45187867e-01, ...,\n",
       "           1.16547704e-01,   6.93882331e-02,   9.02440101e-02],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       [[  2.37335294e-01,   5.36256909e-01,   7.77639449e-01, ...,\n",
       "           7.20159531e-01,   6.08736157e-01,   5.95456064e-01],\n",
       "        [  3.45973782e-02,   2.75261462e-01,   3.64084572e-01, ...,\n",
       "           4.52782929e-01,   3.75217617e-01,   3.14468414e-01],\n",
       "        [ -2.99003363e-01,  -6.83346316e-02,   1.48887679e-01, ...,\n",
       "           1.98830083e-01,   1.75637409e-01,   1.20990217e-01],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       ..., \n",
       "       [[ -7.00848997e-02,   2.84142226e-01,   7.09648371e-01, ...,\n",
       "           7.30572820e-01,   6.59364641e-01,   7.84329295e-01],\n",
       "        [  7.65203685e-02,   4.11661148e-01,   7.34440207e-01, ...,\n",
       "           4.05405194e-01,   3.15774292e-01,   4.78798389e-01],\n",
       "        [  6.97801337e-02,   2.07857877e-01,   5.55614471e-01, ...,\n",
       "           1.01169348e-01,  -1.73361297e-03,   1.88158616e-01],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       [[  7.38257193e-04,   2.68727720e-01,   1.85498431e-01, ...,\n",
       "           4.37337577e-01,   6.25907540e-01,   4.96826112e-01],\n",
       "        [ -2.01631427e-01,  -1.00334704e-01,  -2.69542217e-01, ...,\n",
       "           2.68670619e-01,   4.01342690e-01,   2.44194895e-01],\n",
       "        [ -3.72507989e-01,  -3.43446881e-01,  -5.45298696e-01, ...,\n",
       "           1.50797471e-01,   2.12715462e-01,   1.72269341e-04],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       [[ -7.67345071e-01,  -7.09626496e-01,  -1.80811256e-01, ...,\n",
       "           3.49328935e-01,   3.22032034e-01,   6.77281097e-02],\n",
       "        [ -7.87650704e-01,  -7.21508861e-01,  -2.99959242e-01, ...,\n",
       "           2.00072363e-01,   1.36571780e-01,  -1.06886759e-01],\n",
       "        [ -8.26610565e-01,  -6.50167644e-01,  -2.49446318e-01, ...,\n",
       "           5.79607785e-02,  -2.29406804e-02,  -2.08394855e-01],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object next_batch_rnn at 0x7f6f0c18b888>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEST_MODEL_FILE = \"./dnn_models/lstm_weights1\"+ Code_VERSION+\"_{epoch:02d}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(MODEL_FILE)\n",
    "y_hat = model.predict(x, batch_size=x.shape[0], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.savemat(OUTPUT_FILE, {'y_hat':y_hat})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
