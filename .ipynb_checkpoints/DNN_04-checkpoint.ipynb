{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN\n",
    "### with pretraining, non-freeze previous layers\n",
    "Sep 18, 2018 *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.11</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, TimeDistributed\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "- Read parameters from .mat files\n",
    "- save in Opt object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "# %%pixie_debugger\n",
    "Data_VERSION = '_e10v5'\n",
    "Test_Data_VERSION = '_e10v5'\n",
    "\n",
    "Code_VERSION = '_e04_nf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "DNN_DATA_FILE = \"./dnn_models/DNN_datas\"+Data_VERSION+\".mat\"\n",
    "\n",
    "DNN_TEST_FILE = \"./dnn_models/Test_datas\"+Test_Data_VERSION+\".mat\"\n",
    "\n",
    "\n",
    "DNN_PARAMS_FILE = \"./dnn_models/DNN_params\"+Data_VERSION+\".mat\"\n",
    "\n",
    "DNN_NET_FILE = \"./dnn_models/DNN_net\"+Code_VERSION+\".mat\"\n",
    "\n",
    "\n",
    "# Best model, after adding 1st dense layer\n",
    "MODEL_FILE_1 = \"./dnn_models/weights1\"+ Code_VERSION+\"_{epoch:02d}.h5\"\n",
    "\n",
    "# Best model, after adding 2nd dense layer\n",
    "MODEL_FILE_2 = \"./dnn_models/weights2\"+ Code_VERSION+\"_{epoch:02d}.h5\"\n",
    "\n",
    "# Best model, after adding 3rd dense layer (final)\n",
    "MODEL_FILE_3 = \"./dnn_models/weights3\"+ Code_VERSION+\"_{epoch:02d}.h5\"\n",
    "\n",
    "\n",
    "#dummy save file\n",
    "SAVE_MODEL_FILE = \"./dnn_models/py_model\"+ Code_VERSION+\".h5\"\n",
    "\n",
    "# estimated real+imag for test dataset\n",
    "OUTPUT_FILE = \"./dnn_models/Real_Imag\"+Code_VERSION+\".mat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "class Opts:\n",
    "\n",
    "    def __init__(self, FILE_PARA, FILE_DATA, FILE_TEST):\n",
    "        \n",
    "        # Basic parameters\n",
    "        with h5py.File(FILE_PARA, 'r') as f:\n",
    "            key_list = list(f.keys())\n",
    "            print('File name <{0}>\\nOpt keys (Total {1}):'.format(FILE_PARA,len(f['opts'].items())) )\n",
    "\n",
    "            for k, v in f['opts'].items():\n",
    "\n",
    "                print(k,end=', ')\n",
    "\n",
    "                if k == 'ARMA_order':\n",
    "                    self.ARMA_order = int(np.array(v)[0][0])\n",
    "                    \n",
    "                elif k == 'ada_grad_eps':\n",
    "                    self.ada_grad_eps = np.array(v)[0][0]\n",
    "                    \n",
    "                elif k == 'ada_sgd_scale':\n",
    "                    self.ada_sgd_scale = np.array(v)[0][0]\n",
    "                    \n",
    "                elif k == 'change_momentum_point':\n",
    "                    self.change_momentum_point = int(np.array(v)[0][0])\n",
    "                    \n",
    "                elif k == 'cost_function':\n",
    "                    self.cost_function = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.cost_function += chr(c[0])\n",
    "\n",
    "                elif k == 'cv_interval':\n",
    "                    self.cv_interval = int(np.array(v)[0][0])\n",
    "                    \n",
    "                elif k == 'dim_input':\n",
    "                    self.dim_input = int(np.array(v)[0][0])\n",
    "                    \n",
    "                elif k == 'dim_output':\n",
    "                    self.dim_output = int(np.array(v)[0][0])\n",
    "                    \n",
    "                elif k == 'drop_ratio':\n",
    "                    self.drop_ratio = np.array(v)[0][0]\n",
    "                    \n",
    "                elif k == 'eval_on_gpu':\n",
    "                    self.eval_on_gpu = int(np.array(v)[0][0])\n",
    "                    \n",
    "                elif k == 'final_momentum':\n",
    "                    self.final_momentum = int(np.array(v)[0][0])\n",
    "                   \n",
    "                elif k == 'hid_struct':\n",
    "                    self.hid_struct = np.array(v)\n",
    "                    \n",
    "                elif k == 'initial_momentum':\n",
    "                    self.initial_momentum = np.array(v)[0][0]\n",
    "                    \n",
    "                elif k == 'isDropout':\n",
    "                    self.isDropout = 0\n",
    "                    \n",
    "                elif k == 'isDropoutInput':\n",
    "                    self.isDropoutInput = int(np.array(v)[0][0])\n",
    "                    \n",
    "                elif k == 'isGPU':\n",
    "                    self.isGPU = int(np.array(v)[0][0])\n",
    "                    \n",
    "                elif k == 'isNormalize':\n",
    "                    self.isNormalize = int(np.array(v)[0][0])\n",
    "                    \n",
    "                elif k == 'isPretrain':\n",
    "                    self.isPretrain = int(np.array(v)[0][0])\n",
    "                    \n",
    "                elif k == 'learner':\n",
    "                    self.learner = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.learner += chr(c[0])\n",
    "\n",
    "                elif k == 'net_struct':\n",
    "                    self.net_struct = np.array(v)\n",
    "#                     for n_s in np.array(v):\n",
    "#                         print('Opts Net Stuct:',n_s[0])\n",
    "\n",
    "                elif k == 'rbm_batch_size':\n",
    "                    self.rbm_batch_size = int(np.array(v)[0][0])\n",
    "\n",
    "                elif k == 'rbm_learn_rate_binary':\n",
    "                    self.rbm_learn_rate_binary = np.array(v)\n",
    "\n",
    "                elif k == 'rbm_learn_rate_real':\n",
    "                    self.rbm_learn_rate_real = int(np.array(v)[0][0])\n",
    "\n",
    "                elif k == 'rbm_max_epoch':\n",
    "                    self.rbm_max_epoch = int(np.array(v)[0][0])\n",
    "\n",
    "                elif k == 'save_on_fly':\n",
    "                    self.save_on_fly = int(np.array(v)[0][0])\n",
    "\n",
    "                elif k == 'sgd_batch_size':\n",
    "                    self.sgd_batch_size = int(np.array(v)[0][0]) # BATCH_SIZE for training net\n",
    "                    print(\"self.sgd_batch_size:\",self.sgd_batch_size)\n",
    "\n",
    "                elif k == 'sgd_learn_rate':\n",
    "                    self.sgd_learn_rate = np.array(v)\n",
    "\n",
    "                elif k == 'sgd_max_epoch':\n",
    "                    self.sgd_max_epoch = int(np.array(v)[0][0])\n",
    "\n",
    "                elif k == 'split_tanh1_c1':\n",
    "                    self.split_tanh1_c1 = int(np.array(v)[0][0])\n",
    "\n",
    "                elif k == 'split_tanh1_c2':\n",
    "                    self.split_tanh1_c2 = int(np.array(v)[0][0])\n",
    "\n",
    "                elif k == 'unit_type_hidden':\n",
    "                    self.unit_type_hidden = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.unit_type_hidden += chr(c[0])\n",
    "\n",
    "                elif k == 'unit_type_output':\n",
    "                    self.unit_type_output = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.unit_type_output += chr(c[0])\n",
    "\n",
    "        # Training and Dev Data \n",
    "        with h5py.File(FILE_DATA, 'r') as f:\n",
    "            \n",
    "            print('\\n\\nFile name <{0}>\\nOpt h5py keys (Total {1}):'.format(FILE_DATA,len(f.keys())) )\n",
    "\n",
    "            for k, v in f.items():\n",
    "                print(k, end=', ')\n",
    "                \n",
    "                # Train Data\n",
    "                if k == 'trData':\n",
    "                    self.trData = np.transpose(np.array(v))\n",
    "                    print(\"trData.shape: \", self.trData.shape)\n",
    "                    print(\"trData-> mean:\", np.mean(self.trData), \", var:\", np.var(self.trData), \", std:\",\n",
    "                          np.std(self.trData), \", range:\", (np.amin(self.trData),np.amax(self.trData)))\n",
    "                elif k == 'trLabel_i':\n",
    "                    self.trLabel_i = np.transpose(np.array(v))\n",
    "                    print(\"trLabel_i.shape: \", self.trLabel_i.shape)\n",
    "                    print(\"trLabel_i-> mean:\", np.mean(self.trLabel_i), \", var:\", np.var(self.trLabel_i), \", std:\",\n",
    "                          np.std(self.trLabel_i), \", range:\", (np.amin(self.trLabel_i),np.amax(self.trLabel_i)))\n",
    "                elif k == 'trLabel_r':\n",
    "                    self.trLabel_r = np.transpose(np.array(v))\n",
    "                    print(\"trLabel_r.shape: \", self.trLabel_r.shape)\n",
    "                    print(\"trLabel_r-> mean:\", np.mean(self.trLabel_r), \", var:\", np.var(self.trLabel_r), \", std:\",\n",
    "                          np.std(self.trLabel_r), \", range:\", (np.amin(self.trLabel_r),np.amax(self.trLabel_r)))\n",
    "                elif k == 'trNumframes':\n",
    "                    print(\"trNumframes.shape: \", v.shape)\n",
    "                    self.trNumframes = np.transpose(np.array(v))\n",
    "                    \n",
    "                # Dev Data\n",
    "                elif k == 'cvData':\n",
    "                    self.cvData = np.transpose(np.array(v))\n",
    "                    print(\"cvData.shape: \", self.cvData.shape)\n",
    "                    print(\"cvData-> mean:\", np.mean(self.cvData), \", var:\", np.var(self.cvData), \", std:\",\n",
    "                          np.std(self.cvData), \", range:\", (np.amin(self.cvData),np.amax(self.cvData)))\n",
    "                elif k == 'cvLabel_i':\n",
    "                    self.cvLabel_i = np.transpose(np.array(v))\n",
    "                    print(\"cvLabel_i.shape: \", self.cvLabel_i.shape)\n",
    "                    print(\"cvLabel_i-> mean:\", np.mean(self.cvLabel_i), \", var:\", np.var(self.cvLabel_i), \", std:\",\n",
    "                          np.std(self.cvLabel_i), \", range:\", (np.amin(self.cvLabel_i),np.amax(self.cvLabel_i)))\n",
    "                elif k == 'cvLabel_r':\n",
    "                    self.cvLabel_r = np.transpose(np.array(v))\n",
    "                    print(\"cvLabel_r.shape: \", self.cvLabel_r.shape)\n",
    "                    print(\"cvLabel_r-> mean:\", np.mean(self.cvLabel_r), \", var:\", np.var(self.cvLabel_r), \", std:\",\n",
    "                          np.std(self.cvLabel_r), \", range:\", (np.amin(self.cvLabel_r),np.amax(self.cvLabel_r)))\n",
    "                elif k == 'cvNumframes':\n",
    "                    print(\"cvNumframes.shape: \", v.shape)\n",
    "                    self.cvNumframes = np.transpose(np.array(v))\n",
    "\n",
    "            self.trLabel = np.concatenate((self.trLabel_r, self.trLabel_i), axis=1)\n",
    "            self.cvLabel = np.concatenate((self.cvLabel_r, self.cvLabel_i), axis=1)\n",
    " \n",
    "            \n",
    "        # Test Data \n",
    "        print(FILE_TEST, os.path.isfile(FILE_TEST))\n",
    "        \n",
    "        with h5py.File(FILE_TEST, 'r') as f:\n",
    "            print('\\n\\nFile name <{0}>\\nOpt h5py keys (Total {1}):'.format(FILE_TEST,len(f.keys())) )\n",
    "\n",
    "            \n",
    "            \n",
    "            for k, v in f.items():\n",
    "                print(k, end=', ')\n",
    "                \n",
    "                #Test Data\n",
    "                if k == 'teData':\n",
    "                    self.teData = np.transpose(np.array(v))\n",
    "                    print(\"teData.shape: \", self.teData.shape)\n",
    "                    print(\"teData-> mean:\", np.mean(self.teData), \", var:\", np.var(self.teData), \", std:\",\n",
    "                          np.std(self.teData), \", range:\", (np.amin(self.teData),np.amax(self.teData)))\n",
    "                    \n",
    "                elif k == 'teLabel_i':\n",
    "                    self.teLabel_i = np.transpose(np.array(v))\n",
    "                    print(\"teLabel_i.shape: \", self.teLabel_i.shape)\n",
    "                    print(\"teLabel_i-> mean:\", np.mean(self.teLabel_i), \", var:\", np.var(self.teLabel_i), \", std:\",\n",
    "                          np.std(self.teLabel_i), \", range:\", (np.amin(self.teLabel_i),np.amax(self.teLabel_i)))\n",
    "                    \n",
    "                elif k == 'teLabel_r':\n",
    "                    self.teLabel_r = np.transpose(np.array(v))\n",
    "                    print(\"teLabel_r.shape: \", self.teLabel_r.shape)\n",
    "                    print(\"teLabel_r-> mean:\", np.mean(self.teLabel_r), \", var:\", np.var(self.teLabel_r), \", std:\",\n",
    "                          np.std(self.teLabel_r), \", range:\", (np.amin(self.teLabel_r),np.amax(self.teLabel_r)))\n",
    "                \n",
    "                elif k == 'teNumframes':\n",
    "                    print(\"teNumframes.shape: \", v.shape)\n",
    "                    self.teNumframes = np.transpose(np.array(v))\n",
    "            \n",
    "            self.teLabel = np.concatenate((self.teLabel_r, self.teLabel_i), axis=1)\n",
    "\n",
    "\n",
    "    def ready_batchID(self, total_num_samples, batch_size):\n",
    "        # TRAIN: total_num_samples = self.trData.shape[0] = 195192\n",
    "        # DEV: total_num_samples = self.trData.shape[0] = 44961\n",
    "\n",
    "        batchID = []\n",
    "        num_batch = math.ceil(total_num_samples/batch_size)\n",
    "\n",
    "        for b in range( int(num_batch) ):\n",
    "            s = b*batch_size\n",
    "            e = (b+1)*batch_size -1\n",
    "\n",
    "            if e >= total_num_samples:\n",
    "                e = total_num_samples - 1\n",
    "\n",
    "            batchID.append((s,e))\n",
    "\n",
    "        return np.array(batchID,ndmin=2)\n",
    "\n",
    "\n",
    "    def suffle_data(self, total_num_samples):\n",
    "        # TRAIN: total_num_samples = self.trData.shape[0] = 195192\n",
    "        # DEV: total_num_samples = self.trData.shape[0] = 44961\n",
    "\n",
    "        return  np.random.permutation(total_num_samples)\n",
    "\n",
    "\n",
    "    def next_batch(self, total_num_samples, batch_size, cycle):\n",
    "        '''\n",
    "        Currently we use this one. \n",
    "        \n",
    "        parameters: \n",
    "            total_num_samples <int> = Shape[1] of data\n",
    "            batch_size <int>        \n",
    "            cycle <string>  = train, dev, test\n",
    "        '''\n",
    "        # TRAIN: total_num_samples = self.trData.shape[0] = 195192\n",
    "        # DEV: total_num_samples = self.trData.shape[0] = 44961\n",
    "\n",
    "        while True:\n",
    "            batchID = self.ready_batchID(total_num_samples, batch_size) \n",
    "            seq = self.suffle_data(total_num_samples)\n",
    "\n",
    "            for batch in range(batchID.shape[0]):\n",
    "                if cycle.lower()=='train':\n",
    "                    x = opts.trData[ seq[batchID[batch][0]:batchID[batch][1] ] ]\n",
    "                    y = opts.trLabel[ seq[batchID[batch][0]:batchID[batch][1] ] ]\n",
    "\n",
    "                elif cycle.lower()=='dev':\n",
    "                    x = opts.cvData[seq[batchID[batch][0]:batchID[batch][1]]]\n",
    "                    y = opts.cvLabel[seq[batchID[batch][0]:batchID[batch][1]]]\n",
    "                    \n",
    "                elif cycle.lower()=='test':\n",
    "                    x = opts.teData[seq[batchID[batch][0]:batchID[batch][1]]]\n",
    "                    y = opts.teLabel[seq[batchID[batch][0]:batchID[batch][1]]]\n",
    "\n",
    "                # print('Next Batch', x.shape, y.shape)\n",
    "                yield [x, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name <./dnn_models/DNN_params_e10v5.mat>\n",
      "Opt keys (Total 34):\n",
      "ARMA_order, ada_grad_eps, ada_sgd_scale, change_momentum_point, cost_function, cv_interval, dim_input, dim_output, drop_ratio, eval_on_gpu, final_momentum, hid_struct, initial_momentum, isDropout, isDropoutInput, isGPU, isNormalize, isPretrain, learner, net_struct, rbm_batch_size, rbm_learn_rate_binary, rbm_learn_rate_real, rbm_max_epoch, save_on_fly, sgd_batch_size, self.sgd_batch_size: 1024\n",
      "sgd_learn_rate, sgd_max_epoch, split_tanh1_c1, split_tanh1_c2, tr_mu, tr_std, unit_type_hidden, unit_type_output, \n",
      "\n",
      "File name <./dnn_models/DNN_datas_e10v5.mat>\n",
      "Opt h5py keys (Total 8):\n",
      "cvData, cvData.shape:  (449610, 1230)\n",
      "cvData-> mean: -3.12831e-06 , var: 0.607645 , std: 0.779516 , range: (-9.6298428, 10.49406)\n",
      "cvLabel_i, cvLabel_i.shape:  (449610, 963)\n",
      "cvLabel_i-> mean: -1.2493e-05 , var: 0.0129563 , std: 0.113826 , range: (-10.0, 10.0)\n",
      "cvLabel_r, cvLabel_r.shape:  (449610, 963)\n",
      "cvLabel_r-> mean: 0.028573 , var: 0.0212577 , std: 0.1458 , range: (-10.0, 10.0)\n",
      "cvNumframes, cvNumframes.shape:  (1, 3300)\n",
      "trData, trData.shape:  (1951920, 1230)\n",
      "trData-> mean: -0.000807387 , var: 0.612503 , std: 0.782626 , range: (-11.557238, 12.486189)\n",
      "trLabel_i, trLabel_i.shape:  (1951920, 963)\n",
      "trLabel_i-> mean: 1.29036e-06 , var: 0.0133129 , std: 0.115382 , range: (-10.0, 10.0)\n",
      "trLabel_r, trLabel_r.shape:  (1951920, 963)\n",
      "trLabel_r-> mean: 0.0295324 , var: 0.021696 , std: 0.147296 , range: (-10.0, 10.0)\n",
      "trNumframes, trNumframes.shape:  (1, 15000)\n",
      "./dnn_models/Test_datas_e10v5.mat True\n",
      "\n",
      "\n",
      "File name <./dnn_models/Test_datas_e10v5.mat>\n",
      "Opt h5py keys (Total 7):\n",
      "#refs#, #subsystem#, teData, teData.shape:  (72440, 1230)\n",
      "teData-> mean: -0.00110349 , var: 0.556445 , std: 0.745952 , range: (-4.8041673, 5.2418036)\n",
      "teFilename_mix, teLabel_i, teLabel_i.shape:  (72440, 963)\n",
      "teLabel_i-> mean: -3.01466e-06 , var: 1.05955e-05 , std: 0.00325507 , range: (-0.03745788, 0.035189673)\n",
      "teLabel_r, teLabel_r.shape:  (72440, 963)\n",
      "teLabel_r-> mean: 0.0328164 , var: 0.00246607 , std: 0.0496596 , range: (-0.15398552, 0.43288523)\n",
      "teNumframes, teNumframes.shape:  (1, 545)\n"
     ]
    }
   ],
   "source": [
    "# %%pixie_debugger\n",
    "opts = Opts(DNN_PARAMS_FILE, DNN_DATA_FILE, DNN_TEST_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data/Label Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00080738659, -3.1283103e-06, -0.0011034891] [0.78262568, 0.7795161, 0.74595237]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEoCAYAAACZ5MzqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85f47ce550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "group = 2 # clean and noisy, clean is not ready yet\n",
    "data_partitions = 3 # train, dev and test\n",
    "\n",
    "index = np.arange(data_partitions)\n",
    "bar_width = .35\n",
    "\n",
    "opacity = 0.4\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "# There will be clean_means and clean_std too.\n",
    "\n",
    "noisy_means = [np.mean(opts.trData), np.mean(opts.cvData), np.mean(opts.teData)]\n",
    "noisy_std = [np.std(opts.trData), np.std(opts.cvData), np.std(opts.teData)]\n",
    "print(noisy_means, noisy_std)\n",
    "\n",
    "# print(\"teData-> mean:\", np.mean(self.teData), \", var:\", np.var(self.teData), \", std:\",\n",
    "#                           np.std(self.teData), \", range:\", (np.amin(self.teData),np.amax(self.teData)))\n",
    "\n",
    "\n",
    "rects_clean = ax.bar(index, noisy_means, bar_width,\n",
    "                    alpha=opacity, color='g',\n",
    "                    yerr=noisy_std, error_kw=error_config,\n",
    "                    label='Clean Features')\n",
    "\n",
    "rects_noisy = ax.bar(index + bar_width, noisy_means, bar_width,\n",
    "                    alpha=opacity, color='r',\n",
    "                    yerr=noisy_std, error_kw=error_config,\n",
    "                    label='Noisy Features')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Clean and Noisy Features')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_yticks(np.arange(-1, 1, step=0.05))\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(('Train\\n({0:.2f},{1:.2f})'.format(np.amin(opts.trData),np.amax(opts.trData)), \n",
    "                    'Dev\\n({0:.2f},{1:.2f})'.format(np.amin(opts.cvData),np.amax(opts.cvData)),\n",
    "                    'Test\\n({0:.2f},{1:.2f})'.format(np.amin(opts.teData),np.amax(opts.teData))))\n",
    "ax.set_title('Sharing Y axis')\n",
    "ax.legend()\n",
    "\n",
    "# fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old cost functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def calc(x, y):\n",
    "    # Returns predictions and error\n",
    "    predictions = multilayer_NN(x)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    r, c = y.get_shape().as_list()\n",
    "    r = opts.sgd_batch_size\n",
    "    print('r:', type(r), r, ',c:', type(c), c)\n",
    "\n",
    "    # TRAIN: matlab\n",
    "    # cost1 = 0.5 * sum(sum((pred_real - label_real). ^ 2)) / num_sample;\n",
    "    # cost2 = 0.5 * sum(sum((pred_imag - label_imag). ^ 2)) / num_sample;\n",
    "    # cost = cost1 + cost2;\n",
    "    cost1 = tf.reduce_sum(tf.squared_difference(y[:, :c//2], predictions[:, :c//2]))\n",
    "    cost2 = tf.reduce_sum(tf.squared_difference(y[:, c//2:], predictions[:, c//2:]))\n",
    "    loss_t = 0.5*(cost1+cost2)/r\n",
    "    # mse = tf.losses.mean_squared_error(labels=y, predictions=predictions,weights=0.5)\n",
    "    # loss_t = tf.divide(tf.reduce_sum(mse), r)\n",
    "\n",
    "\n",
    "    # DEV: matlab\n",
    "    # dev_perfs = -mean(sum((dev_label_real - dev_netout1). ^ 2)) - mean(sum((dev_label_imag - dev_netout2). ^ 2));\n",
    "    mse_r = tf.reduce_sum(tf.squared_difference(y[:, :c // 2], predictions[:, :c // 2]), axis=0)\n",
    "    mse_i = tf.reduce_sum(tf.squared_difference(y[:, c // 2:], predictions[:, c // 2:]), axis=0)\n",
    "\n",
    "    loss_d = -tf.reduce_mean(mse_r)-tf.reduce_mean(mse_i)\n",
    "\n",
    "\n",
    "    return [predictions, loss_t, mse_r, mse_i, loss_d ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "    cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_session = K.get_session()\n",
    "val1 = np.array([[1, 2], [3, 4], [6, 7]])\n",
    "val2 = np.array([[2, 3], [4, 5], [8, 9]])\n",
    "\n",
    "kvar1 = K.variable(value=val1)\n",
    "kvar2 = K.variable(value=val2)\n",
    "                   \n",
    "r = K.variable(value=customLoss(kvar1,kvar2))\n",
    "                   \n",
    "K.eval(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256 #opts.sgd_batch_size\n",
    "epochs = 30\n",
    "\n",
    "'''\n",
    "n_train, n_train_dim = <number of samples for training, input dimentions>, final will be (1951920, 1230)\n",
    "n_dev, n_dev_dim = <number of samples for development, input dimentions>, final will be (449610, 1230)\n",
    "n_test, n_test_dim =<number of samples for testing, input dimentions>, final will be (72440, 1230)\n",
    "\n",
    "'''\n",
    "n_train, n_train_dim = (195192, 1230) # opts.trData.shape = (1951920, 1230)\n",
    "n_dev, n_dev_dim = (44961, 1230) # opts.cvData.shape =(449610, 1230)\n",
    "n_test, n_test_dim = (72440, 1230) # opts.teData.shape =(72440, 1230)\n",
    "\n",
    "n_hidden_1 = 1024  # 1st layer number of neurons\n",
    "n_hidden_2 = 1024  # 2nd layer number of neurons\n",
    "n_hidden_3 = 1024  # 3rd layer number of neurons\n",
    "\n",
    "n_classes = (963 + 963)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              1260544   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1926)              1974150   \n",
      "=================================================================\n",
      "Total params: 3,234,694\n",
      "Trainable params: 3,234,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "762/762 [==============================] - 15s - loss: 20.7092 - acc: 0.0254 - mean_squared_error: 0.0215 - mean_absolute_error: 0.0589 - mean_absolute_percentage_error: 86592.1801 - cosine_proximity: -9.8703e-05 - val_loss: 16.8027 - val_acc: 0.0289 - val_mean_squared_error: 0.0174 - val_mean_absolute_error: 0.0592 - val_mean_absolute_percentage_error: 99513.2413 - val_cosine_proximity: -8.2409e-05\n",
      "Epoch 2/30\n",
      "762/762 [==============================] - 15s - loss: 18.2176 - acc: 0.0301 - mean_squared_error: 0.0189 - mean_absolute_error: 0.0483 - mean_absolute_percentage_error: 20563.0228 - cosine_proximity: -1.2324e-04 - val_loss: 16.3844 - val_acc: 0.0255 - val_mean_squared_error: 0.0170 - val_mean_absolute_error: 0.0563 - val_mean_absolute_percentage_error: 83950.5136 - val_cosine_proximity: -8.8935e-05\n",
      "Epoch 3/30\n",
      "762/762 [==============================] - 16s - loss: 18.1586 - acc: 0.0285 - mean_squared_error: 0.0189 - mean_absolute_error: 0.0478 - mean_absolute_percentage_error: 15133.5673 - cosine_proximity: -1.2510e-04 - val_loss: 16.4790 - val_acc: 0.0296 - val_mean_squared_error: 0.0171 - val_mean_absolute_error: 0.0565 - val_mean_absolute_percentage_error: 81221.1388 - val_cosine_proximity: -9.0380e-05\n",
      "Epoch 4/30\n",
      "762/762 [==============================] - 16s - loss: 18.1409 - acc: 0.0304 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0476 - mean_absolute_percentage_error: 14101.9915 - cosine_proximity: -1.2563e-04 - val_loss: 16.5829 - val_acc: 0.0315 - val_mean_squared_error: 0.0172 - val_mean_absolute_error: 0.0565 - val_mean_absolute_percentage_error: 74544.5334 - val_cosine_proximity: -9.1707e-05\n",
      "Epoch 5/30\n",
      "762/762 [==============================] - 15s - loss: 18.1114 - acc: 0.0303 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0475 - mean_absolute_percentage_error: 13679.7589 - cosine_proximity: -1.2588e-04 - val_loss: 16.5944 - val_acc: 0.0313 - val_mean_squared_error: 0.0172 - val_mean_absolute_error: 0.0560 - val_mean_absolute_percentage_error: 67696.9329 - val_cosine_proximity: -9.4230e-05\n",
      "Epoch 6/30\n",
      "762/762 [==============================] - 15s - loss: 18.1069 - acc: 0.0300 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0475 - mean_absolute_percentage_error: 12793.5320 - cosine_proximity: -1.2613e-04 - val_loss: 16.5820 - val_acc: 0.0279 - val_mean_squared_error: 0.0172 - val_mean_absolute_error: 0.0554 - val_mean_absolute_percentage_error: 56652.9581 - val_cosine_proximity: -9.6074e-05\n",
      "Epoch 7/30\n",
      "762/762 [==============================] - 15s - loss: 18.1036 - acc: 0.0294 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0475 - mean_absolute_percentage_error: 11332.9108 - cosine_proximity: -1.2621e-04 - val_loss: 16.6952 - val_acc: 0.0270 - val_mean_squared_error: 0.0173 - val_mean_absolute_error: 0.0554 - val_mean_absolute_percentage_error: 41759.3410 - val_cosine_proximity: -9.5369e-05\n",
      "Epoch 8/30\n",
      "762/762 [==============================] - 15s - loss: 18.1085 - acc: 0.0302 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0474 - mean_absolute_percentage_error: 9457.3546 - cosine_proximity: -1.2651e-04 - val_loss: 16.8316 - val_acc: 0.0293 - val_mean_squared_error: 0.0175 - val_mean_absolute_error: 0.0553 - val_mean_absolute_percentage_error: 31803.7273 - val_cosine_proximity: -9.6391e-05\n",
      "Epoch 9/30\n",
      "762/762 [==============================] - 15s - loss: 18.0848 - acc: 0.0301 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0473 - mean_absolute_percentage_error: 7752.6911 - cosine_proximity: -1.2649e-04 - val_loss: 17.1060 - val_acc: 0.0304 - val_mean_squared_error: 0.0178 - val_mean_absolute_error: 0.0559 - val_mean_absolute_percentage_error: 24416.1910 - val_cosine_proximity: -9.4973e-05\n",
      "Epoch 10/30\n",
      "762/762 [==============================] - 15s - loss: 18.0825 - acc: 0.0300 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0473 - mean_absolute_percentage_error: 6139.3715 - cosine_proximity: -1.2687e-04 - val_loss: 17.4745 - val_acc: 0.0346 - val_mean_squared_error: 0.0181 - val_mean_absolute_error: 0.0568 - val_mean_absolute_percentage_error: 16973.3681 - val_cosine_proximity: -9.6012e-05\n",
      "Epoch 11/30\n",
      "762/762 [==============================] - 16s - loss: 18.0954 - acc: 0.0297 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0473 - mean_absolute_percentage_error: 5308.6908 - cosine_proximity: -1.2701e-04 - val_loss: 17.6739 - val_acc: 0.0305 - val_mean_squared_error: 0.0184 - val_mean_absolute_error: 0.0567 - val_mean_absolute_percentage_error: 9982.1992 - val_cosine_proximity: -9.4836e-05\n",
      "Epoch 12/30\n",
      "762/762 [==============================] - 15s - loss: 18.0875 - acc: 0.0308 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0472 - mean_absolute_percentage_error: 4953.0939 - cosine_proximity: -1.2699e-04 - val_loss: 17.8966 - val_acc: 0.0283 - val_mean_squared_error: 0.0186 - val_mean_absolute_error: 0.0570 - val_mean_absolute_percentage_error: 7318.8657 - val_cosine_proximity: -9.6871e-05\n",
      "Epoch 13/30\n",
      "762/762 [==============================] - 15s - loss: 18.0572 - acc: 0.0301 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0471 - mean_absolute_percentage_error: 4306.4925 - cosine_proximity: -1.2731e-04 - val_loss: 18.0994 - val_acc: 0.0331 - val_mean_squared_error: 0.0188 - val_mean_absolute_error: 0.0567 - val_mean_absolute_percentage_error: 5211.9309 - val_cosine_proximity: -9.6986e-05\n",
      "Epoch 14/30\n",
      "762/762 [==============================] - 14s - loss: 18.0714 - acc: 0.0308 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0471 - mean_absolute_percentage_error: 4583.4627 - cosine_proximity: -1.2753e-04 - val_loss: 17.9712 - val_acc: 0.0312 - val_mean_squared_error: 0.0187 - val_mean_absolute_error: 0.0556 - val_mean_absolute_percentage_error: 6169.4567 - val_cosine_proximity: -9.8530e-05\n",
      "Epoch 15/30\n",
      "762/762 [==============================] - 15s - loss: 18.0857 - acc: 0.0309 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0471 - mean_absolute_percentage_error: 4459.5514 - cosine_proximity: -1.2777e-04 - val_loss: 18.3463 - val_acc: 0.0294 - val_mean_squared_error: 0.0191 - val_mean_absolute_error: 0.0570 - val_mean_absolute_percentage_error: 7730.8613 - val_cosine_proximity: -9.3880e-05\n",
      "Epoch 16/30\n",
      "762/762 [==============================] - 15s - loss: 18.0567 - acc: 0.0324 - mean_squared_error: 0.0188 - mean_absolute_error: 0.0470 - mean_absolute_percentage_error: 4790.8652 - cosine_proximity: -1.2809e-04 - val_loss: 18.5016 - val_acc: 0.0256 - val_mean_squared_error: 0.0192 - val_mean_absolute_error: 0.0563 - val_mean_absolute_percentage_error: 8320.1203 - val_cosine_proximity: -9.6515e-05\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(n_hidden_1, activation='relu', input_shape=(n_train_dim,),name='dense_1'))\n",
    "# we will add 2 more layers\n",
    "model.add(Dense(n_classes, activation='linear'))\n",
    "\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_acc', patience=5, min_delta=1e-6, verbose=1, mode='auto'), \n",
    "             ModelCheckpoint(filepath= MODEL_FILE_1, monitor='val_acc', save_best_only=True)]\n",
    "          \n",
    "model.compile(loss = customLoss, optimizer = 'adam', metrics = ['accuracy','mse', 'mae', 'mape', 'cosine'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit_generator(opts.next_batch(n_train, batch_size, cycle='train'),  \n",
    "                    validation_data=opts.next_batch(n_dev, batch_size, cycle='dev'),\n",
    "                    epochs=epochs, steps_per_epoch=n_train//batch_size,\n",
    "                    validation_steps=n_dev//batch_size, \n",
    "                    verbose=1, callbacks=callbacks)\n",
    "# history = model.fit_generator(opts.next_batch(n_train, batch_size, cycle='train'),  \n",
    "#                     validation_data=opts.next_batch(n_dev, batch_size, cycle='dev'),\n",
    "#                     epochs=epochs, steps_per_epoch=int(math.ceil(n_train/batch_size)),\n",
    "#                     validation_steps=int(math.ceil(n_out_sz/batch_size)), \n",
    "#                     verbose=1, callbacks=callbacks)\n",
    "\n",
    "model.save(SAVE_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Best_weight_1=\"./dnn_models/weights1\"+ Code_VERSION+\"_09.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2nd hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-707aba4af17f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBest_weight_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'customLoss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcustomLoss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'load_model'"
     ]
    }
   ],
   "source": [
    "# SAVE_MODEL_FILE_2 = \"./dnn_models/py_model_2_\"+ Code_VERSION+\".h5\"\n",
    "model = load_model(Best_weight_1, custom_objects={'customLoss':customLoss})\n",
    "\n",
    "model.pop()\n",
    "\n",
    "model.add(Dense(n_hidden_2, activation='relu',name='dense_2'))\n",
    "# we will add 1 more layers\n",
    "model.add(Dense(n_classes, activation='linear'))\n",
    "\n",
    "\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_acc', patience=5, min_delta=1e-6, verbose=1, mode='auto'), \n",
    "             ModelCheckpoint(filepath= MODEL_FILE_2, monitor='val_acc', save_best_only=True)]\n",
    "          \n",
    "model.compile(loss = customLoss, optimizer = 'adam', metrics = ['accuracy','mse', 'mae', 'mape', 'cosine'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit_generator(opts.next_batch(n_train, batch_size, cycle='train'),  \n",
    "                    validation_data=opts.next_batch(n_dev, batch_size, cycle='dev'),\n",
    "                    epochs=epochs, steps_per_epoch=n_train//batch_size,\n",
    "                    validation_steps=n_dev//batch_size, \n",
    "                    verbose=1, callbacks=callbacks)\n",
    "\n",
    "# history = model.fit_generator(opts.next_batch(opts.trData.shape[0], batch_size),  \n",
    "#                     validation_data=opts.next_batch(opts.cvData.shape[0], batch_size, isTrainCycle=False),\n",
    "#                     epochs=epochs, steps_per_epoch=int(math.ceil(n_input_sz/batch_size)),\n",
    "#                     validation_steps=int(math.ceil(n_out_sz/batch_size)), \n",
    "#                     verbose=1, callbacks=callbacks)\n",
    "\n",
    "model.save(SAVE_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Best_weight_2=\"./dnn_models/weights2\"+ Code_VERSION+\"_09.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 3rd hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS-fun: <class 'tensorflow.python.framework.ops.Tensor'> None\n",
      "[OLD] Number of layers (except input layer, including output layer)->\n",
      " [<keras.layers.core.Dense object at 0x7f39787164a8>, <keras.layers.core.Dense object at 0x7f39d9bbe208>, <keras.layers.core.Dense object at 0x7f3978726d68>]\n",
      "[NEW] Number of layers (except input layer, including output layer)->\n",
      " [<keras.layers.core.Dense object at 0x7f39787164a8>, <keras.layers.core.Dense object at 0x7f39d9bbe208>, <keras.layers.core.Dense object at 0x7f395c6652b0>, <keras.layers.core.Dense object at 0x7f395c665358>]\n",
      "LOSS-fun: <class 'tensorflow.python.framework.ops.Tensor'> None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1024)              1260544   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1926)              1974150   \n",
      "=================================================================\n",
      "Total params: 5,333,894\n",
      "Trainable params: 5,333,894\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "3513/3513 [==============================] - 50s - loss: 16.2637 - acc: 0.0281 - mean_squared_error: 0.0170 - mean_absolute_error: 0.0439 - mean_absolute_percentage_error: 4204.6035 - cosine_proximity: -1.3222e-04    \n",
      "Epoch 2/30\n",
      "3513/3513 [==============================] - 45s - loss: 16.1919 - acc: 0.0282 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0435 - mean_absolute_percentage_error: 3358.7763 - cosine_proximity: -1.3506e-04    \n",
      "Epoch 3/30\n",
      "3513/3513 [==============================] - 46s - loss: 16.1611 - acc: 0.0283 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0434 - mean_absolute_percentage_error: 3274.7971 - cosine_proximity: -1.3585e-04    \n",
      "Epoch 4/30\n",
      "3513/3513 [==============================] - 49s - loss: 16.1448 - acc: 0.0286 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0434 - mean_absolute_percentage_error: 3319.1679 - cosine_proximity: -1.3641e-04    \n",
      "Epoch 5/30\n",
      "3513/3513 [==============================] - 47s - loss: 16.1273 - acc: 0.0282 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0433 - mean_absolute_percentage_error: 3285.9319 - cosine_proximity: -1.3670e-04    \n",
      "Epoch 6/30\n",
      "3513/3513 [==============================] - 48s - loss: 16.1156 - acc: 0.0284 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0433 - mean_absolute_percentage_error: 3277.2200 - cosine_proximity: -1.3696e-04    \n",
      "Epoch 7/30\n",
      "3513/3513 [==============================] - 46s - loss: 16.1134 - acc: 0.0285 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0433 - mean_absolute_percentage_error: 3350.5129 - cosine_proximity: -1.3704e-04    \n",
      "Epoch 8/30\n",
      "3513/3513 [==============================] - 46s - loss: 16.1065 - acc: 0.0291 - mean_squared_error: 0.0169 - mean_absolute_error: 0.0432 - mean_absolute_percentage_error: 3253.9561 - cosine_proximity: -1.3726e-04    \n",
      "Epoch 9/30\n",
      "3513/3513 [==============================] - 48s - loss: 16.0970 - acc: 0.0287 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0432 - mean_absolute_percentage_error: 3202.4873 - cosine_proximity: -1.3741e-04    \n",
      "Epoch 10/30\n",
      "3513/3513 [==============================] - 47s - loss: 16.0918 - acc: 0.0292 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0432 - mean_absolute_percentage_error: 3197.5459 - cosine_proximity: -1.3747e-04    \n",
      "Epoch 11/30\n",
      "3513/3513 [==============================] - 47s - loss: 16.0938 - acc: 0.0292 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0432 - mean_absolute_percentage_error: 3224.2779 - cosine_proximity: -1.3747e-04    \n",
      "Epoch 12/30\n",
      "3513/3513 [==============================] - 48s - loss: 16.0883 - acc: 0.0294 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0432 - mean_absolute_percentage_error: 3159.0761 - cosine_proximity: -1.3766e-04    \n",
      "Epoch 13/30\n",
      "3513/3513 [==============================] - 47s - loss: 16.0903 - acc: 0.0297 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0432 - mean_absolute_percentage_error: 3218.7694 - cosine_proximity: -1.3770e-04    \n",
      "Epoch 14/30\n",
      "3513/3513 [==============================] - 46s - loss: 16.0817 - acc: 0.0293 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0432 - mean_absolute_percentage_error: 3132.6325 - cosine_proximity: -1.3764e-04    \n",
      "Epoch 15/30\n",
      "3513/3513 [==============================] - 47s - loss: 16.0803 - acc: 0.0297 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0432 - mean_absolute_percentage_error: 3176.8451 - cosine_proximity: -1.3774e-04    - ETA: 5s - loss: 16.0739 - acc: 0.0298 - mean_squared_error: 0.0168 - mean_absolute_er\n",
      "Epoch 16/30\n",
      "3513/3513 [==============================] - 48s - loss: 16.0767 - acc: 0.0297 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3180.5697 - cosine_proximity: -1.3770e-04    \n",
      "Epoch 17/30\n",
      "3513/3513 [==============================] - 47s - loss: 16.0797 - acc: 0.0290 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0432 - mean_absolute_percentage_error: 3120.6405 - cosine_proximity: -1.3779e-04    \n",
      "Epoch 18/30\n",
      "3513/3513 [==============================] - 49s - loss: 16.0795 - acc: 0.0294 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3077.5466 - cosine_proximity: -1.3772e-04    \n",
      "Epoch 19/30\n",
      "3513/3513 [==============================] - 47s - loss: 16.0785 - acc: 0.0299 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3189.1563 - cosine_proximity: -1.3775e-04    \n",
      "Epoch 20/30\n",
      "3513/3513 [==============================] - 42s - loss: 16.0807 - acc: 0.0297 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3143.4544 - cosine_proximity: -1.3772e-04    \n",
      "Epoch 21/30\n",
      "3513/3513 [==============================] - 44s - loss: 16.0765 - acc: 0.0294 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3183.2669 - cosine_proximity: -1.3779e-04    \n",
      "Epoch 22/30\n",
      "3513/3513 [==============================] - 44s - loss: 16.0686 - acc: 0.0297 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3147.5670 - cosine_proximity: -1.3771e-04    \n",
      "Epoch 23/30\n",
      "3513/3513 [==============================] - 46s - loss: 16.0715 - acc: 0.0292 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3139.8460 - cosine_proximity: -1.3781e-04    \n",
      "Epoch 24/30\n",
      "3513/3513 [==============================] - 45s - loss: 16.0698 - acc: 0.0294 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3153.2982 - cosine_proximity: -1.3790e-04    - ETA: 8s - loss: 16.0672 - a\n",
      "Epoch 25/30\n",
      "3513/3513 [==============================] - 43s - loss: 16.0672 - acc: 0.0302 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3149.7678 - cosine_proximity: -1.3786e-04    \n",
      "Epoch 26/30\n",
      "3513/3513 [==============================] - 43s - loss: 16.0710 - acc: 0.0296 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3118.9035 - cosine_proximity: -1.3782e-04    \n",
      "Epoch 27/30\n",
      "3513/3513 [==============================] - 45s - loss: 16.0679 - acc: 0.0294 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3161.8036 - cosine_proximity: -1.3776e-04    \n",
      "Epoch 28/30\n",
      "3513/3513 [==============================] - 45s - loss: 16.0694 - acc: 0.0295 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3110.3004 - cosine_proximity: -1.3788e-04    \n",
      "Epoch 29/30\n",
      "3513/3513 [==============================] - 43s - loss: 16.0657 - acc: 0.0298 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3172.3820 - cosine_proximity: -1.3787e-04    \n",
      "Epoch 30/30\n",
      "3513/3513 [==============================] - 44s - loss: 16.0662 - acc: 0.0294 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0431 - mean_absolute_percentage_error: 3160.7325 - cosine_proximity: -1.3778e-04    \n"
     ]
    }
   ],
   "source": [
    "# SAVE_MODEL_FILE_3 = \"./dnn_models/py_model_3_\"+ Code_VERSION+\".h5\"\n",
    "model = load_model(Best_weight_2, custom_objects={'customLoss':customLoss})\n",
    "\n",
    "model.pop()\n",
    "\n",
    "model.add(Dense(n_hidden_2, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='linear'))\n",
    "\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_acc', patience=5, min_delta=1e-6, verbose=1, mode='auto'), \n",
    "             ModelCheckpoint(filepath= MODEL_FILE_3, monitor='val_acc', save_best_only=True)]\n",
    "          \n",
    "model.compile(loss = customLoss, optimizer = 'adam', metrics = ['accuracy','mse', 'mae', 'mape', 'cosine'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit_generator(opts.next_batch(n_train, batch_size, cycle='train'),  \n",
    "                    validation_data=opts.next_batch(n_dev, batch_size, cycle='dev'),\n",
    "                    epochs=epochs, steps_per_epoch=n_train//batch_size,\n",
    "                    validation_steps=n_dev//batch_size, \n",
    "                    verbose=1, callbacks=callbacks)\n",
    "\n",
    "# history = model.fit_generator(opts.next_batch(opts.trData.shape[0], batch_size),  \n",
    "#                     validation_data=opts.next_batch(opts.cvData.shape[0], batch_size, isTrainCycle=False),\n",
    "#                     epochs=epochs, steps_per_epoch=int(math.ceil(n_input_sz/batch_size)),\n",
    "#                     validation_steps=int(math.ceil(n_out_sz/batch_size)), \n",
    "#                     verbose=1, callbacks=callbacks)\n",
    "\n",
    "\n",
    "model.save(SAVE_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'dense_3', 'trainable': True, 'batch_input_shape': (None, 1230), 'dtype': 'float32', 'units': 1024, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dense_5', 'trainable': True, 'units': 1024, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dense_7', 'trainable': True, 'units': 1024, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dense_8', 'trainable': True, 'units': 1926, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    g=layer.get_config()\n",
    "    print (g,end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Best_weight_3=\"./dnn_models/weights3\"+ Code_VERSION+\"_09.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(Best_weight_3, custom_objects={'customLoss':customLoss})\n",
    "\n",
    "\n",
    "y_hat = model.predict(x, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print(y_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.savemat(OUTPUT_FILE, {'y_hat':y_hat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unwrapAugmentedTF_wAvg(impt_mag,num_per_side,unwrap_mag=None):\n",
    "    \n",
    "#     Description: Unwrap the augmented time-frequency (T-F) representation and compute the average.\n",
    "\n",
    "#     Input:\n",
    "#         impt_mag: wrapped T-F representation with dimensions (2*T+1)*d x m\n",
    "#         T: number of frames to left and right of each frame used to augmented T-F representation\n",
    "#     Output:\n",
    "#         unwrap_avgmag: unwrapped and averaged T-F representation with dimensions d x m\n",
    "#         unwrap_mag: unwrapped T-F representation with dimensions d x (2*T+1) x m\n",
    "#\n",
    "        \n",
    "        sliding_window_len       = 2*num_per_side + 1\n",
    "        (numWrapFreqs,numFrames) = impt_mag.shape\n",
    "        numFreqs                 = numWrapFreqs//sliding_window_len\n",
    "        unwrap_avgmag            = np.zeros((numFreqs,numFrames))\n",
    "        \n",
    "        if num_per_side > 0:\n",
    "            if unwrap_mag is None:\n",
    "            \n",
    "                unwrap_mag        = np.zeros((numFreqs,sliding_window_len+1,numFrames))\n",
    "                curr_ind_location = np.ones((numFrames,1),dtype=int)\n",
    "                \n",
    "\n",
    "                for frameNum in range(numFrames):\n",
    "                    \n",
    "                    # Get the indices for the frames used in this augmented matrix\n",
    "                    frame_inds=[]\n",
    "                    for inds in range(frameNum-num_per_side,frameNum+num_per_side+1):\n",
    "                        if inds<0:\n",
    "                            frame_inds.append(0)\n",
    "                        elif inds>=numFrames:\n",
    "                            frame_inds.append(numFrames-1)\n",
    "                        else:\n",
    "                            frame_inds.append(inds)\n",
    "                    \n",
    "                    # Unwrap the data for this frame\n",
    "                    slid_win_data = np.reshape( impt_mag[:,frameNum], (numFreqs,sliding_window_len)) #Size d x (2*T + 1)\n",
    "                    \n",
    "                    for ind_num in range(len(frame_inds)):\n",
    "\n",
    "                        slid = np.array(slid_win_data[:,ind_num], ndmin=2).T\n",
    "                        unwrap_mag[:,curr_ind_location[frame_inds[ind_num]], frame_inds[ind_num]] = slid \n",
    "                        \n",
    "                        # Update counters\n",
    "                        curr_ind_location[frame_inds[ind_num]] = curr_ind_location[frame_inds[ind_num]] + 1\n",
    "\n",
    "\n",
    "            temp = np.zeros((numFreqs,sliding_window_len+1))\n",
    "            \n",
    "            for frameNum in range(numFrames):\n",
    "#                 print(unwrap_mag.shape)\n",
    "                \n",
    "                unwrap_avgmag[:,frameNum] = np.mean(unwrap_mag[:,:,frameNum],axis=1)\n",
    "#                 print(unwrap_mag.shape)\n",
    "#                 return\n",
    "\n",
    "            \n",
    "        else:\n",
    "            unwrap_avgmag = impt_mag;\n",
    "            unwrap_mag = 0;\n",
    "            \n",
    "        return unwrap_avgmag,unwrap_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reals=[]\n",
    "imags=None\n",
    "\n",
    "labwin = 1\n",
    "for e, y_ in enumerate(y_hat):\n",
    "    \n",
    "    numFrames = int(opts.teNumframes[e])\n",
    "    \n",
    "    real_output = y_[:numFrames,:out_vec_len]\n",
    "    imag_output = y_[:numFrames,out_vec_len:]\n",
    "#     print(e, numFrames, real_output.shape, imag_output.shape)\n",
    "    \n",
    "    real_output_unwrap, _ = unwrapAugmentedTF_wAvg(real_output.T,labwin)\n",
    "    imag_output_unwrap, _ = unwrapAugmentedTF_wAvg(imag_output.T,labwin)\n",
    "    \n",
    "    print('unwrap:',real_output_unwrap.shape, end=' , ')\n",
    "    \n",
    "#     reals= np.array([list(real_output_unwrap)], dtype=object) if reals is None else np.append(reals,[list(real_output_unwrap)], axis=0)\n",
    "    reals.append(real_output_unwrap)\n",
    "    print('reals:',len(reals))\n",
    "#     imags.append(imag_output_unwrap)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dd7a76c6cee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "np.savetxt('./dnn_models/test.out', reals[0], delimiter=',')   # X is an array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
