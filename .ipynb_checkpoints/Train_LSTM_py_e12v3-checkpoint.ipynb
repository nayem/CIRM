{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LSTM Series (working)\n",
    "\n",
    "** - Simple LSTM  **\n",
    "\n",
    "** - Train and Dev different loss functions **\n",
    "\n",
    "** - Adam Optimizer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.11</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.11, Latest is 1.1.13</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Please restart kernel after upgrading.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, TimeDistributed\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,Callback\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configuration to control GPU use\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.33\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read parameters from .mat files\n",
    "save in Opt object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_VERSION = \"_e10v5\"\n",
    "Test_Data_VERSION = '_e04v2_nf'\n",
    "\n",
    "Code_VERSION = \"_e12v3\"\n",
    "\n",
    "Param_VERSION = '_e12v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DNN_DATA_FILE = \"./dnn_models/DNN_datas\"+ Data_VERSION+\".mat\"\n",
    "DNN_TEST_FILE = \"./dnn_models/Test_datas\"+Test_Data_VERSION+\".mat\"\n",
    "\n",
    "PARAM_FILE = \"./dnn_models/DNN_params\"+Param_VERSION+\".mat\"\n",
    "# PARAM_FILE = \"./dnn_models/DNN_params\"+Data_VERSION+\".mat\"\n",
    "\n",
    "TrainData_FILE = \"./dnn_models/Train_datas.mat\"\n",
    "DevData_FILE = \"./dnn_models/CrossValidation_datas.mat\"\n",
    "TestData_FILE = \"./dnn_models/Test_datas.mat\"\n",
    "\n",
    "\n",
    "# Best model, after adding 1st dense layer\n",
    "MODEL_FILE = \"./dnn_models/lstm_weights\"+ Code_VERSION+\"_{epoch:02d}.h5\"\n",
    "\n",
    "#dummy save file\n",
    "SAVE_MODEL_FILE = \"./dnn_models/lstm_py_model\"+ Code_VERSION+\".h5\"\n",
    "\n",
    "# estimated real+imag for test dataset\n",
    "OUTPUT_FILE = \"./dnn_models/Real_Imag\"+Code_VERSION+\".mat\"\n",
    "\n",
    "LOG_FILE = \"./dnn_models/Log\"+Code_VERSION+\".txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files saved by Matlab reading class. Data, Parameters are read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Opts:\n",
    "#     opts_dict = dict()\n",
    "\n",
    "    def __init__(self, FILE_PARA, FILE_DATA=\"\", FILE_TEST=\"\"):\n",
    "        \n",
    "        # Basic parameters\n",
    "        with h5py.File(FILE_PARA, 'r') as f:\n",
    "            key_list = list(f.keys())\n",
    "            print('Opt keys:')\n",
    "\n",
    "            for e,(k, v) in enumerate(f['opts'].items()):\n",
    "\n",
    "                print(\"{0}->{1},\".format(e,k), end=\"\")\n",
    "\n",
    "                if k == 'ARMA_order':\n",
    "                    self.ARMA_order = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.ARMA_order\n",
    "                elif k == 'ada_grad_eps':\n",
    "                    self.ada_grad_eps = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.ada_grad_eps\n",
    "                elif k == 'ada_sgd_scale':\n",
    "                    self.ada_sgd_scale = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.ada_sgd_scale\n",
    "                elif k == 'change_momentum_point':\n",
    "                    self.change_momentum_point = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.change_momentum_point\n",
    "                elif k == 'cost_function':\n",
    "                    self.cost_function = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.cost_function += chr(c[0])\n",
    "\n",
    "#                     self.opts_dict[k] = self.cost_function\n",
    "\n",
    "                elif k == 'cv_interval':\n",
    "                    self.cv_interval = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.cv_interval\n",
    "                elif k == 'dim_input':\n",
    "                    self.dim_input = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.dim_input\n",
    "                    print(\"(\",k,\"=\",self.dim_input,\")\",end=\" \")\n",
    "                elif k == 'dim_output':\n",
    "                    self.dim_output = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.dim_output\n",
    "                    print(\"(\",k,\"=\",self.dim_output,\")\",end=\" \")\n",
    "                elif k == 'drop_ratio':\n",
    "                    self.drop_ratio = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.drop_ratio\n",
    "                elif k == 'eval_on_gpu':\n",
    "                    self.eval_on_gpu = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.eval_on_gpu\n",
    "                elif k == 'final_momentum':\n",
    "                    self.final_momentum = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.final_momentum\n",
    "                elif k == 'hid_struct':\n",
    "                    self.hid_struct = np.array(v)\n",
    "#                     self.opts_dict[k] = self.hid_struct\n",
    "                elif k == 'initial_momentum':\n",
    "                    self.initial_momentum = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.initial_momentum\n",
    "                elif k == 'isDropout':\n",
    "                    self.isDropout = 0\n",
    "#                     self.opts_dict[k] = self.isDropout\n",
    "                elif k == 'isDropoutInput':\n",
    "                    self.isDropoutInput = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isDropoutInput\n",
    "                elif k == 'isGPU':\n",
    "                    self.isGPU = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isGPU\n",
    "                elif k == 'isNormalize':\n",
    "                    self.isNormalize = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isNormalize\n",
    "                elif k == 'isPretrain':\n",
    "                    self.isPretrain = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isPretrain\n",
    "                elif k == 'learner':\n",
    "                    self.learner = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.learner += chr(c[0])\n",
    "#                     self.opts_dict[k] = self.learner\n",
    "\n",
    "                elif k == 'net_struct':\n",
    "                    self.net_struct = np.array(v)\n",
    "#                     for n_s in np.array(v):\n",
    "#                         print('Opts Net Stuct:',n_s[0])\n",
    "#                     self.opts_dict[k] = self.net_struct\n",
    "                elif k == 'rbm_batch_size':\n",
    "                    self.rbm_batch_size = int(np.array(v)[0][0])\n",
    "                    print(\"(self.rbm_batch_size=\",self.rbm_batch_size,\")\",end=\" \")\n",
    "#                     self.opts_dict[k] = self.rbm_batch_size\n",
    "                elif k == 'rbm_learn_rate_binary':\n",
    "                    self.rbm_learn_rate_binary = np.array(v)\n",
    "#                     self.opts_dict[k] = self.rbm_learn_rate_binary\n",
    "                elif k == 'rbm_learn_rate_real':\n",
    "                    self.rbm_learn_rate_real = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.rbm_learn_rate_real\n",
    "                elif k == 'rbm_max_epoch':\n",
    "                    self.rbm_max_epoch = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.rbm_max_epoch\n",
    "                elif k == 'save_on_fly':\n",
    "                    self.save_on_fly = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.save_on_fly\n",
    "                elif k == 'sgd_batch_size':\n",
    "                    self.sgd_batch_size = int(np.array(v)[0][0]) # BATCH_SIZE for training net\n",
    "                    print(\"(self.sgd_batch_size:\",self.sgd_batch_size,\")\",end=\" \")\n",
    "#                     self.opts_dict[k] = self.sgd_batch_size\n",
    "                elif k == 'sgd_learn_rate':\n",
    "                    self.sgd_learn_rate = np.array(v)\n",
    "#                     self.opts_dict[k] = self.sgd_learn_rate\n",
    "                elif k == 'sgd_max_epoch':\n",
    "                    self.sgd_max_epoch = int(np.array(v)[0][0])\n",
    "                    # self.opts_dict[k] = self.sgd_max_epoch\n",
    "                elif k == 'split_tanh1_c1':\n",
    "                    self.split_tanh1_c1 = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.split_tanh1_c1\n",
    "                elif k == 'split_tanh1_c2':\n",
    "                    self.split_tanh1_c2 = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.split_tanh1_c2\n",
    "                elif k == 'unit_type_hidden':\n",
    "                    self.unit_type_hidden = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.unit_type_hidden += chr(c[0])\n",
    "\n",
    "                elif k == 'unit_type_output':\n",
    "                    self.unit_type_output = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.unit_type_output += chr(c[0])\n",
    "\n",
    "                        \n",
    "\n",
    "    # Read different data files (Train, Dev, Test)\n",
    "    def read_data(self, FILE_NAME, DATA_TYPE):\n",
    "        print(FILE_NAME, os.path.isfile(FILE_NAME))\n",
    "\n",
    "        with h5py.File(FILE_NAME, 'r') as f:\n",
    "            # print('\\n\\nFile name <{0}>\\nOpt h5py keys (Total {1}):'.format(FILE_TEST,len(f.keys())) )\n",
    "\n",
    "            for k, v in f.items():\n",
    "                if DATA_TYPE.lower() == 'train':\n",
    "                    # Features (input)\n",
    "                    if k == 'trData':\n",
    "                        self.trData = np.transpose(np.array(v))\n",
    "                    elif k == 'trLabel_r':\n",
    "                        self.trLabel_r = np.transpose(np.array(v))\n",
    "                    elif k == 'trLabel_i':\n",
    "                        self.trLabel_i = np.transpose(np.array(v))\n",
    "                    elif k == 'numframes':\n",
    "                        self.trNumframes = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_r':\n",
    "                        self.trCleanSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_i':\n",
    "                        self.trCleanSpec_i = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_r':\n",
    "                        self.trMixtureSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_i':\n",
    "                        self.trMixtureSpec_i = np.transpose(np.array(v))\n",
    "                \n",
    "                elif DATA_TYPE.lower() == 'dev':\n",
    "                    # Features (input)\n",
    "                    if k == 'cvData':\n",
    "                        self.cvData = np.transpose(np.array(v))\n",
    "                    elif k == 'cvLabel_r':\n",
    "                        self.cvLabel_r = np.transpose(np.array(v))\n",
    "                    elif k == 'cvLabel_i':\n",
    "                        self.cvLabel_i = np.transpose(np.array(v))\n",
    "                    elif k == 'numframes':\n",
    "                        self.cvNumframes = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_r':\n",
    "                        self.cvCleanSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_i':\n",
    "                        self.cvCleanSpec_i = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_r':\n",
    "                        self.cvMixtureSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_i':\n",
    "                        self.cvMixtureSpec_i = np.transpose(np.array(v))\n",
    "            \n",
    "                elif DATA_TYPE.lower() == 'test':\n",
    "                    # Features (input)\n",
    "                    if k == 'teData':\n",
    "                        self.teData = np.transpose(np.array(v))\n",
    "                    elif k == 'teLabel_r':\n",
    "                        self.teLabel_r = np.transpose(np.array(v))\n",
    "                    elif k == 'teLabel_i':\n",
    "                        self.teLabel_i = np.transpose(np.array(v))\n",
    "                    elif k == 'numframes':\n",
    "                        self.teNumframes = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_r':\n",
    "                        self.teCleanSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_i':\n",
    "                        self.teCleanSpec_i = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_r':\n",
    "                        self.teMixtureSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_i':\n",
    "                        self.teMixtureSpec_i = np.transpose(np.array(v))\n",
    "            \n",
    "            # Display statistics\n",
    "            if DATA_TYPE.lower() == 'train':\n",
    "                self.trLabel = np.concatenate((self.trLabel_r, self.trLabel_i), axis=1)\n",
    "#                 self.display_stat(DATA_TYPE=\"train\")\n",
    "                \n",
    "            elif DATA_TYPE.lower() == 'dev':\n",
    "                self.cvLabel = np.concatenate((self.cvLabel_r, self.cvLabel_i), axis=1)\n",
    "#                 self.display_stat(DATA_TYPE=\"dev\")\n",
    "                \n",
    "            elif DATA_TYPE.lower() == 'test':\n",
    "                self.teLabel = np.concatenate((self.teLabel_r, self.teLabel_i), axis=1)\n",
    "#                 self.display_stat(DATA_TYPE=\"test\")\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Display the simple statistics of Data (train, dev, test)\n",
    "    def display_stat(self, DATA_TYPE):\n",
    "        if DATA_TYPE.lower() == 'train':\n",
    "            print(\"\\nSummary->[TRAIN DATA]\")\n",
    "            print(\"trNumframes.shape=\", self.trNumframes.shape)\n",
    "            \n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trData)\n",
    "            print(\"trData.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trLabel_r)\n",
    "            print(\"trLabel_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trLabel_i)\n",
    "            print(\"trLabel_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trLabel)\n",
    "            print(\"trLabel.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "#             shp, m, v, s, mn, mx = self.data_stat(self.trCleanSpec_r)\n",
    "#             print(\"trCleanSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "#                               format(shp, m, v, s, mn, mx) )\n",
    "#             shp, m, v, s, mn, mx = self.data_stat(self.trCleanSpec_i)\n",
    "#             print(\"trCleanSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "#                               format(shp, m, v, s, mn, mx) )\n",
    "#             shp, m, v, s, mn, mx = self.data_stat(self.trMixtureSpec_r)\n",
    "#             print(\"trMixtureSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "#                               format(shp, m, v, s, mn, mx) )\n",
    "#             shp, m, v, s, mn, mx = self.data_stat(self.trMixtureSpec_i)\n",
    "#             print(\"trMixtureSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "#                               format(shp, m, v, s, mn, mx) )\n",
    "            \n",
    "        elif DATA_TYPE.lower() == 'dev':\n",
    "            print(\"\\nSummary->[DEV DATA]\")\n",
    "            print(\"cvNumframes.shape=\", self.cvNumframes.shape)\n",
    "            \n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvData)\n",
    "            print(\"cvData.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f}-{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvLabel_r)\n",
    "            print(\"cvLabel_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvLabel_i)\n",
    "            print(\"cvLabel_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvLabel)\n",
    "            print(\"cvLabel.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvCleanSpec_r)\n",
    "            print(\"cvCleanSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvCleanSpec_i)\n",
    "            print(\"cvCleanSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvMixtureSpec_r)\n",
    "            print(\"cvMixtureSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvMixtureSpec_i)\n",
    "            print(\"cvMixtureSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "\n",
    "            \n",
    "        elif DATA_TYPE.lower() == 'test':\n",
    "            print(\"\\nSummary->[TEST DATA]\")\n",
    "            print(\"teNumframes.shape=\", self.teNumframes.shape)\n",
    "            \n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teData)\n",
    "            print(\"teData.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teLabel_r)\n",
    "            print(\"teLabel_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teLabel_i)\n",
    "            print(\"teLabel_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teLabel)\n",
    "            print(\"teLabel.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teCleanSpec_r)\n",
    "            print(\"teCleanSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teCleanSpec_i)\n",
    "            print(\"teCleanSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teMixtureSpec_r)\n",
    "            print(\"teMixtureSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teMixtureSpec_i)\n",
    "            print(\"teMixtureSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "                        \n",
    "    # Helper function for display, returns actual values\n",
    "    def data_stat(self, data):\n",
    "        return data.shape,np.mean(data),np.var(data),np.std(data),np.amin(data),np.amax(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt keys:\n",
      "0->ARMA_order,1->ada_grad_eps,2->ada_sgd_scale,3->change_momentum_point,4->cost_function,5->cv_interval,6->dim_input,( dim_input = 1230 ) 7->dim_output,( dim_output = 963 ) 8->drop_ratio,9->eval_on_gpu,10->final_momentum,11->hid_struct,12->initial_momentum,13->isDropout,14->isDropoutInput,15->isGPU,16->isNormalize,17->isPretrain,18->learner,19->net_struct,20->rbm_batch_size,(self.rbm_batch_size= 1024 ) 21->rbm_learn_rate_binary,22->rbm_learn_rate_real,23->rbm_max_epoch,24->save_on_fly,25->sgd_batch_size,(self.sgd_batch_size: 1024 ) 26->sgd_learn_rate,27->sgd_max_epoch,28->split_tanh1_c1,29->split_tanh1_c2,30->tr_mu,31->tr_std,32->unit_type_hidden,33->unit_type_output,"
     ]
    }
   ],
   "source": [
    "opts = Opts(PARAM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dnn_models/Train_datas.mat True\n"
     ]
    }
   ],
   "source": [
    "opts.read_data(TrainData_FILE, DATA_TYPE=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dnn_models/CrossValidation_datas.mat True\n"
     ]
    }
   ],
   "source": [
    "opts.read_data(DevData_FILE, DATA_TYPE=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dnn_models/Test_datas.mat True\n"
     ]
    }
   ],
   "source": [
    "opts.read_data(TestData_FILE, DATA_TYPE=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0134557 , -0.00549853, -0.00025761, -0.0040397 ,  0.00147402],\n",
       "       [-0.04657207,  0.03029321,  0.00073667, -0.02018796,  0.02272554],\n",
       "       [ 0.0426428 , -0.03104717,  0.01431777, -0.0314163 ,  0.06807565],\n",
       "       [-0.09032005,  0.02352479,  0.00491432,  0.04725359, -0.07824395],\n",
       "       [ 0.03109347,  0.00310555, -0.03451523,  0.0277781 , -0.00758577]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts.teCleanSpec_i[789:794, 89:94]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For RNN style 3D batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare3D_list(opts, CYCLE):\n",
    "        # TRAIN: total_num_samples = self.trData.shape[0] = 195192\n",
    "        # DEV: total_num_samples = self.trData.shape[0] = 44961\n",
    "\n",
    "        feat_vec_len = opts.dim_input # 1230\n",
    "        out_vec_len = opts.dim_output #963\n",
    "        \n",
    "        if CYCLE.lower()=='train':\n",
    "            data = opts.trData\n",
    "            label_r = opts.trLabel_r\n",
    "            label_i = opts.trLabel_i\n",
    "            numframes = opts.trNumframes\n",
    "#             mix_spec_r = opts.trMixtureSpec_r\n",
    "#             mix_spec_i = opts.trMixtureSpec_i\n",
    "            \n",
    "        elif CYCLE.lower()=='dev':\n",
    "            data = opts.cvData\n",
    "            label_r = opts.cvLabel_r\n",
    "            label_i = opts.cvLabel_i\n",
    "            numframes = opts.cvNumframes\n",
    "#             mix_spec_r = opts.cvMixtureSpec_r\n",
    "#             mix_spec_i = opts.cvMixtureSpec_i\n",
    "            \n",
    "        elif CYCLE.lower()=='test':\n",
    "            data = opts.teData\n",
    "            label_r = opts.teLabel_r\n",
    "            label_i = opts.teLabel_i\n",
    "            numframes = opts.teNumframes\n",
    "#             mix_spec_r = opts.teMixtureSpec_r\n",
    "#             mix_spec_i = opts.teMixtureSpec_i\n",
    "            \n",
    "\n",
    "        data3D, label3D_r, label3D_i = [], [], []\n",
    "        numframes = np.cumsum(numframes)\n",
    "        \n",
    "        for e, frames in enumerate(numframes):\n",
    "            frames= int(frames)\n",
    "            pre_frames= int(numframes[e-1])\n",
    "            \n",
    "            d = data[:frames] if len(data3D)==0 else data[pre_frames:frames]\n",
    "            r = label_r[:frames] if len(label3D_r)==0 else label_r[pre_frames:frames]\n",
    "            i = label_i[:frames] if len(label3D_i)==0 else label_i[pre_frames:frames]\n",
    "            \n",
    "            data3D.append( d )\n",
    "            label3D_r.append( r )\n",
    "            label3D_i.append( i )\n",
    "            \n",
    "#             print('d.shape=',d.shape, ', r.shape=',r.shape, ', i.shape=',i.shape)\n",
    "        \n",
    "        return data3D, label3D_r, label3D_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opts.batch_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch_rnn(opts, batch_size, CYCLE, maxlen=185):\n",
    "    # TRAIN: total_num_samples = self.trData.shape[0] = 1951920\n",
    "    # DEV: total_num_samples = self.trData.shape[0] = 449610\n",
    "\n",
    "    feat_vec_len = opts.dim_input #1230\n",
    "    out_vec_len = opts.dim_output #963\n",
    "\n",
    "\n",
    "    if CYCLE.lower()=='train':\n",
    "        selected_indics = np.arange(len(opts.trNumframes))\n",
    "        data3D, label3D_r, label3D_i = prepare3D_list(opts,CYCLE)\n",
    "        np.random.shuffle(selected_indics)\n",
    "\n",
    "    elif CYCLE.lower()=='dev':\n",
    "        selected_indics = np.arange(len(opts.cvNumframes))\n",
    "        data3D, label3D_r, label3D_i = prepare3D_list(opts,CYCLE)\n",
    "        np.random.shuffle(selected_indics)\n",
    "\n",
    "    elif CYCLE.lower()=='test':\n",
    "        selected_indics = np.arange(len(opts.teNumframes))\n",
    "        data3D, label3D_r, label3D_i = prepare3D_list(opts, CYCLE)\n",
    "        si = selected_indics\n",
    "\n",
    "\n",
    "    f = 0\n",
    "    while (f*batch_size) < len(selected_indics):\n",
    "\n",
    "        if CYCLE.lower()=='train'or CYCLE.lower()=='dev':\n",
    "            if (f+1)*batch_size < len(selected_indics):\n",
    "                si = selected_indics[(f*batch_size):((f+1)*batch_size)]\n",
    "            else:\n",
    "                si = selected_indics[(f*batch_size):]\n",
    "                \n",
    "        opts.batch_ids = si;\n",
    "\n",
    "            \n",
    "        x, y = None, None\n",
    "        for indx in si:\n",
    "            d = data3D[indx]\n",
    "            d = np.concatenate( (d, np.zeros((maxlen-d.shape[0],feat_vec_len))),axis=0 )\n",
    "            d = np.expand_dims(d, axis=0)\n",
    "\n",
    "            l = np.concatenate((label3D_r[indx], label3D_i[indx]), axis=1)\n",
    "            l = np.concatenate( (l, np.zeros((maxlen-l.shape[0],out_vec_len*2))),axis=0 )\n",
    "            l = np.expand_dims(l, axis=0)\n",
    "\n",
    "            x = d if x is None else np.concatenate( (x,d),axis=0 )\n",
    "            y = l if y is None else np.concatenate( (y,l),axis=0 )\n",
    "\n",
    "        f += 1\n",
    "\n",
    "        if CYCLE.lower()=='test':\n",
    "            \n",
    "            with open(LOG_FILE,'a+') as log:\n",
    "                log.write('{5} {0}-CYCLE, batch_id:{1}, #{2}samples, x.shape:{3}, y.shape:{4}'.\n",
    "                    format(CYCLE, f, len(si), x.shape, y.shape, strftime(\"%Y-%m-%d %H:%M:%S\",gmtime())))\n",
    "            \n",
    "            return x,y\n",
    "\n",
    "        if x.shape[0]<batch_size:\n",
    "            x = np.concatenate( (x, np.zeros((batch_size-x.shape[0],maxlen,feat_vec_len))), axis=0)\n",
    "            y = np.concatenate( (y, np.zeros((batch_size-y.shape[0],maxlen,out_vec_len*2))), axis=0)\n",
    "        #print(\"x:\",x.shape, \", y:\", y.shape)  \n",
    "        \n",
    "        with open(LOG_FILE,'a+') as log:\n",
    "            log.write('{5} {0}-CYCLE, batch_id:{1:0002}, #{2}samples, x.shape:{3}, y.shape:{4}\\n'.\n",
    "                    format(CYCLE, f, len(si), x.shape, y.shape, strftime(\"%Y-%m-%d %H:%M:%S\",gmtime())))\n",
    "            \n",
    "#         print('x=',x.shape, ',y=',y.shape, end=\" \")    \n",
    "        if CYCLE.lower()!='test':\n",
    "            yield x,y\n",
    "    \n",
    "    \n",
    "#     if CYCLE.lower()=='test':\n",
    "#             return x,y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch id 0 [ 3032 12753  4801 14350  7502] [[ 113.]\n",
      " [ 138.]\n",
      " [ 139.]\n",
      " [ 134.]\n",
      " [ 142.]]\n",
      "batch id 1 [ 9626  6052  6638  4498 14849] [[ 108.]\n",
      " [ 142.]\n",
      " [ 126.]\n",
      " [ 129.]\n",
      " [ 114.]]\n",
      "batch id 2 [  582   187  2042  7563 10383] [[ 158.]\n",
      " [ 144.]\n",
      " [ 121.]\n",
      " [ 114.]\n",
      " [ 142.]]\n",
      "batch id 3 [ 7592  9893  7291 11682  9590] [[ 120.]\n",
      " [ 136.]\n",
      " [ 113.]\n",
      " [ 140.]\n",
      " [ 131.]]\n",
      "batch id 4 [ 5798  3404 11589  3088  8493] [[ 130.]\n",
      " [ 127.]\n",
      " [ 103.]\n",
      " [ 101.]\n",
      " [ 140.]]\n",
      "batch id 5 [13361  2038  7119  1804  4663] [[ 114.]\n",
      " [ 138.]\n",
      " [ 138.]\n",
      " [ 133.]\n",
      " [  97.]]\n",
      "batch id 6 [14277  4896   370  5767  3686] [[ 143.]\n",
      " [ 126.]\n",
      " [ 156.]\n",
      " [ 128.]\n",
      " [ 132.]]\n",
      "batch id 7 [ 3271  3463  4908 11774  1171] [[ 100.]\n",
      " [ 113.]\n",
      " [ 126.]\n",
      " [ 132.]\n",
      " [ 103.]]\n",
      "batch id 8 [10119 13192  3560  7253 13107] [[ 136.]\n",
      " [ 112.]\n",
      " [ 115.]\n",
      " [ 121.]\n",
      " [ 121.]]\n",
      "batch id 9 [12139 13816  4361 10772 14786] [[ 156.]\n",
      " [ 117.]\n",
      " [ 106.]\n",
      " [ 125.]\n",
      " [ 130.]]\n",
      "batch id 10 [ 6563  2553   329  5264 13044] [[ 150.]\n",
      " [ 119.]\n",
      " [ 116.]\n",
      " [  97.]\n",
      " [ 145.]]\n"
     ]
    }
   ],
   "source": [
    "for e,[x,y] in enumerate(next_batch_rnn(opts,batch_size = 5,CYCLE='train')):\n",
    "    print('batch id', e, opts.batch_ids, opts.trNumframes[opts.batch_ids])\n",
    "    if e == 10:\n",
    "        break\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch id 0 [3169 1356 2611 1156 2074] [[ 134.]\n",
      " [ 160.]\n",
      " [ 141.]\n",
      " [ 141.]\n",
      " [ 138.]]\n",
      "batch id 1 [2506 2514  129 2776 2240] [[ 114.]\n",
      " [ 114.]\n",
      " [ 135.]\n",
      " [ 118.]\n",
      " [ 174.]]\n",
      "batch id 2 [2347 3027 1009 1030 1139] [[ 161.]\n",
      " [ 137.]\n",
      " [ 130.]\n",
      " [ 136.]\n",
      " [ 139.]]\n",
      "batch id 3 [1465 1125  624 1144   20] [[ 106.]\n",
      " [ 139.]\n",
      " [ 102.]\n",
      " [ 141.]\n",
      " [ 130.]]\n",
      "batch id 4 [3182 1829  257  609 2033] [[ 116.]\n",
      " [ 130.]\n",
      " [ 151.]\n",
      " [ 102.]\n",
      " [ 114.]]\n",
      "batch id 5 [1011  497 1771  107 2434] [[ 130.]\n",
      " [ 129.]\n",
      " [ 145.]\n",
      " [ 128.]\n",
      " [ 176.]]\n",
      "batch id 6 [ 599 3217 2755  582  266] [[ 139.]\n",
      " [ 103.]\n",
      " [ 115.]\n",
      " [ 139.]\n",
      " [ 151.]]\n",
      "batch id 7 [1839  280  498 3145 1561] [[ 131.]\n",
      " [ 142.]\n",
      " [ 129.]\n",
      " [ 119.]\n",
      " [ 133.]]\n",
      "batch id 8 [ 473  867 1200 2967 2739] [[ 154.]\n",
      " [ 125.]\n",
      " [ 134.]\n",
      " [ 132.]\n",
      " [ 115.]]\n",
      "batch id 9 [1741 2907  219 1457  476] [[ 151.]\n",
      " [  99.]\n",
      " [ 158.]\n",
      " [ 106.]\n",
      " [ 154.]]\n",
      "batch id 10 [1430 1513 1032  946 1136] [[ 149.]\n",
      " [ 126.]\n",
      " [ 136.]\n",
      " [ 139.]\n",
      " [ 139.]]\n"
     ]
    }
   ],
   "source": [
    "for e,[x,y] in enumerate(next_batch_rnn(opts,batch_size = 5,CYCLE='dev')):\n",
    "    print('batch id', e, opts.batch_ids, opts.cvNumframes[opts.batch_ids])\n",
    "    if e == 10:\n",
    "        break\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-edff2f9f10cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_batch_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCYCLE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrNumframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-8910135b00ed>\u001b[0m in \u001b[0;36mnext_batch_rnn\u001b[0;34m(opts, batch_size, CYCLE, maxlen)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e,[x,y] in enumerate(next_batch_rnn(opts,batch_size = 5,CYCLE='test')):\n",
    "    print('batch id', e, opts.batch_ids, opts.trNumframes[opts.batch_ids])\n",
    "    if e == 10:\n",
    "        break\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a,b = next_batch_rnn(opts,batch_size = 5,CYCLE='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Opts' object has no attribute 'si'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0cfafb0fc30e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Opts' object has no attribute 'si'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss_train(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    numframes = opts.trNumframes[opts.batch_ids]\n",
    "    numframes = [int(f[0]) for f in numframes]\n",
    "    \n",
    "    cost_r = K.variable(value=0)\n",
    "    cost_i = K.variable(value=0)\n",
    "    for n in numframes:\n",
    "        cost_r += K.sum(K.square(yTrue[:n, :(c//2)]- yPred[:n, :(c//2)]))\n",
    "        cost_i += K.sum(K.square(yTrue[:n, (c//2):]- yPred[:n, (c//2):]))\n",
    "\n",
    "#     cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "#     cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss_val(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    numframes = opts.cvNumframes[opts.batch_ids]\n",
    "    numframes = [int(f[0]) for f in numframes]\n",
    "    \n",
    "    cost_r = K.variable(value=0)\n",
    "    cost_i = K.variable(value=0)\n",
    "    for n in numframes:\n",
    "        cost_r += K.sum(K.square(yTrue[:n, :(c//2)]- yPred[:n, :(c//2)]))\n",
    "        cost_i += K.sum(K.square(yTrue[:n, (c//2):]- yPred[:n, (c//2):]))\n",
    "\n",
    "#     cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "#     cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss_test(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    numframes = opts.teNumframes[opts.batch_ids]\n",
    "    numframes = [int(f[0]) for f in numframes]\n",
    "    \n",
    "    cost_r = K.variable(value=0)\n",
    "    cost_i = K.variable(value=0)\n",
    "    for n in numframes:\n",
    "        cost_r += K.sum(K.square(yTrue[:n, :(c//2)]- yPred[:n, :(c//2)]))\n",
    "        cost_i += K.sum(K.square(yTrue[:n, (c//2):]- yPred[:n, (c//2):]))\n",
    "\n",
    "#     cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "#     cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossFunctionCallback(Callback):\n",
    "    def __init__(self, model, opts):\n",
    "        self.model = model\n",
    "        self.opts = opts\n",
    "        pass\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        self.model.loss = customLoss_train\n",
    "        pass\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.model.loss = customLoss_val\n",
    "        pass\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        # print('-> on_train_end=',self.params)\n",
    "        self.model.loss = customLoss_test\n",
    "        pass\n",
    "        \n",
    " \n",
    "    def on_train_begin(self, logs={}):\n",
    "        pass\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        pass\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### RNN variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Max_RNN = 256\n",
    "\n",
    "# feat_vec_len = 1230\n",
    "# out_vec_len = 963\n",
    "\n",
    "# epochs = 50\n",
    "# train_size = 15000\n",
    "# dev_size = 3300\n",
    "# batch_size = 256\n",
    "\n",
    "\n",
    "batch_size = 25 #opts.sgd_batch_size\n",
    "epochs = 50\n",
    "\n",
    "Max_RNN = 256\n",
    "\n",
    "'''\n",
    "n_train, n_train_dim = <number of samples for training, input dimentions>, final will be (1951920, 1230)\n",
    "n_dev, n_dev_dim = <number of samples for development, input dimentions>, final will be (449610, 1230)\n",
    "n_test, n_test_dim =<number of samples for testing, input dimentions>, final will be (72440, 1230)\n",
    "\n",
    "'''\n",
    "n_train, n_train_dim = (1951920, 1230) # opts.trData.shape = (1951920, 1230)\n",
    "n_dev, n_dev_dim = (449610, 1230) # opts.cvData.shape =(449610, 1230)\n",
    "n_test, n_test_dim = (72440, 1230) # opts.teData.shape =(72440, 1230)\n",
    "\n",
    "n_train_files = 15000 #15000\n",
    "n_dev_files = 3300 # 3300\n",
    "n_test_files = 545\n",
    "\n",
    "n_classes = (963 + 963)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 1\n",
    "single bidirectional GRU layer\n",
    "\n",
    "real+img (963+963)=1926-d output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 256, 256)          1522688   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 256, 256)          525312    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256, 1926)         494982    \n",
      "=================================================================\n",
      "Total params: 2,542,982\n",
      "Trainable params: 2,542,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4ba79d182148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train_files\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_dev_files\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     verbose=1, callbacks=callbacks)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_MODEL_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1108\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m                 self.total_loss)\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, params, constraints, loss)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mm_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0mv_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm_t\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    637\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    111\u001b[0m                                          as_ref=False):\n\u001b[1;32m    112\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/home/knayem/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(Max_RNN, return_sequences=True, input_shape=(Max_RNN,opts.dim_input)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(Max_RNN, return_sequences=True, input_shape=(Max_RNN,opts.dim_input)))\n",
    "# model.add(Bidirectional(LSTM(Max_RNN, return_sequences=True), input_shape=(Max_RNN,feat_vec_len)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Bidirectional(GRU(Max_RNN, return_sequences=True, stateful=True)))\n",
    "model.add(Dense(n_classes, activation='linear'))\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_acc', patience=2, min_delta=1e-6, verbose=1, mode='auto'), \n",
    "             ModelCheckpoint(filepath= MODEL_FILE, monitor='val_acc', save_best_only=True),\n",
    "            LossFunctionCallback(model,opts)]\n",
    "\n",
    "\n",
    "model.compile(loss = customLoss_train, optimizer = 'adam', metrics = ['accuracy','mse', 'mae', 'mape', 'cosine'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit_generator(next_batch_rnn(opts,batch_size,maxlen=Max_RNN,CYCLE='train'), \n",
    "                    validation_data=next_batch_rnn(opts,batch_size,maxlen=Max_RNN,CYCLE='dev'),\n",
    "                    epochs=epochs, steps_per_epoch=n_train_files//batch_size, \n",
    "                    validation_steps=n_dev_files//batch_size, \n",
    "                    verbose=1, callbacks=callbacks)\n",
    "\n",
    "model.save(SAVE_MODEL_FILE)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-674b27952856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot metrics                                                       \n",
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.suptitle(\"Train result\")\n",
    "\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "# plt.plot(history.history['val_mean_absolute_percentage_error'])\n",
    "# plt.plot(history.history['val_cosine_proximity'])\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['acc'])\n",
    "\n",
    "# plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    "# plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "# plt.plot(history.history['cosine_proximity'])\n",
    "                                                           \n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"numbers\")\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = next_batch_rnn(opts, batch_size, CYCLE='test', maxlen=Max_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEST_MODEL_FILE = \"./dnn_models/lstm_weights1\"+ Code_VERSION+\"_{epoch:02d}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(MODEL_FILE)\n",
    "y_hat = model.predict(x, batch_size=x.shape[0], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.savemat(OUTPUT_FILE, {'y_hat':y_hat})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
