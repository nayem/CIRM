{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LSTM Series (working)\n",
    "\n",
    "** - Simple LSTM  **\n",
    "\n",
    "** - Train and Dev different loss functions **\n",
    "\n",
    "** - Adam Optimizer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,Callback\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configuration to control GPU use\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.33\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read parameters from .mat files\n",
    "save in Opt object"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'_e12v1' -> 2 lstm layers, batch size 25, 256 nodes\n",
    "'_e12v2' -> 2 lstm layers with a dropout layer, batch size 25, 256 nodes\n",
    "\n",
    "'_e12v3' -> 2 BLSTM layers, batch size 25, 256 nodes\n",
    "'_e12v4' -> 2 lstm layers with a dropout layer, batch size 25, 256 nodes\n",
    "\n",
    "'_e13v1' -> 2 lstm layers, batch size 25, 256 nodes, signal approximation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Param_VERSION = '_e12v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_VERSION = \"_e10v5\"\n",
    "Test_Data_VERSION = '_e04v2_nf'\n",
    "\n",
    "Code_VERSION = \"_e12v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DNN_DATA_FILE = \"./dnn_models/DNN_datas\"+ Data_VERSION+\".mat\"\n",
    "DNN_TEST_FILE = \"./dnn_models/Test_datas\"+Test_Data_VERSION+\".mat\"\n",
    "\n",
    "PARAM_FILE = \"./dnn_models/DNN_params.mat\"\n",
    "# PARAM_FILE = \"./dnn_models/DNN_params\"+Data_VERSION+\".mat\"\n",
    "\n",
    "TrainData_FILE = \"./dnn_models/Train_datas.mat\"\n",
    "DevData_FILE = \"./dnn_models/CrossValidation_datas.mat\"\n",
    "TestData_FILE = \"./dnn_models/Test_datas.mat\"\n",
    "\n",
    "\n",
    "# Best model, after adding 1st dense layer\n",
    "MODEL_FILE = \"./dnn_models/lstm_weights\"+ Code_VERSION+\"_{epoch:02d}.h5\"\n",
    "\n",
    "#dummy save file\n",
    "SAVE_MODEL_FILE = \"./dnn_models/lstm_py_model\"+ Code_VERSION+\".h5\"\n",
    "\n",
    "# estimated real+imag for test dataset\n",
    "OUTPUT_FILE = \"./dnn_models/Real_Imag\"+Code_VERSION+\".mat\"\n",
    "\n",
    "LOG_FILE = \"./dnn_models/Log\"+Code_VERSION+\".txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files saved by Matlab reading class. Data, Parameters are read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Opts:\n",
    "#     opts_dict = dict()\n",
    "\n",
    "    def __init__(self, FILE_PARA, FILE_DATA=\"\", FILE_TEST=\"\"):\n",
    "        \n",
    "        # Basic parameters\n",
    "        with h5py.File(FILE_PARA, 'r') as f:\n",
    "            key_list = list(f.keys())\n",
    "            print('Opt keys:')\n",
    "\n",
    "            for e,(k, v) in enumerate(f['opts'].items()):\n",
    "\n",
    "                print(\"{0}->{1},\".format(e,k), end=\"\")\n",
    "\n",
    "                if k == 'ARMA_order':\n",
    "                    self.ARMA_order = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.ARMA_order\n",
    "                elif k == 'ada_grad_eps':\n",
    "                    self.ada_grad_eps = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.ada_grad_eps\n",
    "                elif k == 'ada_sgd_scale':\n",
    "                    self.ada_sgd_scale = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.ada_sgd_scale\n",
    "                elif k == 'amra_order':\n",
    "                    self.amra_order = int(np.array(v)[0][0])\n",
    "                elif k == 'change_momentum_point':\n",
    "                    self.change_momentum_point = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.change_momentum_point\n",
    "                elif k == 'clip_level':\n",
    "                    self.clip_level = int(np.array(v)[0][0])\n",
    "                elif k == 'cost_function':\n",
    "                    self.cost_function = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.cost_function += chr(c[0])\n",
    "\n",
    "#                     self.opts_dict[k] = self.cost_function\n",
    "\n",
    "                elif k == 'cv_interval':\n",
    "                    self.cv_interval = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.cv_interval\n",
    "                elif k == 'dim_input':\n",
    "                    self.dim_input = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.dim_input\n",
    "                    print(\"(\",k,\"=\",self.dim_input,\")\",end=\" \")\n",
    "                elif k == 'dim_output':\n",
    "                    self.dim_output = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.dim_output\n",
    "                    print(\"(\",k,\"=\",self.dim_output,\")\",end=\" \")\n",
    "                elif k == 'drop_ratio':\n",
    "                    self.drop_ratio = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.drop_ratio\n",
    "                elif k == 'eval_on_gpu':\n",
    "                    self.eval_on_gpu = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.\n",
    "                elif k == 'feawin':\n",
    "                    self.feawin = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.feawin\n",
    "                elif k == 'final_momentum':\n",
    "                    self.final_momentum = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.final_momentum\n",
    "                elif k == 'Fs':\n",
    "                    self.Fs = int(np.array(v)[0][0])\n",
    "                elif k == 'fRange':\n",
    "                    self.fRange = int(np.array(v)[0][0])\n",
    "                elif k == 'hid_struct':\n",
    "                    self.hid_struct = np.array(v)\n",
    "#                     self.opts_dict[k] = self.hid_struct\n",
    "                elif k == 'hopsize':\n",
    "                    self.hopsize = int(np.array(v)[0][0])\n",
    "                elif k == 'initial_momentum':\n",
    "                    self.initial_momentum = np.array(v)[0][0]\n",
    "#                     self.opts_dict[k] = self.initial_momentum\n",
    "                elif k == 'isDropout':\n",
    "                    self.isDropout = 0\n",
    "#                     self.opts_dict[k] = self.isDropout\n",
    "                elif k == 'isDropoutInput':\n",
    "                    self.isDropoutInput = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isDropoutInput\n",
    "                elif k == 'isGPU':\n",
    "                    self.isGPU = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isGPU\n",
    "                elif k == 'isNormalize':\n",
    "                    self.isNormalize = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isNormalize\n",
    "                elif k == 'isPretrain':\n",
    "                    self.isPretrain = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.isPretrain\n",
    "                elif k == 'labwin':\n",
    "                    self.labwin = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.labwin\n",
    "                elif k == 'labeltype':\n",
    "                    self.labeltype = int(np.array(v)[0][0])\n",
    "                elif k == 'labcompress':\n",
    "                    self.labcompress = int(np.array(v)[0][0])\n",
    "                elif k == 'learner':\n",
    "                    self.learner = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.learner += chr(c[0])\n",
    "#                     self.opts_dict[k] = self.learner\n",
    "                elif k == 'logistic_max':\n",
    "                    self.logistic_max = int(np.array(v)[0][0])\n",
    "                elif k == 'logistic_steep':\n",
    "                    self.logistic_max = int(np.array(v)[0][0])\n",
    "                elif k == 'net_struct':\n",
    "                    self.net_struct = np.array(v)\n",
    "#                     for n_s in np.array(v):\n",
    "#                         print('Opts Net Stuct:',n_s[0])\n",
    "#                     self.opts_dict[k] = self.net_struct\n",
    "                elif k == 'noise':\n",
    "                    self.noise = int(np.array(v)[0][0])\n",
    "                elif k == 'nfft':\n",
    "                    self.nfft = int(np.array(v)[0][0])\n",
    "                elif k == 'numGammatoneChans':\n",
    "                    self.numGammatoneChans = int(np.array(v)[0][0])\n",
    "                elif k == 'overlap':\n",
    "                    self.overlap = int(np.array(v)[0][0])\n",
    "                elif k == 'overlap_len':\n",
    "                    self.overlap_len = int(np.array(v)[0][0])\n",
    "                elif k == 'rbm_batch_size':\n",
    "                    self.rbm_batch_size = int(np.array(v)[0][0])\n",
    "                    print(\"(self.rbm_batch_size=\",self.rbm_batch_size,\")\",end=\" \")\n",
    "#                     self.opts_dict[k] = self.rbm_batch_size\n",
    "                elif k == 'rbm_learn_rate_binary':\n",
    "                    self.rbm_learn_rate_binary = np.array(v)\n",
    "#                     self.opts_dict[k] = self.rbm_learn_rate_binary\n",
    "                elif k == 'rbm_learn_rate_real':\n",
    "                    self.rbm_learn_rate_real = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.rbm_learn_rate_real\n",
    "                elif k == 'rbm_max_epoch':\n",
    "                    self.rbm_max_epoch = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.rbm_max_epoch\n",
    "                elif k == 'save_on_fly':\n",
    "                    self.save_on_fly = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.save_on_fly\n",
    "                elif k == 'sgd_batch_size':\n",
    "                    self.sgd_batch_size = int(np.array(v)[0][0]) # BATCH_SIZE for training net\n",
    "                    print(\"(self.sgd_batch_size:\",self.sgd_batch_size,\")\",end=\" \")\n",
    "#                     self.opts_dict[k] = self.sgd_batch_size\n",
    "                elif k == 'sgd_learn_rate':\n",
    "                    self.sgd_learn_rate = np.array(v)\n",
    "#                     self.opts_dict[k] = self.sgd_learn_rate\n",
    "                elif k == 'sgd_max_epoch':\n",
    "                    self.sgd_max_epoch = int(np.array(v)[0][0])\n",
    "                    # self.opts_dict[k] = self.sgd_max_epoch\n",
    "                elif k == 'split_tanh1_c1':\n",
    "                    self.split_tanh1_c1 = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.split_tanh1_c1\n",
    "                elif k == 'split_tanh1_c2':\n",
    "                    self.split_tanh1_c2 = int(np.array(v)[0][0])\n",
    "#                     self.opts_dict[k] = self.split_tanh1_c2\n",
    "                elif k == 'unit_type_hidden':\n",
    "                    self.unit_type_hidden = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.unit_type_hidden += chr(c[0])\n",
    "\n",
    "                elif k == 'unit_type_output':\n",
    "                    self.unit_type_output = \"\"\n",
    "                    for c in np.array(v):\n",
    "                        self.unit_type_output += chr(c[0])\n",
    "                elif k == 'winlen':\n",
    "                    self.winlen = int(np.array(v)[0][0])\n",
    "                elif k == 'feawin':\n",
    "                    self.feawin = int(np.array(v)[0][0])\n",
    "\n",
    "                        \n",
    "\n",
    "    # Read different data files (Train, Dev, Test)\n",
    "    def read_data(self, FILE_NAME, DATA_TYPE):\n",
    "        print(FILE_NAME, os.path.isfile(FILE_NAME))\n",
    "\n",
    "        with h5py.File(FILE_NAME, 'r') as f:\n",
    "            # print('\\n\\nFile name <{0}>\\nOpt h5py keys (Total {1}):'.format(FILE_TEST,len(f.keys())) )\n",
    "\n",
    "            for k, v in f.items():\n",
    "                if DATA_TYPE.lower() == 'train':\n",
    "                    # Features (input)\n",
    "                    if k == 'trData':\n",
    "                        self.trData = np.transpose(np.array(v))\n",
    "                    elif k == 'trLabel_r':\n",
    "                        self.trLabel_r = np.transpose(np.array(v))\n",
    "                    elif k == 'trLabel_i':\n",
    "                        self.trLabel_i = np.transpose(np.array(v))\n",
    "                    elif k == 'numframes':\n",
    "                        self.trNumframes = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_r':\n",
    "                        self.trCleanSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_i':\n",
    "                        self.trCleanSpec_i = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_r':\n",
    "                        self.trMixtureSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_i':\n",
    "                        self.trMixtureSpec_i = np.transpose(np.array(v))\n",
    "                \n",
    "                elif DATA_TYPE.lower() == 'dev':\n",
    "                    # Features (input)\n",
    "                    if k == 'cvData':\n",
    "                        self.cvData = np.transpose(np.array(v))\n",
    "                    elif k == 'cvLabel_r':\n",
    "                        self.cvLabel_r = np.transpose(np.array(v))\n",
    "                    elif k == 'cvLabel_i':\n",
    "                        self.cvLabel_i = np.transpose(np.array(v))\n",
    "                    elif k == 'numframes':\n",
    "                        self.cvNumframes = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_r':\n",
    "                        self.cvCleanSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_i':\n",
    "                        self.cvCleanSpec_i = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_r':\n",
    "                        self.cvMixtureSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_i':\n",
    "                        self.cvMixtureSpec_i = np.transpose(np.array(v))\n",
    "            \n",
    "                elif DATA_TYPE.lower() == 'test':\n",
    "                    # Features (input)\n",
    "                    if k == 'teData':\n",
    "                        self.teData = np.transpose(np.array(v))\n",
    "                    elif k == 'teLabel_r':\n",
    "                        self.teLabel_r = np.transpose(np.array(v))\n",
    "                    elif k == 'teLabel_i':\n",
    "                        self.teLabel_i = np.transpose(np.array(v))\n",
    "                    elif k == 'numframes':\n",
    "                        self.teNumframes = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_r':\n",
    "                        self.teCleanSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_clean_i':\n",
    "                        self.teCleanSpec_i = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_r':\n",
    "                        self.teMixtureSpec_r = np.transpose(np.array(v))\n",
    "                    elif k == 'spec_mixture_i':\n",
    "                        self.teMixtureSpec_i = np.transpose(np.array(v))\n",
    "            \n",
    "            # Display statistics\n",
    "            if DATA_TYPE.lower() == 'train':\n",
    "                self.trLabel = np.concatenate((self.trLabel_r, self.trLabel_i), axis=1)\n",
    "                self.display_stat(DATA_TYPE=\"train\")\n",
    "                \n",
    "            elif DATA_TYPE.lower() == 'dev':\n",
    "                self.cvLabel = np.concatenate((self.cvLabel_r, self.cvLabel_i), axis=1)\n",
    "                self.display_stat(DATA_TYPE=\"dev\")\n",
    "                \n",
    "            elif DATA_TYPE.lower() == 'test':\n",
    "                self.teLabel = np.concatenate((self.teLabel_r, self.teLabel_i), axis=1)\n",
    "                self.display_stat(DATA_TYPE=\"test\")\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Display the simple statistics of Data (train, dev, test)\n",
    "    def display_stat(self, DATA_TYPE):\n",
    "        if DATA_TYPE.lower() == 'train':\n",
    "            print(\"\\nSummary->[TRAIN DATA]\")\n",
    "            print(\"trNumframes.shape=\", self.trNumframes.shape)\n",
    "            \n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trData)\n",
    "            print(\"trData.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trLabel_r)\n",
    "            print(\"trLabel_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trLabel_i)\n",
    "            print(\"trLabel_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trLabel)\n",
    "            print(\"trLabel.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trCleanSpec_r)\n",
    "            print(\"trCleanSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trCleanSpec_i)\n",
    "            print(\"trCleanSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trMixtureSpec_r)\n",
    "            print(\"trMixtureSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.trMixtureSpec_i)\n",
    "            print(\"trMixtureSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            \n",
    "        elif DATA_TYPE.lower() == 'dev':\n",
    "            print(\"\\nSummary->[DEV DATA]\")\n",
    "            print(\"cvNumframes.shape=\", self.cvNumframes.shape)\n",
    "            \n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvData)\n",
    "            print(\"cvData.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvLabel_r)\n",
    "            print(\"cvLabel_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvLabel_i)\n",
    "            print(\"cvLabel_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvLabel)\n",
    "            print(\"cvLabel.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvCleanSpec_r)\n",
    "            print(\"cvCleanSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvCleanSpec_i)\n",
    "            print(\"cvCleanSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvMixtureSpec_r)\n",
    "            print(\"cvMixtureSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.cvMixtureSpec_i)\n",
    "            print(\"cvMixtureSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "\n",
    "            \n",
    "        elif DATA_TYPE.lower() == 'test':\n",
    "            print(\"\\nSummary->[TEST DATA]\")\n",
    "            print(\"teNumframes.shape=\", self.teNumframes.shape)\n",
    "            \n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teData)\n",
    "            print(\"teData.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teLabel_r)\n",
    "            print(\"teLabel_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teLabel_i)\n",
    "            print(\"teLabel_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teLabel)\n",
    "            print(\"teLabel.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teCleanSpec_r)\n",
    "            print(\"teCleanSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teCleanSpec_i)\n",
    "            print(\"teCleanSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teMixtureSpec_r)\n",
    "            print(\"teMixtureSpec_r.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "            shp, m, v, s, mn, mx = self.data_stat(self.teMixtureSpec_i)\n",
    "            print(\"teMixtureSpec_i.shape={0}, mean={1:.4f}, variance={2:.4f}, std={3:.4f}, range=[{4:.4f},{5:.4f}]\".\n",
    "                              format(shp, m, v, s, mn, mx) )\n",
    "                        \n",
    "    # Helper function for display, returns actual values\n",
    "    def data_stat(self, data):\n",
    "        return data.shape,np.mean(data),np.var(data),np.std(data),np.amin(data),np.amax(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt keys:\n",
      "0->ARMA_order,1->Fs,2->ada_grad_eps,3->ada_sgd_scale,4->arma_order,5->change_momentum_point,6->clip_level,7->cost_function,8->cv_interval,9->dim_input,( dim_input = 1230 ) 10->dim_output,( dim_output = 963 ) 11->drop_ratio,12->eval_on_gpu,13->fRange,14->feawin,15->final_momentum,16->hid_struct,17->hop_size,18->hopsize,19->initial_momentum,20->isDropout,21->isDropoutInput,22->isGPU,23->isNormalize,24->isPretrain,25->labcompress,26->labeltype,27->labwin,28->learner,29->logistic_max,30->logistic_steep,31->net_struct,32->nfft,33->noise,34->numGammatoneChans,35->overlap,36->overlap_len,37->rbm_batch_size,(self.rbm_batch_size= 1024 ) 38->rbm_learn_rate_binary,39->rbm_learn_rate_real,40->rbm_max_epoch,41->save_on_fly,42->sgd_batch_size,(self.sgd_batch_size: 1024 ) 43->sgd_learn_rate,44->sgd_max_epoch,45->split_tanh1_c1,46->split_tanh1_c2,47->tr_mu,48->tr_std,49->unit_type_hidden,50->unit_type_output,51->win_len,52->winlen,"
     ]
    }
   ],
   "source": [
    "opts = Opts(PARAM_FILE)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "opts.batch_ids=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dnn_models/Train_datas.mat True\n",
      "\n",
      "Summary->[TRAIN DATA]\n",
      "trNumframes.shape= (15000, 1)\n",
      "trData.shape=(1951920, 1230), mean=-0.0008, variance=0.6125, std=0.7826, range=[-11.5572,12.4862]\n",
      "trLabel_r.shape=(1951920, 963), mean=0.0295, variance=0.0217, std=0.1473, range=[-10.0000,10.0000]\n",
      "trLabel_i.shape=(1951920, 963), mean=0.0000, variance=0.0133, std=0.1154, range=[-10.0000,10.0000]\n",
      "trLabel.shape=(1951920, 1926), mean=0.0148, variance=0.0177, std=0.1331, range=[-10.0000,10.0000]\n",
      "trCleanSpec_r.shape=(1951920, 321), mean=0.0021, variance=0.2999, std=0.5477, range=[-46.6837,39.0942]\n",
      "trCleanSpec_i.shape=(1951920, 321), mean=-0.0000, variance=0.2914, std=0.5398, range=[-50.2884,37.3594]\n",
      "trMixtureSpec_r.shape=(1951920, 321), mean=0.0046, variance=3.2842, std=1.8122, range=[-133.2251,127.9604]\n",
      "trMixtureSpec_i.shape=(1951920, 321), mean=-0.0000, variance=3.1975, std=1.7882, range=[-133.8369,109.0255]\n"
     ]
    }
   ],
   "source": [
    "opts.read_data(TrainData_FILE, DATA_TYPE=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dnn_models/CrossValidation_datas.mat True\n",
      "\n",
      "Summary->[DEV DATA]\n",
      "cvNumframes.shape= (3300, 1)\n",
      "cvData.shape=(449610, 1230), mean=-0.0000, variance=0.6076, std=0.7795, range=[-9.6298-10.4941]\n",
      "cvLabel_r.shape=(449610, 963), mean=0.0286, variance=0.0213, std=0.1458, range=[-10.0000,10.0000]\n",
      "cvLabel_i.shape=(449610, 963), mean=-0.0000, variance=0.0130, std=0.1138, range=[-10.0000,10.0000]\n",
      "cvLabel.shape=(449610, 1926), mean=0.0143, variance=0.0173, std=0.1316, range=[-10.0000,10.0000]\n",
      "cvCleanSpec_r.shape=(449610, 321), mean=0.0020, variance=0.3002, std=0.5479, range=[-40.8223,41.5895]\n",
      "cvCleanSpec_i.shape=(449610, 321), mean=-0.0000, variance=0.2895, std=0.5381, range=[-39.2169,43.0322]\n",
      "cvMixtureSpec_r.shape=(449610, 321), mean=0.0044, variance=3.2486, std=1.8024, range=[-121.7945,125.0182]\n",
      "cvMixtureSpec_i.shape=(449610, 321), mean=-0.0001, variance=3.1470, std=1.7740, range=[-101.6771,93.7446]\n"
     ]
    }
   ],
   "source": [
    "opts.read_data(DevData_FILE, DATA_TYPE=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dnn_models/Test_datas.mat True\n",
      "\n",
      "Summary->[TEST DATA]\n",
      "teNumframes.shape= (545, 1)\n",
      "teData.shape=(72440, 1230), mean=-0.0000, variance=0.6272, std=0.7919, range=[-9.4365,10.2858]\n",
      "teLabel_r.shape=(72440, 963), mean=0.0308, variance=0.0225, std=0.1500, range=[-10.0000,10.0000]\n",
      "teLabel_i.shape=(72440, 963), mean=-0.0000, variance=0.0138, std=0.1175, range=[-10.0000,10.0000]\n",
      "teLabel.shape=(72440, 1926), mean=0.0154, variance=0.0184, std=0.1356, range=[-10.0000,10.0000]\n",
      "teCleanSpec_r.shape=(72440, 321), mean=0.0020, variance=0.2997, std=0.5475, range=[-42.8964,38.0338]\n",
      "teCleanSpec_i.shape=(72440, 321), mean=-0.0000, variance=0.2920, std=0.5403, range=[-37.0904,45.6445]\n",
      "teMixtureSpec_r.shape=(72440, 321), mean=0.0041, variance=3.4055, std=1.8454, range=[-104.7786,93.6277]\n",
      "teMixtureSpec_i.shape=(72440, 321), mean=-0.0000, variance=3.3203, std=1.8222, range=[-96.0003,123.9898]\n"
     ]
    }
   ],
   "source": [
    "opts.read_data(TestData_FILE, DATA_TYPE=\"test\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "opts.teCleanSpec_i[789:794, 89:94]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For RNN style 3D batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare3D_list(opts, CYCLE):\n",
    "        # TRAIN: total_num_samples = self.trData.shape[0] = 195192\n",
    "        # DEV: total_num_samples = self.trData.shape[0] = 44961\n",
    "\n",
    "        feat_vec_len = opts.dim_input # 1230\n",
    "        out_vec_len = opts.dim_output #963\n",
    "        \n",
    "        if CYCLE.lower()=='train':\n",
    "            data = opts.trData\n",
    "            label_r = opts.trLabel_r\n",
    "            label_i = opts.trLabel_i\n",
    "            numframes = opts.trNumframes\n",
    "#             mix_spec_r = opts.trMixtureSpec_r\n",
    "#             mix_spec_i = opts.trMixtureSpec_i\n",
    "            \n",
    "        elif CYCLE.lower()=='dev':\n",
    "            data = opts.cvData\n",
    "            label_r = opts.cvLabel_r\n",
    "            label_i = opts.cvLabel_i\n",
    "            numframes = opts.cvNumframes\n",
    "#             mix_spec_r = opts.cvMixtureSpec_r\n",
    "#             mix_spec_i = opts.cvMixtureSpec_i\n",
    "            \n",
    "        elif CYCLE.lower()=='test':\n",
    "            data = opts.teData\n",
    "            label_r = opts.teLabel_r\n",
    "            label_i = opts.teLabel_i\n",
    "            numframes = opts.teNumframes\n",
    "#             mix_spec_r = opts.teMixtureSpec_r\n",
    "#             mix_spec_i = opts.teMixtureSpec_i\n",
    "            \n",
    "\n",
    "        data3D, label3D_r, label3D_i = [], [], []\n",
    "        numframes = np.cumsum(numframes)\n",
    "        \n",
    "        for e, frames in enumerate(numframes):\n",
    "            frames= int(frames)\n",
    "            pre_frames= int(numframes[e-1])\n",
    "            \n",
    "            d = data[:frames] if len(data3D)==0 else data[pre_frames:frames]\n",
    "            r = label_r[:frames] if len(label3D_r)==0 else label_r[pre_frames:frames]\n",
    "            i = label_i[:frames] if len(label3D_i)==0 else label_i[pre_frames:frames]\n",
    "            \n",
    "            data3D.append( d )\n",
    "            label3D_r.append( r )\n",
    "            label3D_i.append( i )\n",
    "            \n",
    "#             print('d.shape=',d.shape, ', r.shape=',r.shape, ', i.shape=',i.shape)\n",
    "        \n",
    "        return data3D, label3D_r, label3D_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch_rnn(opts, batch_size, CYCLE, maxlen=185):\n",
    "    # TRAIN: total_num_samples = self.trData.shape[0] = 1951920\n",
    "    # DEV: total_num_samples = self.trData.shape[0] = 449610\n",
    "\n",
    "    feat_vec_len = opts.dim_input #1230\n",
    "    out_vec_len = opts.dim_output #963\n",
    "\n",
    "\n",
    "    if CYCLE.lower()=='train':\n",
    "        selected_indics = np.arange(len(opts.trNumframes))\n",
    "        data3D, label3D_r, label3D_i = prepare3D_list(opts,CYCLE)\n",
    "        np.random.shuffle(selected_indics)\n",
    "\n",
    "    elif CYCLE.lower()=='dev':\n",
    "        selected_indics = np.arange(len(opts.cvNumframes))\n",
    "        data3D, label3D_r, label3D_i = prepare3D_list(opts,CYCLE)\n",
    "        np.random.shuffle(selected_indics)\n",
    "\n",
    "    elif CYCLE.lower()=='test':\n",
    "        selected_indics = np.arange(len(opts.teNumframes))\n",
    "        data3D, label3D_r, label3D_i = prepare3D_list(opts, CYCLE)\n",
    "        si = selected_indics\n",
    "\n",
    "\n",
    "    while True:\n",
    "        f = 0\n",
    "        while (f*batch_size) < len(selected_indics):\n",
    "\n",
    "            if CYCLE.lower()=='train'or CYCLE.lower()=='dev':\n",
    "                if (f+1)*batch_size < len(selected_indics):\n",
    "                    si = selected_indics[(f*batch_size):((f+1)*batch_size)]\n",
    "                else:\n",
    "                    si = selected_indics[(f*batch_size):]\n",
    "\n",
    "            opts.batch_ids = si;\n",
    "\n",
    "            x, y = None, None\n",
    "            for indx in si:\n",
    "                d = data3D[indx]\n",
    "                d = np.concatenate( (d, np.zeros((maxlen-d.shape[0],feat_vec_len))),axis=0 )\n",
    "                d = np.expand_dims(d, axis=0)\n",
    "\n",
    "                l = np.concatenate((label3D_r[indx], label3D_i[indx]), axis=1)\n",
    "                l = np.concatenate( (l, np.zeros((maxlen-l.shape[0],out_vec_len*2))),axis=0 )\n",
    "                l = np.expand_dims(l, axis=0)\n",
    "\n",
    "                x = d if x is None else np.concatenate( (x,d),axis=0 )\n",
    "                y = l if y is None else np.concatenate( (y,l),axis=0 )\n",
    "\n",
    "\n",
    "            f += 1\n",
    "\n",
    "            if CYCLE.lower()=='test':\n",
    "                with open(LOG_FILE,'a+') as log:\n",
    "                    log.write('{5} {0}-CYCLE, batch_id:{1}, #{2}samples, x.shape:{3}, y.shape:{4}\\n'.\n",
    "                        format(CYCLE, f, len(si), x.shape, y.shape, strftime(\"%Y-%m-%d %H:%M:%S\",gmtime())))\n",
    "\n",
    "                # print(x.shape, y.shape)\n",
    "                yield x, y\n",
    "                return\n",
    "\n",
    "            else:\n",
    "\n",
    "                if x.shape[0]<batch_size:\n",
    "                    x = np.concatenate( (x, np.zeros((batch_size-x.shape[0],maxlen,feat_vec_len))), axis=0)\n",
    "                    y = np.concatenate( (y, np.zeros((batch_size-y.shape[0],maxlen,out_vec_len*2))), axis=0)\n",
    "\n",
    "                with open(LOG_FILE,'a+') as log:\n",
    "                    log.write('{5} {0}-CYCLE, batch_id:{1:0002}, #{2}samples, x.shape:{3}, y.shape:{4}\\n'.\n",
    "                            format(CYCLE, f, len(si), x.shape, y.shape, strftime(\"%Y-%m-%d %H:%M:%S\",gmtime())))\n",
    "                yield x,y\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for e,[x,y] in enumerate(next_batch_rnn(opts,50,CYCLE='train')):\n",
    "    print(e,end=\" \")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for e,[x,y] in enumerate(next_batch_rnn(opts,batch_size = 5,CYCLE='dev')):\n",
    "    print('batch id', e, opts.batch_ids, opts.cvNumframes[opts.batch_ids])\n",
    "    if e == 10:\n",
    "        break\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Unwrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unwrapAugmentedTF_wAvg(impt_mag,num_per_side,unwrap_mag=None):\n",
    "    \n",
    "#     Description: Unwrap the augmented time-frequency (T-F) representation and compute the average.\n",
    "\n",
    "#     Input:\n",
    "#         impt_mag: wrapped T-F representation with dimensions (2*T+1)*d x m\n",
    "#         num_per_side(T): number of frames to left and right of each frame used to augmented T-F representation\n",
    "#     Output:\n",
    "#         unwrap_avgmag: unwrapped and averaged T-F representation with dimensions d x m\n",
    "#         unwrap_mag: unwrapped T-F representation with dimensions d x (2*T+1) x m\n",
    "#\n",
    "        \n",
    "        sliding_window_len       = 2*num_per_side + 1\n",
    "        (numWrapFreqs,numFrames) = impt_mag.shape\n",
    "        numFreqs                 = numWrapFreqs//sliding_window_len\n",
    "        unwrap_avgmag            = np.zeros((numFreqs,numFrames))\n",
    "        \n",
    "        if num_per_side > 0:\n",
    "            if unwrap_mag is None:\n",
    "            \n",
    "                unwrap_mag        = np.zeros((numFreqs,sliding_window_len+1,numFrames))\n",
    "                curr_ind_location = np.ones((numFrames,1),dtype=int)\n",
    "                \n",
    "\n",
    "                for frameNum in range(numFrames):\n",
    "                    \n",
    "                    # Get the indices for the frames used in this augmented matrix\n",
    "                    frame_inds=np.arange(frameNum-num_per_side, frameNum+num_per_side)\n",
    "                    frame_inds[frame_inds<0] = 0;\n",
    "                    frame_inds[frame_inds>=numFrames] = numFrames-1;\n",
    "                    \n",
    "#                     for inds in range(frameNum-num_per_side,frameNum+num_per_side+1):\n",
    "#                         if inds<0:\n",
    "#                             frame_inds.append(0)\n",
    "#                         elif inds>=numFrames:\n",
    "#                             frame_inds.append(numFrames-1)\n",
    "#                         else:\n",
    "#                             frame_inds.append(inds)\n",
    "                    \n",
    "                    # Unwrap the data for this frame\n",
    "                    slid_win_data = np.reshape( impt_mag[:,frameNum], (numFreqs,sliding_window_len)) #Size d x (2*T + 1)\n",
    "                    \n",
    "                    for ind_num in range(len(frame_inds)):\n",
    "\n",
    "                        slid = np.array(slid_win_data[:,ind_num], ndmin=2).T\n",
    "                        unwrap_mag[:,curr_ind_location[frame_inds[ind_num]], frame_inds[ind_num]] = slid \n",
    "                        \n",
    "                        # Update counters\n",
    "                        curr_ind_location[frame_inds[ind_num]] = curr_ind_location[frame_inds[ind_num]] + 1\n",
    "\n",
    "\n",
    "            temp = np.zeros((numFreqs,sliding_window_len+1))\n",
    "            \n",
    "            for frameNum in range(numFrames):\n",
    "#                 print(unwrap_mag.shape)\n",
    "                \n",
    "                unwrap_avgmag[:,frameNum] = np.mean(unwrap_mag[:,:,frameNum],axis=1)\n",
    "#                 print(unwrap_mag.shape)\n",
    "#                 return\n",
    "\n",
    "            \n",
    "        else:\n",
    "            unwrap_avgmag = impt_mag;\n",
    "            unwrap_mag = 0;\n",
    "            \n",
    "        return unwrap_avgmag,unwrap_mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss_train_SA(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    numframes = opts.trNumframes[opts.batch_ids]\n",
    "    numframes = [int(f[0]) for f in numframes]\n",
    "    \n",
    "    cost_r = K.variable(value=0)\n",
    "    cost_i = K.variable(value=0)\n",
    "    \n",
    "    for n,ids in zip(numframes,opts.batch_ids):\n",
    "        real_output = yPred[:n, :(c//2)]\n",
    "        imag_output = yPred[:n, (c//2):]\n",
    "        \n",
    "        mix_stft = self.trMixtureSpec_r[ids].T + 1j*self.trMixtureSpec_i[ids].T\n",
    "        \n",
    "        cIRM = yTrue[:n, :(c//2)].T + 1j*yTrue[:n, (c//2):].T # ideal mask\n",
    "        y           = cIRM*mix_stft\n",
    "        \n",
    "        complex_irmmask = complex(real_output.T, imag_output.T) # estimate mask\n",
    "        \n",
    "        if opts.labwin==0:\n",
    "            estimate           = complex_irmmask*mix_stft\n",
    "#             estimate_r = real_output*self.trMixtureSpec_r[ids]\n",
    "#             estimate_i = imag_output*self.trMixtureSpec_i[ids]\n",
    "        else:\n",
    "            real_output_unwrap = unwrapAugmentedTF_wAvg(real_output.T, opts.labwin)\n",
    "            imag_output_unwrap = unwrapAugmentedTF_wAvg(imag_output.T, opts.labwin)\n",
    "            complex_irmmask    = real_output_unwrap + 1j*imag_output_unwrap\n",
    "            estimate           = complex_irmmask*mix_stft\n",
    "        \n",
    "        diff = y-estimate\n",
    "        cost_r += K.sum(K.square(np.real(diff)))\n",
    "        cost_i += K.sum(K.square(np.imag(diff)))\n",
    "\n",
    "#     cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "#     cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Opts' object has no attribute 'si'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0cfafb0fc30e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Opts' object has no attribute 'si'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss_train(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    numframes = opts.trNumframes[opts.batch_ids]\n",
    "    numframes = [int(f[0]) for f in numframes]\n",
    "    \n",
    "    cost_r = K.variable(value=0)\n",
    "    cost_i = K.variable(value=0)\n",
    "    for n in numframes:\n",
    "        cost_r += K.sum(K.square(yTrue[:n, :(c//2)]- yPred[:n, :(c//2)]))\n",
    "        cost_i += K.sum(K.square(yTrue[:n, (c//2):]- yPred[:n, (c//2):]))\n",
    "\n",
    "#     cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "#     cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss_val(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    numframes = opts.cvNumframes[opts.batch_ids]\n",
    "    numframes = [int(f[0]) for f in numframes]\n",
    "    \n",
    "    cost_r = K.variable(value=0)\n",
    "    cost_i = K.variable(value=0)\n",
    "    for n in numframes:\n",
    "        cost_r += K.sum(K.square(yTrue[:n, :(c//2)]- yPred[:n, :(c//2)]))\n",
    "        cost_i += K.sum(K.square(yTrue[:n, (c//2):]- yPred[:n, (c//2):]))\n",
    "\n",
    "#     cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "#     cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customLoss_test(yTrue,yPred):\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    r,c = K.shape(yTrue)[0], K.shape(yTrue)[1] # opts.sgd_batch_size\n",
    "    \n",
    "    r= K.cast(r,dtype='float32') # because by default, K.shape tensors are dtype int32\n",
    "\n",
    "    numframes = opts.teNumframes[opts.batch_ids]\n",
    "    numframes = [int(f[0]) for f in numframes]\n",
    "    \n",
    "    cost_r = K.variable(value=0)\n",
    "    cost_i = K.variable(value=0)\n",
    "    for n in numframes:\n",
    "        cost_r += K.sum(K.square(yTrue[:n, :(c//2)]- yPred[:n, :(c//2)]))\n",
    "        cost_i += K.sum(K.square(yTrue[:n, (c//2):]- yPred[:n, (c//2):]))\n",
    "\n",
    "#     cost_r = K.sum(K.square(yTrue[:, :(c//2)]- yPred[:, :(c//2)]))\n",
    "#     cost_i = K.sum(K.square(yTrue[:, (c//2):]- yPred[:, (c//2):]))\n",
    "    \n",
    "    cost = 0.5*(cost_r+cost_i)/r\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossFunctionCallback(Callback):\n",
    "    def __init__(self, model, opts):\n",
    "        self.model = model\n",
    "        self.opts = opts\n",
    "        pass\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        self.model.loss = customLoss_train\n",
    "        pass\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.model.loss = customLoss_val\n",
    "        pass\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        # print('-> on_train_end=',self.params)\n",
    "        self.model.loss = customLoss_test\n",
    "        pass\n",
    "        \n",
    " \n",
    "    def on_train_begin(self, logs={}):\n",
    "        pass\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        pass\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### RNN variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Max_RNN = 256\n",
    "\n",
    "# feat_vec_len = 1230\n",
    "# out_vec_len = 963\n",
    "\n",
    "# epochs = 50\n",
    "# train_size = 15000\n",
    "# dev_size = 3300\n",
    "# batch_size = 256\n",
    "\n",
    "\n",
    "batch_size = 25 #opts.sgd_batch_size\n",
    "epochs = 50\n",
    "\n",
    "Max_RNN = 256\n",
    "Max_Frame = 185\n",
    "\n",
    "'''\n",
    "n_train, n_train_dim = <number of samples for training, input dimentions>, final will be (1951920, 1230)\n",
    "n_dev, n_dev_dim = <number of samples for development, input dimentions>, final will be (449610, 1230)\n",
    "n_test, n_test_dim =<number of samples for testing, input dimentions>, final will be (72440, 1230)\n",
    "\n",
    "'''\n",
    "n_train, n_train_dim = (1951920, 1230) # opts.trData.shape = (1951920, 1230)\n",
    "n_dev, n_dev_dim = (449610, 1230) # opts.cvData.shape =(449610, 1230)\n",
    "n_test, n_test_dim = (72440, 1230) # opts.teData.shape =(72440, 1230)\n",
    "\n",
    "n_train_files = 15000 #15000\n",
    "n_dev_files = 3300 # 3300\n",
    "n_test_files = 545\n",
    "\n",
    "n_classes = (963 + 963)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 1\n",
    "single bidirectional GRU layer\n",
    "\n",
    "real+img (963+963)=1926-d output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 185, 256)          1522688   \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 185, 256)          525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 185, 256)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 185, 1926)         494982    \n",
      "=================================================================\n",
      "Total params: 2,542,982\n",
      "Trainable params: 2,542,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "600/600 [==============================] - 607s - loss: 0.0133 - acc: 0.0018 - val_loss: 0.0124 - val_acc: 0.0035\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 594s - loss: 0.0120 - acc: 0.0052 - val_loss: 0.0121 - val_acc: 0.0103\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 608s - loss: 0.0118 - acc: 0.0080 - val_loss: 0.0120 - val_acc: 0.0114\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 597s - loss: 0.0117 - acc: 0.0089 - val_loss: 0.0119 - val_acc: 0.0118\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 606s - loss: 0.0116 - acc: 0.0112 - val_loss: 0.0119 - val_acc: 0.0119\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 629s - loss: 0.0116 - acc: 0.0171 - val_loss: 0.0119 - val_acc: 0.0120\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 615s - loss: 0.0116 - acc: 0.0270 - val_loss: 0.0118 - val_acc: 0.0123\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 600s - loss: 0.0116 - acc: 0.0401 - val_loss: 0.0118 - val_acc: 0.0126\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 594s - loss: 0.0115 - acc: 0.0553 - val_loss: 0.0118 - val_acc: 0.0134\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 599s - loss: 0.0115 - acc: 0.0710 - val_loss: 0.0118 - val_acc: 0.0160\n",
      "Epoch 11/50\n",
      "356/600 [================>.............] - ETA: 190s - loss: 0.0115 - acc: 0.0853"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "BatchNormalization()\n",
    "model.add(LSTM(Max_RNN, return_sequences=True, input_shape=(Max_Frame,opts.dim_input)))\n",
    "BatchNormalization()\n",
    "model.add(LSTM(Max_RNN, return_sequences=True))\n",
    "# model.add(Bidirectional(LSTM(Max_RNN, return_sequences=True), input_shape=(Max_RNN,feat_vec_len)))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Bidirectional(GRU(Max_RNN, return_sequences=True, stateful=True)))\n",
    "BatchNormalization()\n",
    "model.add(TimeDistributed(Dense(units=n_classes, activation='linear')))\n",
    "#model.add(Dense(n_classes, activation='linear'))\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "# callbacks = [EarlyStopping(monitor='val_acc', patience=2, min_delta=1e-6, verbose=1, mode='auto'), \n",
    "#              ModelCheckpoint(filepath= MODEL_FILE, monitor='val_acc', save_best_only=True)]\n",
    "callbacks = [EarlyStopping(monitor='val_acc', patience=5, min_delta=1e-4, verbose=1, mode='auto'), \n",
    "             ModelCheckpoint(filepath= MODEL_FILE, monitor='val_acc', save_best_only=True),\n",
    "             LossFunctionCallback(model,opts)]\n",
    "\n",
    "\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsprop = optimizers.RMSprop(lr=0.00001, rho=0.9, epsilon=1e-08)\n",
    "adam = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "# model.compile(loss = \"mse\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = rmsprop, metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit_generator(next_batch_rnn(opts,batch_size,maxlen=Max_Frame,CYCLE='train'), \n",
    "                    validation_data=next_batch_rnn(opts,batch_size,maxlen=Max_Frame,CYCLE='dev'),\n",
    "                    epochs=epochs, steps_per_epoch=n_train_files//batch_size, \n",
    "                    validation_steps=n_dev_files//batch_size, \n",
    "                    verbose=1, callbacks=callbacks)\n",
    "\n",
    "model.save(SAVE_MODEL_FILE)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# plot metrics                                                       \n",
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.suptitle(\"Train result\")\n",
    "\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "# plt.plot(history.history['val_mean_absolute_percentage_error'])\n",
    "# plt.plot(history.history['val_cosine_proximity'])\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['acc'])\n",
    "\n",
    "# plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    "# plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "# plt.plot(history.history['cosine_proximity'])\n",
    "                                                           \n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"numbers\")\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for x,y in next_batch_rnn(opts,batch_size,maxlen=Max_RNN, CYCLE='test'):\n",
    "    print('OUTSIDE:',x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEST_MODEL_FILE = \"./dnn_models/lstm_weights\"+ Code_VERSION+\"_02.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = load_model(BEST_MODEL_FILE, custom_objects={'customLoss_train':customLoss_train,\n",
    "                                                          'customLoss_val':customLoss_val,\n",
    "                                                          'customLoss_test':customLoss_test,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545/545 [==============================] - 5s\n",
      "y_hat shape (545, 185, 1926)\n"
     ]
    }
   ],
   "source": [
    "for x,y in next_batch_rnn(opts,batch_size,maxlen=Max_Frame, CYCLE='test'):\n",
    "    y_hat = model.predict(x, batch_size=x.shape[0], verbose=1)\n",
    "    print('y_hat shape', y_hat.shape)\n",
    "    sio.savemat(OUTPUT_FILE, {'y_hat':y_hat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 185, 1926)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
