{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/knayem/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import math\n",
    "import array\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(sys.executable)\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.restoration import unwrap_phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. File paths "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IEEE Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a Mixture (Noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .NPY FILE PATH\n",
    "FILE_SAVE_PATH = '/data/knayem/IEEE_DataFiles' # store .npy data file path for quick access\n",
    "\n",
    "# SSN PATH\n",
    "SSN_MIXTURE_PATH = '/data/knayem/denoising_mix_wavs_SSN_15000noisespercs'\n",
    "\n",
    "# CAFE PATH\n",
    "CAFE_MIXTURE_PATH = '/data/knayem/denoising_mix_wavs_Cafe_15000noisespercs'\n",
    "\n",
    "# BABBLE PATH\n",
    "BABBLE_MIXTURE_PATH = '/data/knayem/denoising_mix_wavs_Babble_1500noisespercs'\n",
    "\n",
    "# FACTORY PATH\n",
    "FACTORY_MIXTURE_PATH = '/data/knayem/denoising_mix_wavs_Factory_15000noisespercs'\n",
    "\n",
    "\n",
    "# Train, Dev, Test\n",
    "TRAIN_MIXTURE_PATH = 'training_16k'\n",
    "DEV_MIXTURE_PATH = 'development_16k'\n",
    "TEST_MIXTURE_PATH = 'testing_matched'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN PATH\n",
    "CLEAN_PATH = '/data/knayem/denoising_clean_wavs_SSN_10noisespercs'\n",
    "\n",
    "# Train, Dev, Test\n",
    "TRAIN_CLEAN_PATH = 'training_16k'\n",
    "DEV_CLEAN_PATH = 'development_16k'\n",
    "TEST_CLEAN_PATH = 'testing_16k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIMIT Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a Mixture (Noisy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# .NPY FILE PATH\n",
    "FILE_SAVE_PATH = '/data/knayem/TIMIT_DataFiles'\n",
    "\n",
    "# SSN PATH\n",
    "SSN_MIXTURE_PATH = '/data/knayem/TIMIT_mixture/ssn'\n",
    "\n",
    "# CAFE PATH\n",
    "CAFE_MIXTURE_PATH = '/data/knayem/TIMIT_mixture/cafe'\n",
    "\n",
    "# BABBLE PATH\n",
    "BABBLE_MIXTURE_PATH = '/data/knayem/TIMIT_mixture/babble'\n",
    "\n",
    "# FACTORY PATH\n",
    "FACTORY_MIXTURE_PATH = '/data/knayem/TIMIT_mixture/factory'\n",
    "\n",
    "\n",
    "# Train, Dev, Test\n",
    "TRAIN_MIXTURE_PATH = 'train_16k'\n",
    "DEV_MIXTURE_PATH = 'dev_16k'\n",
    "TEST_MIXTURE_PATH = 'test_16k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CLEAN PATH\n",
    "CLEAN_PATH = '/data/knayem/TIMIT_clean_16k'\n",
    "\n",
    "# Train, Dev, Test\n",
    "TRAIN_CLEAN_PATH = 'train_16k'\n",
    "DEV_CLEAN_PATH = 'dev_16k'\n",
    "TEST_CLEAN_PATH = 'test_16k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = os.path.join(CLEAN_PATH,TRAIN_CLEAN_PATH) # clean train\n",
    "# PATH = os.path.join(CLEAN_PATH,DEV_CLEAN_PATH) # clean dev\n",
    "PATH = os.path.join(CLEAN_PATH,TEST_CLEAN_PATH) # clean test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c STFT parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followings are the basic parameter for calculating STFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16e3\n",
    "\n",
    "n_fft = 640\n",
    "win_length = int(40e-3*fs) # librosa needs scalar value\n",
    "overlap = int(20e-3*fs)\n",
    "hop_length = win_length - overlap # librosa needs scalar value\n",
    "\n",
    "NUMS_PRINTS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Magnitude and Group Delay of the PATH (train, dev, test of IEEE/TIMIT) to get an overview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /data/knayem/TIMIT_clean_16k/test_16k , len(DIR): 0 , len(FILES): 1360\n",
      "[0]...[10]...[20]...[30]...[40]...[50]...[60]...[70]...[80]...[90]...\n",
      "Max Spec len: 345 , Max Spec val: 29.712965 , Min Spec val: 2.9391e-09\n",
      "Max GD len: 345 , Max GD val: 3.1415926297400323 , Min GD val: -3.1415926456925596\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "mag_len = []\n",
    "mag_max = []\n",
    "mag_min = []\n",
    "\n",
    "gd_len = []\n",
    "gd_max = []\n",
    "gd_min = []\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(PATH):\n",
    "    print(\"ROOT:\",root, \", len(DIR):\", len(dirs), \", len(FILES):\",len(files))\n",
    "    \n",
    "    selected_print = np.floor(np.linspace(0, len(files), NUMS_PRINTS, False))\n",
    "    \n",
    "    for enum, filename in enumerate(files):\n",
    "\n",
    "        FILE_NAME = os.path.join(root,filename)\n",
    "        \n",
    "        y, sr = librosa.load(FILE_NAME, fs)\n",
    "        s_stft = librosa.stft(y,n_fft,hop_length,win_length)\n",
    "        mag, phase = librosa.magphase(s_stft)\n",
    "        angle = np.angle(phase)\n",
    "        \n",
    "        unwrap_angle = np.unwrap(angle, axis=0) # freq, MATLAB implementation\n",
    "        unwrap_angle_s = np.roll(unwrap_angle, 1, axis=0) # roll across freq\n",
    "        unwrap_GD = np.angle(np.exp(1j*(unwrap_angle - unwrap_angle_s))) # paper implementation\n",
    "        \n",
    "        mag_len.append(mag.shape[1])\n",
    "        mag_max.append(max(mag.flatten()))\n",
    "        mag_min.append(min(mag.flatten()))\n",
    "        \n",
    "        gd_len.append(unwrap_GD.shape[1])\n",
    "        gd_max.append(max(unwrap_GD.flatten()))\n",
    "        gd_min.append(min(unwrap_GD.flatten()))\n",
    "        \n",
    "        if enum in selected_print:\n",
    "            print(np.where(selected_print==enum)[0]*10, end='...')\n",
    "            \n",
    "\n",
    "print( '\\nMax Spec len:', max(mag_len),', Max Spec val:', max(mag_max), ', Min Spec val:',min(mag_min))\n",
    "print( 'Max GD len:', max(gd_len),', Max GD val:', max(gd_max), ', Min GD val:',min(gd_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For IEEE clean training,**\n",
    "\n",
    "ROOT: /data/knayem/denoising_clean_wavs_SSN_10noisespercs/training_16k , len(DIR): 0 , len(FILES): 500\n",
    "\n",
    "Max Spec len: 186 , Max Spec val: 50.611187 , Min Spec val: 0.0\n",
    "\n",
    "Max GD len: 186 , Max GD val: 3.1415926297400323 , Min GD val: -3.1415926297400323\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "**For IEEE clean dev,**\n",
    "\n",
    "ROOT: /data/knayem/denoising_clean_wavs_SSN_10noisespercs/development_16k , len(DIR): 0 , len(FILES): 110\n",
    "\n",
    "Max Spec len: 178 , Max Spec val: 42.42621 , Min Spec val: 0.0\n",
    "\n",
    "Max GD len: 178 , Max GD val: 3.1415926297400323 , Min GD val: -3.1415926297400323\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "**For IEEE clean testing,**\n",
    "\n",
    "ROOT: /data/knayem/denoising_clean_wavs_SSN_10noisespercs/testing_16k , len(DIR): 0 , len(FILES): 109\n",
    "\n",
    "Max Spec len: 183 , Max Spec val: 42.816093 , Min Spec val: 0.0\n",
    "\n",
    "Max GD len: 183 , Max GD val: 3.1415926297400323 , Min GD val: -3.1415926297400323"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For TIMIT clean training,**\n",
    "\n",
    "ROOT: /data/knayem/TIMIT_clean_16k/train_16k , len(DIR): 0 , len(FILES): 4620\n",
    "\n",
    "Max Spec len: 390 , Max Spec val: 35.032005 , Min Spec val: 3.7300213e-10\n",
    "\n",
    "Max GD len: 390 , Max GD val: 3.1415926297400323 , Min GD val: -3.1415926456925596\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "**For TIMIT clean dev,**\n",
    "\n",
    "ROOT: /data/knayem/TIMIT_clean_16k/dev_16k , len(DIR): 0 , len(FILES): 320\n",
    "\n",
    "Max Spec len: 379 , Max Spec val: 25.104317 , Min Spec val: 7.5970613e-10\n",
    "\n",
    "Max GD len: 379 , Max GD val: 3.1415926297400323 , Min GD val: -3.1415926456925596\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "**For TIMIT clean testing,** \n",
    "\n",
    "ROOT: /data/knayem/TIMIT_clean_16k/test_16k , len(DIR): 0 , len(FILES): 1360\n",
    "\n",
    "Max Spec len: 345 , Max Spec val: 29.712965 , Min Spec val: 2.9391e-09\n",
    "\n",
    "Max GD len: 345 , Max GD val: 3.1415926297400323 , Min GD val: -3.1415926456925596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d (Target_path, Mixture_path) pair genetrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store **(clean_fileName, mixture_fileName)** pairs in a .npy file for quick file retrival when needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN FILE PATH\n",
    "TRAIN_CLEAN_PATHS = {os.path.join(CLEAN_PATH,TRAIN_CLEAN_PATH)}\n",
    "\n",
    "DEV_CLEAN_PATHS = {os.path.join(CLEAN_PATH,DEV_CLEAN_PATH)}\n",
    "\n",
    "TEST_CLEAN_PATHS = {os.path.join(CLEAN_PATH,TEST_CLEAN_PATH)}\n",
    "\n",
    "\n",
    "# MIXTURE FILE PATH\n",
    "TRAIN_MIXTURE_PATHS = {os.path.join(SSN_MIXTURE_PATH,TRAIN_MIXTURE_PATH), \n",
    "                 os.path.join(CAFE_MIXTURE_PATH,TRAIN_MIXTURE_PATH), \n",
    "                 os.path.join(BABBLE_MIXTURE_PATH,TRAIN_MIXTURE_PATH), \n",
    "                 os.path.join(FACTORY_MIXTURE_PATH,TRAIN_MIXTURE_PATH), \n",
    "                }\n",
    "\n",
    "DEV_MIXTURE_PATHS = {os.path.join(SSN_MIXTURE_PATH,DEV_MIXTURE_PATH), \n",
    "                 os.path.join(CAFE_MIXTURE_PATH,DEV_MIXTURE_PATH), \n",
    "                 os.path.join(BABBLE_MIXTURE_PATH,DEV_MIXTURE_PATH), \n",
    "                 os.path.join(FACTORY_MIXTURE_PATH,DEV_MIXTURE_PATH), \n",
    "                }\n",
    "\n",
    "TEST_MIXTURE_PATHS = {os.path.join(SSN_MIXTURE_PATH,TEST_MIXTURE_PATH), \n",
    "                 os.path.join(CAFE_MIXTURE_PATH,TEST_MIXTURE_PATH), \n",
    "                 os.path.join(BABBLE_MIXTURE_PATH,TEST_MIXTURE_PATH), \n",
    "                 os.path.join(FACTORY_MIXTURE_PATH,TEST_MIXTURE_PATH), \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /data/knayem/denoising_clean_wavs_SSN_10noisespercs/testing_16k , len(DIR): 0 , len(C_FILES): 109\n",
      "ROOT: /data/knayem/denoising_mix_wavs_Cafe_15000noisespercs/testing_matched , len(DIR): 0 , len(FILES): 5450\n",
      "ROOT: /data/knayem/denoising_mix_wavs_Factory_15000noisespercs/testing_matched , len(DIR): 0 , len(FILES): 5450\n",
      "ROOT: /data/knayem/denoising_mix_wavs_Babble_15000noisespercs/testing_matched , len(DIR): 0 , len(FILES): 5450\n",
      "ROOT: /data/knayem/denoising_mix_wavs_SSN_15000noisespercs/testing_matched , len(DIR): 0 , len(FILES): 5450\n",
      "43600\n",
      "(21800, 2)\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "\n",
    "# MIXTURE_PATHS = TRAIN_MIXTURE_PATHS\n",
    "# CLEAN_PATHS = TRAIN_CLEAN_PATHS\n",
    "\n",
    "# MIXTURE_PATHS = DEV_MIXTURE_PATHS\n",
    "# CLEAN_PATHS = DEV_CLEAN_PATHS\n",
    "\n",
    "MIXTURE_PATHS = TEST_MIXTURE_PATHS\n",
    "CLEAN_PATHS = TEST_CLEAN_PATHS\n",
    "\n",
    "\n",
    "CLEAN_FILE_NAMES = dict()\n",
    "CLEAN_MIXTURE_PAIR = []\n",
    "\n",
    "\n",
    "\n",
    "for C_PATHS in CLEAN_PATHS:\n",
    "    for root, dirs, files in os.walk(C_PATHS): \n",
    "        print(\"ROOT:\",root, \", len(DIR):\", len(dirs), \", len(C_FILES):\",len(files))\n",
    "        \n",
    "        for enum, filename in enumerate(files):\n",
    "            FILE_NAME = os.path.join(root,filename)\n",
    "            key = filename.split(\".\")[0]\n",
    "            CLEAN_FILE_NAMES[key]=FILE_NAME\n",
    "\n",
    "        \n",
    "for PATHS in MIXTURE_PATHS:\n",
    "    for root, dirs, files in os.walk(PATHS): \n",
    "        print(\"ROOT:\",root, \", len(DIR):\", len(dirs), \", len(FILES):\",len(files))\n",
    "        \n",
    "        for enum, filename in enumerate(files):\n",
    "            FILE_NAME = os.path.join(root,filename)\n",
    "            key = filename.split(\".\")[0][:11]\n",
    "            CLEAN_MIXTURE_PAIR.extend([CLEAN_FILE_NAMES[key],FILE_NAME])\n",
    "\n",
    "            \n",
    "print(len(CLEAN_MIXTURE_PAIR))\n",
    "CLEAN_MIXTURE_PAIR = np.array(CLEAN_MIXTURE_PAIR).reshape(-1,2)\n",
    "print(CLEAN_MIXTURE_PAIR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['/data/knayem/denoising_clean_wavs_SSN_10noisespercs/testing_16k/S_67_06_16k.wav'\n",
      "  '/data/knayem/denoising_mix_wavs_Cafe_15000noisespercs/testing_matched/S_67_06_16k_8_-6dB_CAFE_noisyspeech.wav']\n",
      " ['/data/knayem/denoising_clean_wavs_SSN_10noisespercs/testing_16k/S_69_09_16k.wav'\n",
      "  '/data/knayem/denoising_mix_wavs_Cafe_15000noisespercs/testing_matched/S_69_09_16k_4_-3dB_CAFE_noisyspeech.wav']\n",
      " ['/data/knayem/denoising_clean_wavs_SSN_10noisespercs/testing_16k/S_62_06_16k.wav'\n",
      "  '/data/knayem/denoising_mix_wavs_Cafe_15000noisespercs/testing_matched/S_62_06_16k_7_-3dB_CAFE_noisyspeech.wav']\n",
      " ['/data/knayem/denoising_clean_wavs_SSN_10noisespercs/testing_16k/S_70_06_16k.wav'\n",
      "  '/data/knayem/denoising_mix_wavs_Cafe_15000noisespercs/testing_matched/S_70_06_16k_9_-6dB_CAFE_noisyspeech.wav']\n",
      " ['/data/knayem/denoising_clean_wavs_SSN_10noisespercs/testing_16k/S_72_08_16k.wav'\n",
      "  '/data/knayem/denoising_mix_wavs_Cafe_15000noisespercs/testing_matched/S_72_08_16k_3_-6dB_CAFE_noisyspeech.wav']\n",
      " ['/data/knayem/denoising_clean_wavs_SSN_10noisespercs/testing_16k/S_65_08_16k.wav'\n",
      "  '/data/knayem/denoising_mix_wavs_Cafe_15000noisespercs/testing_matched/S_65_08_16k_2_3dB_CAFE_noisyspeech.wav']]\n"
     ]
    }
   ],
   "source": [
    "print(CLEAN_MIXTURE_PAIR[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair file name, and save it\n",
    "train_clean_mix_file = 'train_clean_mix.npy'\n",
    "dev_clean_mix_file = 'dev_clean_mix.npy'\n",
    "test_clean_mix_file = 'test_clean_mix.npy'\n",
    "\n",
    "# np.save(os.path.join(FILE_SAVE_PATH,train_clean_mix_file), np.random.permutation(CLEAN_MIXTURE_PAIR))\n",
    "# np.save(os.path.join(FILE_SAVE_PATH,dev_clean_mix_file), np.random.permutation(CLEAN_MIXTURE_PAIR))\n",
    "# np.save(os.path.join(FILE_SAVE_PATH,test_clean_mix_file), np.random.permutation(CLEAN_MIXTURE_PAIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read files and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_gd(filename, fs, n_fft, hop_length, win_length, MAX_TIME_FRAME=None):\n",
    "    \n",
    "    y, sr = librosa.load(filename, fs)\n",
    "    s_stft = librosa.stft(y,n_fft,hop_length,win_length)\n",
    "    mag, phase = librosa.magphase(s_stft)\n",
    "    angle = np.angle(phase)\n",
    "\n",
    "    unwrap_angle = np.unwrap(angle, axis=0) # freq, MATLAB implementation\n",
    "    unwrap_angle_s = np.roll(unwrap_angle, 1, axis=0) # roll across freq\n",
    "    unwrap_GD = np.angle(np.exp(1j*(unwrap_angle - unwrap_angle_s))) # paper implementation\n",
    "    \n",
    "    # print('1.mag.shape:', mag.shape, ', gd.shape:', unwrap_GD.shape)\n",
    "    \n",
    "    if MAX_TIME_FRAME is not None:\n",
    "        zero_pad = MAX_TIME_FRAME - mag.shape[1]\n",
    "        zp = np.zeros( (mag.shape[0],zero_pad) )\n",
    "        print('zero_pad:', zero_pad, ', zp.shape:', zp.shape)\n",
    "        mag = np.concatenate( (mag,zp), axis=1)\n",
    "        unwrap_GD = np.concatenate( (unwrap_GD,zp), axis=1)\n",
    "        print('2.mag.shape:', mag.shape, ', unwrap_GD.shape:', unwrap_GD.shape)\n",
    "\n",
    "    return mag, unwrap_GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_gd_phase(filename, fs, n_fft, hop_length, win_length, MAX_TIME_FRAME=None):\n",
    "    \n",
    "    y, sr = librosa.load(filename, fs)\n",
    "    s_stft = librosa.stft(y,n_fft,hop_length,win_length)\n",
    "    mag, phase = librosa.magphase(s_stft)\n",
    "    angle = np.angle(phase)\n",
    "\n",
    "    unwrap_angle = np.unwrap(angle, axis=0) # freq, MATLAB implementation\n",
    "    unwrap_angle_s = np.roll(unwrap_angle, 1, axis=0) # roll across freq\n",
    "    unwrap_GD = np.angle(np.exp(1j*(unwrap_angle - unwrap_angle_s))) # paper implementation\n",
    "\n",
    "    return mag, unwrap_GD, phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NPY = os.path.join(FILE_SAVE_PATH,train_clean_mix_file)\n",
    "DEV_NPY = os.path.join(FILE_SAVE_PATH,dev_clean_mix_file)\n",
    "TEST_NPY = os.path.join(FILE_SAVE_PATH,test_clean_mix_file)\n",
    "\n",
    "# TASK = 'TRAIN'\n",
    "TASK = 'DEV'\n",
    "# TASK = 'TEST'\n",
    "\n",
    "\n",
    "if TASK == 'TRAIN':\n",
    "    PATH_NPY = TRAIN_NPY\n",
    "elif TASK == 'DEV':\n",
    "    PATH_NPY = DEV_NPY\n",
    "elif TASK == 'TEST':\n",
    "    PATH_NPY = TEST_NPY\n",
    "    \n",
    "    \n",
    "MAX_TIME_FRAME = 390 # TIMIT = 390, IEEE = 186\n",
    "\n",
    "CLEAN_MAG_FRAMES = []\n",
    "CLEAN_GD_FRAMES = []\n",
    "CLEAN_PHASE_FRAMES = []\n",
    "\n",
    "MIX_MAG_FRAMES = []\n",
    "MIX_GD_FRAMES = []\n",
    "MIX_PHASE_FRAMES = []\n",
    "\n",
    "NOISE_MAG_FRAMES = []\n",
    "NOISE_GD_FRAMES = []\n",
    "NOISE_PHASE_FRAMES = []\n",
    "\n",
    "TIME_FRAMS = []\n",
    "\n",
    "FILE_LIMIT = 10\n",
    "\n",
    "\n",
    "for enum, X in enumerate(np.load(PATH_NPY)):\n",
    "    clean_filename = X[0]\n",
    "    mix_filename = X[1]\n",
    "    \n",
    "#     mag_clean, gd_clean = mag_gd(clean_filename,fs, n_fft, hop_length, win_length)\n",
    "    mag_clean, gd_clean, phase_clean = mag_gd_phase(clean_filename,fs, n_fft, hop_length, win_length)\n",
    "    CLEAN_MAG_FRAMES.extend(mag_clean.T)\n",
    "    CLEAN_GD_FRAMES.extend(gd_clean.T)\n",
    "    CLEAN_PHASE_FRAMES.extend(phase_clean.T)\n",
    "    \n",
    "    D = mag_clean*phase_clean\n",
    "    enhanced = librosa.istft(D,n_fft,hop_length,win_length)\n",
    "    \n",
    "    wav_filepath = \"\".join(['/data/knayem/TEST/',str(enum),'.wav'])\n",
    "    soundfile.write(wav_filepath, enhanced, int(fs))\n",
    "    \n",
    "#     mag_mix, gd_mix = mag_gd(mix_filename,fs, n_fft, hop_length, win_length)\n",
    "    mag_mix, gd_mix, phase_mix = mag_gd_phase(mix_filename,fs, n_fft, hop_length, win_length)\n",
    "    MIX_MAG_FRAMES.extend(mag_mix.T)\n",
    "    MIX_GD_FRAMES.extend(gd_mix.T)\n",
    "    MIX_PHASE_FRAMES.extend(phase_mix.T)\n",
    "    \n",
    "#     mag_noise, gd_noise = (mag_mix-mag_clean), (gd_mix-gd_clean)\n",
    "    mag_noise, gd_noise, phase_noise = (mag_mix-mag_clean), (gd_mix-gd_clean), (phase_mix-phase_clean)\n",
    "    NOISE_MAG_FRAMES.extend(mag_noise.T)\n",
    "    NOISE_GD_FRAMES.extend(gd_noise.T)\n",
    "    NOISE_PHASE_FRAMES.extend(phase_noise.T)\n",
    "    \n",
    "    TIME_FRAMS.append(mag_clean.shape[1])\n",
    "    \n",
    "    if enum == FILE_LIMIT:\n",
    "        break\n",
    "        \n",
    "        \n",
    "CLEAN_MAGS = np.stack(CLEAN_MAG_FRAMES,axis=1)\n",
    "CLEAN_GDS = np.stack(CLEAN_GD_FRAMES,axis=1)\n",
    "CLEAN_PHASES = np.stack(CLEAN_PHASE_FRAMES,axis=1)\n",
    "\n",
    "MIX_MAGS = np.stack(MIX_MAG_FRAMES,axis=1)\n",
    "MIX_GDS = np.stack(MIX_GD_FRAMES,axis=1)\n",
    "MIX_PHASES = np.stack(MIX_PHASE_FRAMES,axis=1)\n",
    "\n",
    "NOISE_MAGS = np.stack(NOISE_MAG_FRAMES,axis=1)\n",
    "NOISE_GDS = np.stack(NOISE_GD_FRAMES,axis=1)\n",
    "NOISE_PHASES = np.stack(NOISE_PHASE_FRAMES,axis=1)\n",
    "\n",
    "TIME_FRAMS = np.array(TIME_FRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TASK == 'TRAIN':\n",
    "    train_clean_mags_file = 'train_clean_mags.npy' if FILE_LIMIT is None else 'train_clean_mags'+str(FILE_LIMIT)+'.npy' #(321x)\n",
    "    train_clean_gds_file = 'train_clean_gds.npy' #(321x)\n",
    "    train_clean_phases_file = 'train_clean_phases.npy' #(321x)\n",
    "    \n",
    "    train_mix_mags_file = 'train_mix_mags.npy' #(321x)\n",
    "    train_mix_gds_file = 'train_mix_gds.npy' #(321x)\n",
    "    train_mix_phases_file = 'train_mix_phases.npy' #(321x)\n",
    "    \n",
    "    train_noise_mags_file = 'train_noise_mags.npy' #(321x)\n",
    "    train_noise_gds_file = 'train_noise_gds.npy' #(321x)\n",
    "    train_noise_phases_file = 'train_noise_phases.npy' #(321x)\n",
    "    \n",
    "    train_timeframe_file = 'train_timeframe.npy' #(1-d)\n",
    "\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,train_clean_mags_file), CLEAN_MAGS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,train_clean_gds_file), CLEAN_GDS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,train_clean_phases_file), CLEAN_PHASES)\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,train_mix_mags_file), MIX_MAGS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,train_mix_gds_file), MIX_GDS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,train_mix_phases_file), MIX_PHASES)\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,train_noise_mags_file), NOISE_MAGS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,train_noise_gds_file), NOISE_GDS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,train_noise_phases_file), NOISE_PHASES)\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,train_timeframe_file), TIME_FRAMS)\n",
    "    \n",
    "    \n",
    "    \n",
    "elif TASK == 'DEV':\n",
    "    dev_clean_mags_file = 'dev_clean_mags.npy' if FILE_LIMIT is None else 'dev_clean_mags'+str(FILE_LIMIT)+'.npy' #(321x)\n",
    "    dev_clean_gds_file = 'dev_clean_gds.npy' if FILE_LIMIT is None else 'dev_clean_gds'+str(FILE_LIMIT)+'.npy'#(321x)\n",
    "    dev_clean_phases_file = 'dev_clean_phases.npy' if FILE_LIMIT is None else 'dev_clean_phases'+str(FILE_LIMIT)+'.npy' #(321x)\n",
    "    \n",
    "    dev_mix_mags_file = 'dev_mix_mags.npy' if FILE_LIMIT is None else 'dev_mix_mags'+str(FILE_LIMIT)+'.npy' #(321x)\n",
    "    dev_mix_gds_file = 'dev_mix_gds.npy' if FILE_LIMIT is None else 'dev_mix_gds'+str(FILE_LIMIT)+'.npy' #(321x)\n",
    "    dev_mix_phases_file = 'dev_mix_phases.npy' if FILE_LIMIT is None else 'dev_mix_phases'+str(FILE_LIMIT)+'.npy' #(321x)\n",
    "    \n",
    "    dev_noise_mags_file = 'dev_noise_mags.npy' if FILE_LIMIT is None else 'dev_noise_mags'+str(FILE_LIMIT)+'.npy' #(321x)\n",
    "    dev_noise_gds_file = 'dev_noise_gds.npy' if FILE_LIMIT is None else 'dev_noise_gds'+str(FILE_LIMIT)+'.npy' #(321x)\n",
    "    dev_noise_phases_file = 'dev_noise_phases.npy' if FILE_LIMIT is None else 'dev_noise_phases'+str(FILE_LIMIT)+'.npy' #(321x)\n",
    "    \n",
    "    dev_timeframe_file = 'dev_timeframe.npy' if FILE_LIMIT is None else 'dev_timeframe'+str(FILE_LIMIT)+'.npy' #(1-d)\n",
    "\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,dev_clean_mags_file), CLEAN_MAGS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,dev_clean_gds_file), CLEAN_GDS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,dev_clean_phases_file), CLEAN_PHASES)\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,dev_mix_mags_file), MIX_MAGS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,dev_mix_gds_file), MIX_GDS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,dev_mix_phases_file), MIX_PHASES)\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,dev_noise_mags_file), NOISE_MAGS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,dev_noise_gds_file), NOISE_GDS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,dev_noise_phases_file), NOISE_PHASES)\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,dev_timeframe_file), TIME_FRAMS)\n",
    "    \n",
    "    \n",
    "    \n",
    "elif TASK == 'TEST':\n",
    "    test_clean_mags_file = 'test_clean_mags.npy' #(321x)\n",
    "    test_clean_gds_file = 'test_clean_gds.npy' #(321x)\n",
    "    test_clean_phases_file = 'test_clean_phases.npy' #(321x)\n",
    "    \n",
    "    test_mix_mags_file = 'test_mix_mags.npy' #(321x)\n",
    "    test_mix_gds_file = 'test_mix_gds.npy' #(321x)\n",
    "    test_mix_phases_file = 'test_mix_phases.npy' #(321x)\n",
    "    \n",
    "    test_noise_mags_file = 'test_noise_mags.npy' #(321x)\n",
    "    test_noise_gds_file = 'test_noise_gds.npy' #(321x)\n",
    "    test_noise_phases_file = 'test_noise_phases.npy' #(321x)\n",
    "    \n",
    "    test_timeframe_file = 'test_timeframe.npy' #(1-d)\n",
    "\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,test_clean_mags_file), CLEAN_MAGS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,test_clean_gds_file), CLEAN_GDS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,test_clean_phases_file), CLEAN_PHASES)\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,test_mix_mags_file), MIX_MAGS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,test_mix_gds_file), MIX_GDS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,test_mix_phases_file), MIX_PHASES)\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,test_noise_mags_file), NOISE_MAGS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,test_noise_gds_file), NOISE_GDS)\n",
    "    np.save(os.path.join(FILE_SAVE_PATH,test_noise_phases_file), NOISE_PHASES)\n",
    "    \n",
    "    np.save(os.path.join(FILE_SAVE_PATH,test_timeframe_file), TIME_FRAMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 799)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(os.path.join(FILE_SAVE_PATH,dev_clean_mags_file)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 799)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75135916, 0.34473017, 0.12033577, 0.13483784, 0.00905557,\n",
       "       0.11165312, 0.08665249, 0.03198211, 0.01739748, 0.02441831],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75135916, 0.34473017, 0.12033577, 0.13483784, 0.00905557,\n",
       "       0.11165312, 0.08665249, 0.03198211, 0.01739748, 0.02441831],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
